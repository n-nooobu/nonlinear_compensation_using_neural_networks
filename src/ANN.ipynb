{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3層ANNによる非線形歪補償\n",
    "最も基本的な、入力層・中間層・出力層からなる3層ANNによる補償"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "sys.path.append('../')\n",
    "from pyopt.util import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 データの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shaping(input_signal, signal, sampling, tap, max_tap, n):\n",
    "    \"\"\"\n",
    "    input_signal: 伝送前の信号\n",
    "    signal: 伝送後の信号\n",
    "    max_tap: 最大の同時入力シンボル数\n",
    "    tap: 同時入力シンボル数\n",
    "    \n",
    "    signal = [x_0, x_1, ... , x_(n-1)]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[x_0, x_1, ... , x_tap-1],\n",
    "            [x_1, x_2, ..., x_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [x_(n-tap), x_(n-tap+1), ..., x(n-1)]]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[i_0, q_0, i_1, q_1, ... , i_(tap-1), q_(tap-1)],\n",
    "            [i_1, q_1, i_2, q_2, ... , i_tap, q_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [i_(n-tap), q_(n-tap), i_(n-tap+1), q_(n-tap+1), ..., i_(n-1), q_(n-1)]] (batch, input_dim) input_dim = tap * 2\n",
    "    \n",
    "    y  (batch, output_dim) output_dim = 2\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.zeros((len(input_signal) // n - (max_tap - 1), sampling * tap * 2), dtype=float)\n",
    "    y = np.zeros((len(input_signal) // n - (max_tap - 1), 2), dtype=float)\n",
    "    if sampling == 1:\n",
    "        for i, center in enumerate(range(max_tap // 2, len(input_signal) // n - max_tap // 2)):\n",
    "            for j, symbol in enumerate(range(tap)):\n",
    "                x[i, j * 2] = signal[n * (center - tap // 2 + j) + n // 2].real\n",
    "                x[i, j * 2 + 1] = signal[n * (center - tap // 2 + j) + n // 2].imag\n",
    "            y[i, 0] = input_signal[n // 2 + n * center].real\n",
    "            y[i, 1] = input_signal[n // 2 + n * center].imag\n",
    "    else:\n",
    "        for i, center in enumerate(range(max_tap // 2, len(input_signal) // n - max_tap // 2)):\n",
    "            for j, symbol in enumerate(range(tap)):\n",
    "                for k, sample in enumerate([round(_ * n / sampling) for _ in range(sampling)]):\n",
    "                    x[i, j * sampling * 2 + k * 2] = signal[n * (center - tap // 2 + j) + sample].real\n",
    "                    x[i, j * sampling * 2 + k * 2 + 1] = signal[n * (center - tap // 2 + j) + sample].imag\n",
    "            y[i, 0] = input_signal[n // 2 + n * center].real\n",
    "            y[i, 1] = input_signal[n // 2 + n * center].imag\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size:  (1548, 306)\n",
      "y size:  (1548, 2)\n",
      "[ 3.32045355e+02 -2.75519561e+02  4.60798224e+04 -4.66110424e+04\n",
      "  4.21489600e+04 -4.67112229e+04 -2.32276054e+03  3.07608289e+03\n",
      " -4.51780310e+04 -3.78998500e+04 -4.76122063e+04 -4.59213781e+04\n",
      " -4.30312746e+03  5.16168853e+02 -4.71965222e+04  5.23620751e+04\n",
      " -4.90156310e+04  4.78102035e+04 -2.11024062e+03 -1.27503787e+03\n",
      "  3.04625620e+04  7.02327156e+03  3.32956474e+04  4.77377947e+03\n",
      " -5.24451737e+02 -3.21177869e+03 -4.58767073e+04  4.41633798e+04\n",
      " -4.02995504e+04  4.46267546e+04  3.18925268e+03 -2.47473771e+02\n",
      " -8.17551172e+04 -2.76568296e+04 -8.44275255e+04 -2.73195821e+04\n",
      " -1.24965302e+01  6.39903865e+02  6.71308196e+04 -1.32647465e+04\n",
      "  6.34534868e+04 -1.13760122e+04  1.77276951e+03 -1.29113052e+03\n",
      "  1.22564189e+04  6.37524278e+04  1.17292734e+04  6.21289954e+04\n",
      "  3.36816206e+02  1.70855464e+02  9.66458066e+03  7.04518322e+04\n",
      "  8.50997421e+03  6.33176591e+04  4.41145849e+02  3.15510735e+03\n",
      " -2.46742537e+04 -7.34993019e+03 -2.48112644e+04 -1.03964673e+04\n",
      " -3.90033822e+03 -7.21752961e+02 -1.08389738e+04 -6.65034997e+04\n",
      " -8.87908216e+03 -6.73213119e+04  7.13816855e+00  3.42239998e+02\n",
      " -4.70250927e+04 -4.49640606e+04 -4.61192789e+04 -4.16110950e+04\n",
      "  4.72988212e+03  1.24523425e+03  2.42318744e+04 -8.18089954e+04\n",
      "  2.85358275e+04 -8.20175530e+04 -9.90552350e+02  1.95030006e+03\n",
      "  5.81079575e+03  6.39442604e+04  1.15286728e+04  6.08774830e+04\n",
      " -4.84180117e+02  2.28750490e+03  8.37920873e+04  2.81499650e+04\n",
      "  8.39637993e+04  3.10408525e+04 -1.86027119e+02 -1.35211075e+03\n",
      " -4.08047219e+04 -4.50303954e+04 -4.55120486e+04 -4.68882816e+04\n",
      "  2.13356392e+03  1.54401100e+03  9.15253451e+03 -2.44307766e+04\n",
      "  1.08443820e+04 -2.59165815e+04  2.57089816e+02  1.24604373e+03\n",
      "  2.48185541e+04  8.99318015e+03  2.93637504e+04  9.12224959e+03\n",
      " -7.54156886e+02  6.81946289e+03  6.90808136e+03 -2.75577469e+04\n",
      "  5.32146609e+03 -2.82429774e+04 -1.24658647e+03 -1.80191779e+03\n",
      "  2.31189220e+04 -8.13105073e+04  2.53777360e+04 -8.09490811e+04\n",
      " -1.73290221e+03 -1.25002230e+03  8.81998222e+03 -3.28764374e+04\n",
      "  9.21176409e+03 -2.54999676e+04 -2.61977059e+03  8.04075691e+02\n",
      "  2.59479479e+04 -7.96862434e+04  2.92836347e+04 -8.11292489e+04\n",
      " -1.71236369e+03  3.01779520e+03 -4.73710004e+04 -4.96109932e+04\n",
      " -5.14265785e+04 -5.08166866e+04  1.12386576e+03 -2.57368574e+03\n",
      "  2.60916536e+04  9.12311796e+03  2.53540058e+04  6.42796615e+03\n",
      "  4.14075379e+02 -1.17365426e+03 -1.27604725e+04  2.71874921e+04\n",
      " -1.05661874e+04  2.78303741e+04  2.33268189e+03  2.04412925e+03\n",
      "  8.66132113e+04  2.69695552e+04  8.45211186e+04  2.54157516e+04\n",
      " -5.49166818e+02 -4.18430513e+03 -2.15459032e+04  8.30796044e+04\n",
      " -2.51084508e+04  8.28115994e+04 -2.84551899e+02  4.28974779e+03\n",
      " -4.52587627e+04  4.99250802e+04 -4.36806033e+04  4.95340150e+04\n",
      "  3.68851072e+01  2.83131697e+03 -2.64332603e+04 -7.54420913e+03\n",
      " -2.56205808e+04 -7.66280302e+03 -1.63458715e+03  1.62010934e+03\n",
      " -7.99683475e+04 -2.85498791e+04 -8.11733306e+04 -2.87000030e+04\n",
      "  2.03796042e+03  1.96356657e+03  2.84244832e+04  1.01544884e+04\n",
      "  2.71645653e+04  6.74953727e+03  1.38525154e+02  1.65878737e+03\n",
      "  2.46323137e+04  8.38549236e+03  2.60056369e+04  6.06721551e+03\n",
      " -1.57056096e+03  4.33145091e+03  5.10403416e+04  4.55674755e+04\n",
      "  4.75064913e+04  4.51240854e+04  8.82823223e+02 -1.59336889e+03\n",
      " -8.72997849e+04 -2.51665311e+04 -8.27454183e+04 -2.42123908e+04\n",
      "  1.86080521e+03  3.51768050e+03 -3.12697592e+04 -8.12374471e+03\n",
      " -2.76794579e+04 -1.10031487e+04  1.42643104e+03  5.56680656e+02\n",
      "  6.66141424e+04 -9.28668407e+03  6.11534402e+04 -1.14722715e+04\n",
      "  2.00570338e+02 -9.41969756e+02 -4.65144029e+04  4.47745086e+04\n",
      " -4.85917645e+04  4.26519018e+04  2.52279079e+03  1.62726184e+03\n",
      "  8.29489918e+04  2.82133674e+04  7.92664570e+04  2.73878092e+04\n",
      " -1.08447167e+03 -6.76918971e+02 -6.36115951e+04  8.03251456e+03\n",
      " -6.27420834e+04  1.41194012e+04  1.21654336e+03 -2.16447136e+03\n",
      " -6.79322395e+04  1.12138359e+04 -6.23313950e+04  6.40062510e+03\n",
      " -1.04825888e+03 -1.43596659e+03  6.16675499e+04 -9.94075807e+03\n",
      "  6.19866212e+04 -1.18299655e+04 -3.72250372e+03 -5.37954712e+02\n",
      " -8.30669465e+04 -2.40051258e+04 -7.98169225e+04 -2.63163393e+04\n",
      "  1.59971195e+02  9.73601992e+01 -1.03180678e+04  3.03623751e+04\n",
      " -1.08704334e+04  2.64513244e+04 -9.04078604e+02  5.35702446e+02\n",
      " -2.81105310e+04 -1.22749974e+04 -3.20849262e+04 -1.10112739e+04\n",
      " -1.33610755e+02 -1.12192167e+03  5.09700623e+04 -4.76953327e+04\n",
      "  4.67810827e+04 -4.41862359e+04 -3.99368400e+03  3.42150923e+03\n",
      "  6.46803856e+04 -9.19397202e+03  6.38207511e+04 -1.12047091e+04\n",
      "  6.23366351e+02 -5.57269505e+02 -2.38260144e+04  8.31586738e+04\n",
      " -2.52584837e+04  8.30293409e+04  1.55241712e+03 -1.98538335e+03\n",
      " -6.85660051e+04  1.08056785e+04 -6.50783081e+04  1.27607210e+04\n",
      " -3.46964956e+02 -1.43479685e+03 -1.07954779e+04  3.20283639e+04\n",
      " -1.14392804e+04  3.13400136e+04  2.31624369e+03 -1.38730458e+03\n",
      "  4.68354965e+04  4.37590223e+04  4.53304681e+04  4.43524221e+04\n",
      "  7.60731373e+02  3.06697784e+03 -8.18468950e+03 -6.90333435e+04\n",
      " -1.10430112e+04 -6.87647114e+04]\n",
      "[70474.95606832 70474.95606832]\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "sampling = 3\n",
    "tap = 51\n",
    "max_tap = 501\n",
    "\n",
    "df_dir = '../data/input/prbs.csv'\n",
    "df = pd.read_csv(df_dir, index_col=0)  # dataframe読み込み\n",
    "condition = (df['N']==13) & (df['itr']==1) & (df['form']=='RZ16QAM') & (df['n']==32) & (df['equalize']==False) & (df['baudrate']==28) & (df['PdBm']==1)\n",
    "sgnl = load_pickle(df[condition].iloc[0]['data_path'])  # dataframeから条件と合う行を取得し,pickleの保存先(data_path)にアクセス\n",
    "lc = sgnl.linear_compensation(500, sgnl.signal['x_500'])\n",
    "x, y = data_shaping(sgnl.signal['x_0'], lc, sampling, tap, max_tap, 32)  # ANNに入力できるようにデータを整形\n",
    "\n",
    "print('x size: ', x.shape)\n",
    "print('y size: ', y.shape)\n",
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x432 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(20, 6))\n",
    "ax1 = fig.add_subplot(1, 3, 1)\n",
    "ax2 = fig.add_subplot(1, 3, 2)\n",
    "ax3 = fig.add_subplot(1, 3, 3)\n",
    "\n",
    "ax1.plot(sgnl.signal['x_0'][16::32].real, sgnl.signal['x_0'][16::32].imag, 'o')\n",
    "ax1.set_title('constellation L=0km')\n",
    "\n",
    "ax2.plot(sgnl.signal['x_500'][16::32].real, sgnl.signal['x_500'][16::32].imag, 'o')\n",
    "ax2.set_title('constellation L=500km')\n",
    "\n",
    "ax3.plot(lc[16::32].real, lc[16::32].imag, 'o')\n",
    "ax3.set_title('constellation L=500km 100%linear comp.');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 平均,標準偏差の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  1053.2765739234778\n",
      "std:  45950.91990246874\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "\n",
    "print('mean: ', mean)\n",
    "print('std: ', std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, mean, std):\n",
    "        self.x, self.y, self.mean, self.std = x, y, mean, std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        x = (x - self.mean) / self.std\n",
    "        y = (y - self.mean) / self.std\n",
    "        return torch.Tensor(x), torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.03935981\n",
      "std:  0.9990706\n",
      "tensor([ 0.1744, -0.6305,  0.2542, -0.6643,  0.1498, -0.5816,  0.0621, -0.5425,\n",
      "         0.0989, -0.6737,  0.2707, -0.7228,  0.5879, -1.8054,  0.5348, -1.8017,\n",
      "         1.4744, -0.2758,  1.3161, -0.2410,  1.7203,  0.5624,  1.7064,  0.5428,\n",
      "        -0.6141, -0.2306, -0.6262, -0.2575,  1.8602,  0.5342,  1.7956,  0.5487,\n",
      "        -0.6887,  1.8563, -0.6805,  1.8318,  1.7734,  0.5692,  1.8469,  0.4622,\n",
      "         0.1909, -0.5909,  0.1415, -0.5378,  1.0256, -1.0119,  0.9728, -1.0440,\n",
      "        -0.6777,  1.8656, -0.6665,  1.8169, -0.6359,  1.8979, -0.5313,  1.8349,\n",
      "         0.6288,  0.2404,  0.5757,  0.2335,  0.0350,  1.3691,  0.1842,  1.3636,\n",
      "         0.5889,  0.1623,  0.4928,  0.1936, -1.5795,  0.1956, -1.4978,  0.2328,\n",
      "        -1.4946,  0.1612, -1.4766,  0.1482,  1.3541, -0.1792,  1.3138, -0.2410,\n",
      "         0.6693,  0.0918,  0.5981,  0.1094,  0.1877, -0.6334,  0.1373, -0.6857,\n",
      "         0.1281, -0.7059,  0.1780, -0.6310, -1.4345,  0.1194, -1.4554,  0.1487,\n",
      "        -1.0567,  0.9861, -1.0175,  0.9582, -1.0534,  1.0651, -0.9946,  0.8584,\n",
      "         0.6258, -1.8519,  0.5814, -1.8388, -0.3147,  0.5872, -0.3128,  0.6085,\n",
      "        -0.9721,  0.9487, -0.9926,  1.0160, -0.2349, -1.4616, -0.2106, -1.4232,\n",
      "        -0.1222,  0.6249, -0.3570,  0.5721, -0.9767,  1.0222, -0.9368,  0.8951,\n",
      "        -1.8920, -0.6365, -1.8180, -0.6650, -0.9942,  0.9424, -1.0756,  0.9713,\n",
      "        -1.3181,  0.2100, -1.3924,  0.2597,  1.8347,  0.5703,  1.8313,  0.5678,\n",
      "         0.9322, -0.9259,  0.9901, -1.0064, -1.8963, -0.6826, -1.6828, -0.6674,\n",
      "        -0.6219, -0.3288, -0.6863, -0.2532,  0.1582, -0.6396,  0.1476, -0.6192,\n",
      "         1.0003,  0.9253,  1.0361,  0.9888, -1.4005,  0.1922, -1.4542,  0.1440,\n",
      "        -0.0970, -1.4383, -0.1806, -1.5318, -0.1594, -1.4511, -0.2324, -1.3888,\n",
      "        -0.9514,  1.0526, -0.9514,  0.9613,  1.0373,  0.9032,  1.0107,  0.9216,\n",
      "        -1.0290, -0.9567, -1.0048, -1.0088, -0.5480,  1.8265, -0.6128,  1.8537,\n",
      "         0.2205,  1.4553,  0.2521,  1.3858,  1.3612, -0.1437,  1.3794, -0.1965,\n",
      "         1.7403,  0.4873,  1.7683,  0.6537])\n",
      "tensor([-1.5566,  0.4883])\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "\n",
    "index = 0\n",
    "x_normalized, y_normalized = train_dataset.__getitem__(index)\n",
    "x_array = x_normalized.detach().numpy()\n",
    "\n",
    "print('mean: ', np.mean(x_array))\n",
    "print('std: ', np.std(x_array))\n",
    "print(x_normalized)\n",
    "print(y_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_neuron, activation):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_neuron)\n",
    "        self.fc2 = nn.Linear(hidden_neuron, output_dim)\n",
    "        if activation == 'ReLU':\n",
    "            self.activation = F.relu\n",
    "        elif activation == 'Sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "torch.Size([100, 204])\n",
      "tensor([[-0.0459,  0.0695],\n",
      "        [ 0.0309, -0.0350],\n",
      "        [-0.0725,  0.1273],\n",
      "        [-0.0221,  0.0749],\n",
      "        [-0.1046,  0.1126],\n",
      "        [-0.0534,  0.1939]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "hidden_neuron = 300\n",
    "activation = 'Sigmoid'\n",
    "device = torch.device('cpu') # 'cuda' if torch.cuda.is_available() else \n",
    "print('Device available now:', device)\n",
    "\n",
    "model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=hidden_neuron, activation=activation).to(device)\n",
    "for x, y in train_dataloader:\n",
    "    print(x.shape)\n",
    "    output = model(x)\n",
    "    print(output[:6])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evm_score(y_pred, y_true):\n",
    "    tmp = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        tmp += ((y_pred[i][0] - y_true[i][0]) ** 2 + (y_pred[i][1] - y_true[i][1]) ** 2) / (y_true[i][0] ** 2 + y_true[i][1] ** 2)\n",
    "    evm = torch.sqrt(tmp / len(y_pred))\n",
    "    return evm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, model, dataloaders_dict, criterion, optimizer, epochs, epochs_section=None):\n",
    "    \"\"\"\n",
    "    epochs_section: [start_epoch, end_epoch]\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if epochs_section is not None:\n",
    "            epoch += epochs_section[0]\n",
    "            end_epoch = epochs_section[1]\n",
    "        else:\n",
    "            end_epoch = epochs\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for phase in dataloaders_dict.keys():\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_evms = 0.0\n",
    "            \n",
    "            for x, y in dataloaders_dict[phase]:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(x)\n",
    "                    loss = criterion(outputs, y)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item() * x.size(0)\n",
    "                    epoch_evms += (evm_score(outputs, y)) ** 2 * x.size(0)\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_evm = torch.sqrt(epoch_evms / len(dataloaders_dict[phase].dataset)) * 100\n",
    "            \n",
    "            duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "            print('{} | Epoch: {}/{} | {} Loss: {:.4} | EVM: {:.4}'.format(duration, epoch + 1, end_epoch, phase, epoch_loss, epoch_evm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 | Epoch: 1/5 | train Loss: 0.9742 | EVM: 99.0\n",
      "0:00:00 | Epoch: 2/5 | train Loss: 0.8474 | EVM: 92.44\n",
      "0:00:00 | Epoch: 3/5 | train Loss: 0.733 | EVM: 86.64\n",
      "0:00:00 | Epoch: 4/5 | train Loss: 0.6156 | EVM: 79.79\n",
      "0:00:00 | Epoch: 5/5 | train Loss: 0.4839 | EVM: 71.19\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    if signal_info['signal_type'] == 'prbs':\n",
    "        return load_prbs(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    elif signal_info['signal_type'] == 'random':\n",
    "        return load_random(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    elif signal_info['signal_type'] == 'image':\n",
    "        return load_image(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prbs(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    N = signal_info['N']\n",
    "    itr = signal_info['itr']\n",
    "    signal_condition = 'N=='+str(N)+'&itr=='+str(itr)\n",
    "    signal_list = [N, itr] + [None] * 6\n",
    "    \n",
    "    # prbs.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'prbs.csv', index_col=0)\n",
    "    \n",
    "    # prbs.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "    t_query = t_df.query(signal_condition + '&' + trans_condition)\n",
    "    \n",
    "    # if prbs.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "    if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "        print('指定された伝送条件の信号が存在しません')\n",
    "        return\n",
    "    else:\n",
    "        # 伝送信号を学習データに整形する\n",
    "        sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "        if lc:\n",
    "            sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "        else:\n",
    "            sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "        x, y = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "        return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    seed = signal_info['seed']\n",
    "    bit_num = signal_info['bit_num']\n",
    "    signal_condition = 'seed=='+str(seed)+'&bit_num=='+str(bit_num)\n",
    "    signal_list = [None] * 2 + [seed, bit_num] + [None] * 4\n",
    "    \n",
    "    # random.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'random.csv', index_col=0)\n",
    "    \n",
    "    # random.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "    t_query = t_df.query(signal_condition + '&' + trans_condition)\n",
    "    \n",
    "    # if random.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "    if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "        print('指定された伝送条件の信号が存在しません')\n",
    "        return\n",
    "    else:\n",
    "        # 伝送信号を学習データに整形する\n",
    "        sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "        if lc:\n",
    "            sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "        else:\n",
    "            sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "        x, y = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "        return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    target_dir = signal_info['target_dir']\n",
    "    step = signal_info['step']\n",
    "    image_number = signal_info['image_number']\n",
    "    image_number_split = image_number.split(', ')\n",
    "    ebtb = signal_info['ebtb']\n",
    "    signal_condition = 'target_dir==\"'+str(target_dir)+'\"&step=='+str(step)+'&image_number==\"'+image_number+'\"&ebtb=='+str(ebtb)\n",
    "    signal_list = [None] * 4 + [target_dir, step, image_number, ebtb]\n",
    "    \n",
    "    # image.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'image.csv', index_col=0)\n",
    "    \n",
    "    x = None\n",
    "    y = None\n",
    "    for i in range(len(image_number_split)):\n",
    "        # image.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "        t_query = t_df.query('target_dir==\"'+str(target_dir)+'\"&step=='+str(step)+'&image_number=='+image_number_split[i]+'&ebtb=='+str(ebtb) + '&' + trans_condition)\n",
    "        \n",
    "        # if image.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "        if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "            print('指定された伝送条件の信号が存在しません')\n",
    "            return\n",
    "        else:\n",
    "            # 伝送信号を学習データに整形する\n",
    "            sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "            if lc:\n",
    "                sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "            else:\n",
    "                sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "            if len(sgnl.signal['x_0']) // n - (max_tap - 1) > 0:\n",
    "                x_tmp, y_tmp = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "            if x is None:\n",
    "                x = x_tmp\n",
    "                y = y_tmp\n",
    "            else:\n",
    "                x = np.concatenate([x, x_tmp])\n",
    "                y = np.concatenate([y, y_tmp])\n",
    "    return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(learn_condition, trans_condition, signal_condition, device, sampling, tap, neuron, epochs, activation, Lmax):\n",
    "    # if ANN.csv がある: pandasで読み込む if ANN.csvがない: 新しいDataFrameを作る\n",
    "    l_df_dir = '../data/params/ANN.csv'\n",
    "    if os.path.exists(l_df_dir):\n",
    "        l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "    else:\n",
    "        cols = ['linear_compensation', 'sampling', 'tap', 'max_tap', 'batch_size', 'neuron', 'epochs', 'learning_rate', 'activation', 'N', 'itr', 'seed', 'bit_num', 'target_dir', 'step', 'image_number', 'ebtb', 'form', 'n', 'equalize', 'baudrate', 'PdBm', 'Ledfa', 'stepedfa', 'gamma', 'D', 'Alpha', 'NF', 'Lmax', 'ase', 'params_path', 'train_samples']\n",
    "        l_df = pd.DataFrame(index=[], columns=cols)\n",
    "        l_df.to_csv(l_df_dir)\n",
    "\n",
    "    # ANN.csvにおいて、指定した条件を満たす行だけqueryとして抜き出す\n",
    "    l_query = l_df.query(learn_condition + '&' + signal_condition + '&' + trans_condition + '&Lmax=='+str(Lmax))\n",
    "    \n",
    "    #if epochsを含む指定された条件を満たす結果がある: 何もしない\n",
    "    if len(l_query) > 0 and l_query['epochs'].max() >= epochs:\n",
    "        print('指定された条件の学習結果はすでに存在します')\n",
    "        return None, None, None\n",
    "    else:\n",
    "        # if epochs以外の指定された条件を満たす結果がある: パラメータを読み込む if ない: 新しくモデルを作成する\n",
    "        if len(l_query) > 0:\n",
    "            index = l_query['epochs'].idxmax()\n",
    "            trained_epochs = l_query['epochs'][index]\n",
    "            model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=neuron, activation=activation).to(device)\n",
    "            model.load_state_dict(torch.load(l_query['params_path'][index]))\n",
    "        else:\n",
    "            trained_epochs = 0\n",
    "            model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=neuron, activation=activation).to(device)\n",
    "    return model, l_df_dir, trained_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果と条件を保存しない\n",
    "def train_ann(model_info, signal_info, tap, PdBm):\n",
    "    device = torch.device('cpu') #'cuda' if torch.cuda.is_available() else \n",
    "    print('Device available now:', device)\n",
    "    \n",
    "    lc = model_info['linear_compensation']\n",
    "    sampling = model_info['sampling']\n",
    "    #tap = model_info['tap']\n",
    "    batch_size = model_info['batch_size']\n",
    "    neuron = model_info['neuron']\n",
    "    epochs = model_info['epochs']\n",
    "    lr = model_info['lr']\n",
    "    activation = model_info['activation']\n",
    "    form = model_info['form']\n",
    "    #PdBm = model_info['PdBm']\n",
    "    Lmax = model_info['Lmax']\n",
    "\n",
    "    max_tap = 501\n",
    "    n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "    equalize = False  # 各シンボル数を均等にするか\n",
    "    baudrate = 28  # ボーレート[GBaud]\n",
    "    Ledfa = 100  # EDFAスパン[km]\n",
    "    stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "    gamma = 2.8  # 非線形係数[/W/km]\n",
    "    D = 16  # 分散パラメータ[ps/nm/km]\n",
    "    Alpha = 0.16  # 伝送損失[dB/km]\n",
    "    NF = 4  # ASE雑音指数[dB]\n",
    "    ase = True  # ASE雑音を考慮するか\n",
    "\n",
    "    # 指定した学習条件と伝送条件\n",
    "    trans_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                                    gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "\n",
    "    x, y, _, _ = load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    \n",
    "    # 平均,標準偏差の計算\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    \n",
    "    model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=neuron, activation=activation).to(device)\n",
    "\n",
    "    # dataset, dataloaderの作成\n",
    "    train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "    train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dataloaders_dict = {'train': train_dataloader}\n",
    "\n",
    "    # 損失関数, オプティマイザの作成\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "    # モデルのトレーニング\n",
    "    model = train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果と条件を../data/params/ANN.csvに保存する\n",
    "def train_ann_with_save(model_info, signal_info, tap, PdBm):\n",
    "    device = torch.device('cpu') #'cuda' if torch.cuda.is_available() else \n",
    "    print('Device available now:', device)\n",
    "    \n",
    "    lc = model_info['linear_compensation']\n",
    "    sampling = model_info['sampling']\n",
    "    #tap = model_info['tap']\n",
    "    batch_size = model_info['batch_size']\n",
    "    neuron = model_info['neuron']\n",
    "    epochs = model_info['epochs']\n",
    "    lr = model_info['lr']\n",
    "    activation = model_info['activation']\n",
    "    form = model_info['form']\n",
    "    #PdBm = model_info['PdBm']\n",
    "    Lmax = model_info['Lmax']\n",
    "    \n",
    "    max_tap = 501\n",
    "    n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "    equalize = False  # 各シンボル数を均等にするか\n",
    "    baudrate = 28  # ボーレート[GBaud]\n",
    "    Ledfa = 100  # EDFAスパン[km]\n",
    "    stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "    gamma = 2.8  # 非線形係数[/W/km]\n",
    "    D = 16  # 分散パラメータ[ps/nm/km]\n",
    "    Alpha = 0.16  # 伝送損失[dB/km]\n",
    "    NF = 4  # ASE雑音指数[dB]\n",
    "    ase = True  # ASE雑音を考慮するか\n",
    "\n",
    "    # 指定した学習条件と伝送条件\n",
    "    learn_condition = 'linear_compensation=='+str(lc)+'&sampling=='+str(sampling)+'&tap=='+str(tap)+'&max_tap=='+str(max_tap)+'&batch_size=='+str(batch_size)+'&neuron=='+str(neuron)+'&learning_rate=='+str(lr)+'&activation==\"'+str(activation)+'\"'\n",
    "    trans_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                                    gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "    \n",
    "    x, y, signal_condition, signal_list = load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    if x is not None:\n",
    "        model, l_df_dir, trained_epochs = load_model(learn_condition, trans_condition, signal_condition, device, sampling, tap, neuron, epochs, activation, Lmax)\n",
    "        \n",
    "        if model is not None:\n",
    "            train_samples = len(x)\n",
    "    \n",
    "            # 平均,標準偏差の計算\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            \n",
    "            # dataset, dataloaderの作成\n",
    "            train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "            train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            dataloaders_dict = {'train': train_dataloader}\n",
    "\n",
    "            # 損失関数, オプティマイザの作成\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "            # モデルのトレーニング(50epochsずつ学習し、50epochsずつパラメータを保存する)\n",
    "            for epoch in range(trained_epochs, epochs, 50):\n",
    "                model = train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=50, epochs_section=[epoch, epochs])\n",
    "\n",
    "                # 学習済みパラメータを保存し、ANN.csvに保存先を記入する\n",
    "                l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "                params_path = '../data/params/ANN/params_' + str(len(l_df)).zfill(10) + '.pth'\n",
    "                torch.save(model.state_dict(), params_path)\n",
    "                sr = pd.Series([lc, sampling, tap, max_tap, batch_size, neuron, epoch + 50, lr, activation] + signal_list + [form, n, equalize, baudrate, PdBm, Ledfa, stepedfa, gamma, D, Alpha, NF, Lmax, ase, params_path, train_samples], index=l_df.columns)\n",
    "                l_df = l_df.append(sr, ignore_index=True)\n",
    "                l_df.to_csv(l_df_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "0:00:04 | Epoch: 1/500 | train Loss: 0.4403 | EVM: 50.33\n",
      "0:00:04 | Epoch: 2/500 | train Loss: 0.03639 | EVM: 17.55\n",
      "0:00:04 | Epoch: 3/500 | train Loss: 0.02976 | EVM: 15.89\n",
      "0:00:03 | Epoch: 4/500 | train Loss: 0.0266 | EVM: 14.97\n",
      "0:00:03 | Epoch: 5/500 | train Loss: 0.02521 | EVM: 14.61\n",
      "0:00:03 | Epoch: 6/500 | train Loss: 0.02347 | EVM: 14.06\n",
      "0:00:03 | Epoch: 7/500 | train Loss: 0.02212 | EVM: 13.64\n",
      "0:00:03 | Epoch: 8/500 | train Loss: 0.02117 | EVM: 13.38\n",
      "0:00:04 | Epoch: 9/500 | train Loss: 0.02027 | EVM: 13.08\n",
      "0:00:04 | Epoch: 10/500 | train Loss: 0.01963 | EVM: 12.93\n",
      "0:00:03 | Epoch: 11/500 | train Loss: 0.01873 | EVM: 12.57\n",
      "0:00:03 | Epoch: 12/500 | train Loss: 0.01792 | EVM: 12.32\n",
      "0:00:04 | Epoch: 13/500 | train Loss: 0.0179 | EVM: 12.27\n",
      "0:00:03 | Epoch: 14/500 | train Loss: 0.01696 | EVM: 12.0\n",
      "0:00:04 | Epoch: 15/500 | train Loss: 0.01695 | EVM: 12.0\n",
      "0:00:03 | Epoch: 16/500 | train Loss: 0.01605 | EVM: 11.7\n",
      "0:00:03 | Epoch: 17/500 | train Loss: 0.01544 | EVM: 11.43\n",
      "0:00:04 | Epoch: 18/500 | train Loss: 0.01513 | EVM: 11.34\n",
      "0:00:03 | Epoch: 19/500 | train Loss: 0.01494 | EVM: 11.32\n",
      "0:00:04 | Epoch: 20/500 | train Loss: 0.01456 | EVM: 11.25\n",
      "0:00:04 | Epoch: 21/500 | train Loss: 0.01449 | EVM: 11.11\n",
      "0:00:04 | Epoch: 22/500 | train Loss: 0.01376 | EVM: 10.84\n",
      "0:00:03 | Epoch: 23/500 | train Loss: 0.01303 | EVM: 10.59\n",
      "0:00:03 | Epoch: 24/500 | train Loss: 0.01296 | EVM: 10.54\n",
      "0:00:04 | Epoch: 25/500 | train Loss: 0.01263 | EVM: 10.41\n",
      "0:00:03 | Epoch: 26/500 | train Loss: 0.01245 | EVM: 10.23\n",
      "0:00:03 | Epoch: 27/500 | train Loss: 0.01199 | EVM: 10.16\n",
      "0:00:03 | Epoch: 28/500 | train Loss: 0.01158 | EVM: 9.959\n",
      "0:00:03 | Epoch: 29/500 | train Loss: 0.01202 | EVM: 10.22\n",
      "0:00:04 | Epoch: 30/500 | train Loss: 0.01126 | EVM: 9.872\n",
      "0:00:04 | Epoch: 31/500 | train Loss: 0.01147 | EVM: 9.957\n",
      "0:00:03 | Epoch: 32/500 | train Loss: 0.0106 | EVM: 9.585\n",
      "0:00:03 | Epoch: 33/500 | train Loss: 0.01006 | EVM: 9.388\n",
      "0:00:04 | Epoch: 34/500 | train Loss: 0.01004 | EVM: 9.332\n",
      "0:00:03 | Epoch: 35/500 | train Loss: 0.009946 | EVM: 9.232\n",
      "0:00:04 | Epoch: 36/500 | train Loss: 0.009991 | EVM: 9.306\n",
      "0:00:03 | Epoch: 37/500 | train Loss: 0.009545 | EVM: 9.105\n",
      "0:00:03 | Epoch: 38/500 | train Loss: 0.009551 | EVM: 9.063\n",
      "0:00:03 | Epoch: 39/500 | train Loss: 0.009504 | EVM: 9.051\n",
      "0:00:03 | Epoch: 40/500 | train Loss: 0.009059 | EVM: 8.874\n",
      "0:00:03 | Epoch: 41/500 | train Loss: 0.008932 | EVM: 8.82\n",
      "0:00:04 | Epoch: 42/500 | train Loss: 0.008568 | EVM: 8.624\n",
      "0:00:03 | Epoch: 43/500 | train Loss: 0.008622 | EVM: 8.636\n",
      "0:00:03 | Epoch: 44/500 | train Loss: 0.008027 | EVM: 8.333\n",
      "0:00:04 | Epoch: 45/500 | train Loss: 0.007781 | EVM: 8.242\n",
      "0:00:03 | Epoch: 46/500 | train Loss: 0.008073 | EVM: 8.337\n",
      "0:00:04 | Epoch: 47/500 | train Loss: 0.007726 | EVM: 8.19\n",
      "0:00:03 | Epoch: 48/500 | train Loss: 0.007753 | EVM: 8.218\n",
      "0:00:04 | Epoch: 49/500 | train Loss: 0.008003 | EVM: 8.331\n",
      "0:00:03 | Epoch: 50/500 | train Loss: 0.007338 | EVM: 8.016\n",
      "0:00:03 | Epoch: 51/500 | train Loss: 0.007392 | EVM: 8.026\n",
      "0:00:03 | Epoch: 52/500 | train Loss: 0.007016 | EVM: 7.822\n",
      "0:00:03 | Epoch: 53/500 | train Loss: 0.006948 | EVM: 7.761\n",
      "0:00:04 | Epoch: 54/500 | train Loss: 0.007141 | EVM: 7.865\n",
      "0:00:03 | Epoch: 55/500 | train Loss: 0.00711 | EVM: 7.946\n",
      "0:00:03 | Epoch: 56/500 | train Loss: 0.006723 | EVM: 7.716\n",
      "0:00:03 | Epoch: 57/500 | train Loss: 0.006867 | EVM: 7.683\n",
      "0:00:03 | Epoch: 58/500 | train Loss: 0.006629 | EVM: 7.619\n",
      "0:00:03 | Epoch: 59/500 | train Loss: 0.006352 | EVM: 7.437\n",
      "0:00:04 | Epoch: 60/500 | train Loss: 0.00648 | EVM: 7.464\n",
      "0:00:04 | Epoch: 61/500 | train Loss: 0.006016 | EVM: 7.227\n",
      "0:00:04 | Epoch: 62/500 | train Loss: 0.005782 | EVM: 7.164\n",
      "0:00:03 | Epoch: 63/500 | train Loss: 0.005968 | EVM: 7.191\n",
      "0:00:04 | Epoch: 64/500 | train Loss: 0.005823 | EVM: 7.103\n",
      "0:00:04 | Epoch: 65/500 | train Loss: 0.006142 | EVM: 7.304\n",
      "0:00:04 | Epoch: 66/500 | train Loss: 0.006241 | EVM: 7.314\n",
      "0:00:03 | Epoch: 67/500 | train Loss: 0.005985 | EVM: 7.225\n",
      "0:00:04 | Epoch: 68/500 | train Loss: 0.005837 | EVM: 7.143\n",
      "0:00:03 | Epoch: 69/500 | train Loss: 0.005548 | EVM: 6.973\n",
      "0:00:03 | Epoch: 70/500 | train Loss: 0.0055 | EVM: 6.954\n",
      "0:00:04 | Epoch: 71/500 | train Loss: 0.005655 | EVM: 6.987\n",
      "0:00:03 | Epoch: 72/500 | train Loss: 0.005321 | EVM: 6.858\n",
      "0:00:03 | Epoch: 73/500 | train Loss: 0.005118 | EVM: 6.7\n",
      "0:00:03 | Epoch: 74/500 | train Loss: 0.005405 | EVM: 6.905\n",
      "0:00:03 | Epoch: 75/500 | train Loss: 0.004868 | EVM: 6.525\n",
      "0:00:04 | Epoch: 76/500 | train Loss: 0.005347 | EVM: 6.824\n",
      "0:00:04 | Epoch: 77/500 | train Loss: 0.005301 | EVM: 6.786\n",
      "0:00:03 | Epoch: 78/500 | train Loss: 0.005195 | EVM: 6.752\n",
      "0:00:03 | Epoch: 79/500 | train Loss: 0.005149 | EVM: 6.722\n",
      "0:00:04 | Epoch: 80/500 | train Loss: 0.004389 | EVM: 6.2\n",
      "0:00:04 | Epoch: 81/500 | train Loss: 0.00471 | EVM: 6.427\n",
      "0:00:04 | Epoch: 82/500 | train Loss: 0.004738 | EVM: 6.469\n",
      "0:00:04 | Epoch: 83/500 | train Loss: 0.004514 | EVM: 6.269\n",
      "0:00:04 | Epoch: 84/500 | train Loss: 0.00429 | EVM: 6.085\n",
      "0:00:03 | Epoch: 85/500 | train Loss: 0.004686 | EVM: 6.361\n",
      "0:00:03 | Epoch: 86/500 | train Loss: 0.005044 | EVM: 6.664\n",
      "0:00:03 | Epoch: 87/500 | train Loss: 0.004319 | EVM: 6.106\n",
      "0:00:03 | Epoch: 88/500 | train Loss: 0.00446 | EVM: 6.248\n",
      "0:00:03 | Epoch: 89/500 | train Loss: 0.004474 | EVM: 6.232\n",
      "0:00:04 | Epoch: 90/500 | train Loss: 0.004228 | EVM: 6.067\n",
      "0:00:04 | Epoch: 91/500 | train Loss: 0.004085 | EVM: 6.049\n",
      "0:00:03 | Epoch: 92/500 | train Loss: 0.004283 | EVM: 6.092\n",
      "0:00:03 | Epoch: 93/500 | train Loss: 0.00418 | EVM: 6.083\n",
      "0:00:03 | Epoch: 94/500 | train Loss: 0.004074 | EVM: 5.957\n",
      "0:00:03 | Epoch: 95/500 | train Loss: 0.004061 | EVM: 5.924\n",
      "0:00:04 | Epoch: 96/500 | train Loss: 0.003991 | EVM: 5.915\n",
      "0:00:04 | Epoch: 97/500 | train Loss: 0.003719 | EVM: 5.69\n",
      "0:00:03 | Epoch: 98/500 | train Loss: 0.003876 | EVM: 5.815\n",
      "0:00:04 | Epoch: 99/500 | train Loss: 0.003875 | EVM: 5.81\n",
      "0:00:03 | Epoch: 100/500 | train Loss: 0.003978 | EVM: 5.938\n",
      "0:00:03 | Epoch: 101/500 | train Loss: 0.004134 | EVM: 6.038\n",
      "0:00:04 | Epoch: 102/500 | train Loss: 0.00404 | EVM: 5.956\n",
      "0:00:03 | Epoch: 103/500 | train Loss: 0.004145 | EVM: 6.028\n",
      "0:00:04 | Epoch: 104/500 | train Loss: 0.003799 | EVM: 5.798\n",
      "0:00:04 | Epoch: 105/500 | train Loss: 0.003941 | EVM: 5.888\n",
      "0:00:04 | Epoch: 106/500 | train Loss: 0.004243 | EVM: 6.066\n",
      "0:00:04 | Epoch: 107/500 | train Loss: 0.003776 | EVM: 5.754\n",
      "0:00:04 | Epoch: 108/500 | train Loss: 0.003905 | EVM: 5.811\n",
      "0:00:04 | Epoch: 109/500 | train Loss: 0.003858 | EVM: 5.83\n",
      "0:00:03 | Epoch: 110/500 | train Loss: 0.00348 | EVM: 5.51\n",
      "0:00:04 | Epoch: 111/500 | train Loss: 0.003171 | EVM: 5.318\n",
      "0:00:03 | Epoch: 112/500 | train Loss: 0.00352 | EVM: 5.559\n",
      "0:00:03 | Epoch: 113/500 | train Loss: 0.003551 | EVM: 5.544\n",
      "0:00:03 | Epoch: 114/500 | train Loss: 0.003136 | EVM: 5.242\n",
      "0:00:04 | Epoch: 115/500 | train Loss: 0.003219 | EVM: 5.288\n",
      "0:00:04 | Epoch: 116/500 | train Loss: 0.003287 | EVM: 5.33\n",
      "0:00:03 | Epoch: 117/500 | train Loss: 0.003128 | EVM: 5.218\n",
      "0:00:03 | Epoch: 118/500 | train Loss: 0.003656 | EVM: 5.655\n",
      "0:00:03 | Epoch: 119/500 | train Loss: 0.003894 | EVM: 5.852\n",
      "0:00:04 | Epoch: 120/500 | train Loss: 0.003068 | EVM: 5.185\n",
      "0:00:04 | Epoch: 121/500 | train Loss: 0.003679 | EVM: 5.674\n",
      "0:00:04 | Epoch: 122/500 | train Loss: 0.003733 | EVM: 5.741\n",
      "0:00:03 | Epoch: 123/500 | train Loss: 0.003335 | EVM: 5.407\n",
      "0:00:03 | Epoch: 124/500 | train Loss: 0.003067 | EVM: 5.199\n",
      "0:00:04 | Epoch: 125/500 | train Loss: 0.003315 | EVM: 5.391\n",
      "0:00:04 | Epoch: 126/500 | train Loss: 0.003095 | EVM: 5.209\n",
      "0:00:03 | Epoch: 127/500 | train Loss: 0.003055 | EVM: 5.245\n",
      "0:00:03 | Epoch: 128/500 | train Loss: 0.00289 | EVM: 5.101\n",
      "0:00:04 | Epoch: 129/500 | train Loss: 0.002864 | EVM: 5.04\n",
      "0:00:03 | Epoch: 130/500 | train Loss: 0.003267 | EVM: 5.387\n",
      "0:00:03 | Epoch: 131/500 | train Loss: 0.003246 | EVM: 5.323\n",
      "0:00:03 | Epoch: 132/500 | train Loss: 0.003667 | EVM: 5.66\n",
      "0:00:04 | Epoch: 133/500 | train Loss: 0.004316 | EVM: 6.126\n",
      "0:00:03 | Epoch: 134/500 | train Loss: 0.003296 | EVM: 5.374\n",
      "0:00:03 | Epoch: 135/500 | train Loss: 0.002982 | EVM: 5.097\n",
      "0:00:04 | Epoch: 136/500 | train Loss: 0.003043 | EVM: 5.184\n",
      "0:00:03 | Epoch: 137/500 | train Loss: 0.003054 | EVM: 5.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03 | Epoch: 138/500 | train Loss: 0.003062 | EVM: 5.199\n",
      "0:00:04 | Epoch: 139/500 | train Loss: 0.003239 | EVM: 5.332\n",
      "0:00:04 | Epoch: 140/500 | train Loss: 0.002703 | EVM: 4.892\n",
      "0:00:04 | Epoch: 141/500 | train Loss: 0.003016 | EVM: 5.135\n",
      "0:00:04 | Epoch: 142/500 | train Loss: 0.002841 | EVM: 4.993\n",
      "0:00:04 | Epoch: 143/500 | train Loss: 0.002737 | EVM: 4.869\n",
      "0:00:04 | Epoch: 144/500 | train Loss: 0.002718 | EVM: 4.906\n",
      "0:00:04 | Epoch: 145/500 | train Loss: 0.00286 | EVM: 5.051\n",
      "0:00:04 | Epoch: 146/500 | train Loss: 0.003218 | EVM: 5.285\n",
      "0:00:03 | Epoch: 147/500 | train Loss: 0.003347 | EVM: 5.398\n",
      "0:00:03 | Epoch: 148/500 | train Loss: 0.002906 | EVM: 4.99\n",
      "0:00:03 | Epoch: 149/500 | train Loss: 0.002671 | EVM: 4.804\n",
      "0:00:04 | Epoch: 150/500 | train Loss: 0.002686 | EVM: 4.861\n",
      "0:00:04 | Epoch: 151/500 | train Loss: 0.002686 | EVM: 4.877\n",
      "0:00:03 | Epoch: 152/500 | train Loss: 0.002649 | EVM: 4.854\n",
      "0:00:03 | Epoch: 153/500 | train Loss: 0.002956 | EVM: 5.117\n",
      "0:00:03 | Epoch: 154/500 | train Loss: 0.003271 | EVM: 5.39\n",
      "0:00:03 | Epoch: 155/500 | train Loss: 0.003084 | EVM: 5.209\n",
      "0:00:03 | Epoch: 156/500 | train Loss: 0.00286 | EVM: 5.057\n",
      "0:00:03 | Epoch: 157/500 | train Loss: 0.002592 | EVM: 4.756\n",
      "0:00:03 | Epoch: 158/500 | train Loss: 0.002496 | EVM: 4.667\n",
      "0:00:04 | Epoch: 159/500 | train Loss: 0.002783 | EVM: 4.958\n",
      "0:00:03 | Epoch: 160/500 | train Loss: 0.003034 | EVM: 5.185\n",
      "0:00:04 | Epoch: 161/500 | train Loss: 0.002615 | EVM: 4.813\n",
      "0:00:03 | Epoch: 162/500 | train Loss: 0.003163 | EVM: 5.313\n",
      "0:00:04 | Epoch: 163/500 | train Loss: 0.002615 | EVM: 4.787\n",
      "0:00:04 | Epoch: 164/500 | train Loss: 0.002655 | EVM: 4.843\n",
      "0:00:03 | Epoch: 165/500 | train Loss: 0.00249 | EVM: 4.707\n",
      "0:00:03 | Epoch: 166/500 | train Loss: 0.002311 | EVM: 4.52\n",
      "0:00:03 | Epoch: 167/500 | train Loss: 0.002545 | EVM: 4.708\n",
      "0:00:04 | Epoch: 168/500 | train Loss: 0.003094 | EVM: 5.251\n",
      "0:00:04 | Epoch: 169/500 | train Loss: 0.002679 | EVM: 4.882\n",
      "0:00:03 | Epoch: 170/500 | train Loss: 0.002602 | EVM: 4.836\n",
      "0:00:03 | Epoch: 171/500 | train Loss: 0.002419 | EVM: 4.618\n",
      "0:00:03 | Epoch: 172/500 | train Loss: 0.002249 | EVM: 4.449\n",
      "0:00:03 | Epoch: 173/500 | train Loss: 0.002288 | EVM: 4.436\n",
      "0:00:04 | Epoch: 174/500 | train Loss: 0.00218 | EVM: 4.4\n",
      "0:00:03 | Epoch: 175/500 | train Loss: 0.002478 | EVM: 4.666\n",
      "0:00:03 | Epoch: 176/500 | train Loss: 0.002785 | EVM: 4.952\n",
      "0:00:03 | Epoch: 177/500 | train Loss: 0.002584 | EVM: 4.786\n",
      "0:00:04 | Epoch: 178/500 | train Loss: 0.002502 | EVM: 4.713\n",
      "0:00:04 | Epoch: 179/500 | train Loss: 0.002278 | EVM: 4.456\n",
      "0:00:03 | Epoch: 180/500 | train Loss: 0.002446 | EVM: 4.638\n",
      "0:00:03 | Epoch: 181/500 | train Loss: 0.003007 | EVM: 5.12\n",
      "0:00:04 | Epoch: 182/500 | train Loss: 0.002426 | EVM: 4.604\n",
      "0:00:03 | Epoch: 183/500 | train Loss: 0.002725 | EVM: 4.87\n",
      "0:00:03 | Epoch: 184/500 | train Loss: 0.002723 | EVM: 4.846\n",
      "0:00:03 | Epoch: 185/500 | train Loss: 0.00301 | EVM: 5.145\n",
      "0:00:03 | Epoch: 186/500 | train Loss: 0.002624 | EVM: 4.826\n",
      "0:00:04 | Epoch: 187/500 | train Loss: 0.002226 | EVM: 4.444\n",
      "0:00:03 | Epoch: 188/500 | train Loss: 0.002302 | EVM: 4.483\n",
      "0:00:04 | Epoch: 189/500 | train Loss: 0.002245 | EVM: 4.411\n",
      "0:00:04 | Epoch: 190/500 | train Loss: 0.001853 | EVM: 4.018\n",
      "0:00:04 | Epoch: 191/500 | train Loss: 0.002039 | EVM: 4.229\n",
      "0:00:04 | Epoch: 192/500 | train Loss: 0.00236 | EVM: 4.57\n",
      "0:00:03 | Epoch: 193/500 | train Loss: 0.002765 | EVM: 4.941\n",
      "0:00:03 | Epoch: 194/500 | train Loss: 0.002989 | EVM: 5.12\n",
      "0:00:03 | Epoch: 195/500 | train Loss: 0.002341 | EVM: 4.522\n",
      "0:00:03 | Epoch: 196/500 | train Loss: 0.002009 | EVM: 4.242\n",
      "0:00:03 | Epoch: 197/500 | train Loss: 0.002257 | EVM: 4.491\n",
      "0:00:03 | Epoch: 198/500 | train Loss: 0.002509 | EVM: 4.648\n",
      "0:00:03 | Epoch: 199/500 | train Loss: 0.002411 | EVM: 4.586\n",
      "0:00:03 | Epoch: 200/500 | train Loss: 0.002004 | EVM: 4.195\n",
      "0:00:03 | Epoch: 201/500 | train Loss: 0.001962 | EVM: 4.159\n",
      "0:00:03 | Epoch: 202/500 | train Loss: 0.002258 | EVM: 4.405\n",
      "0:00:03 | Epoch: 203/500 | train Loss: 0.002643 | EVM: 4.839\n",
      "0:00:03 | Epoch: 204/500 | train Loss: 0.0024 | EVM: 4.607\n",
      "0:00:03 | Epoch: 205/500 | train Loss: 0.002037 | EVM: 4.242\n",
      "0:00:04 | Epoch: 206/500 | train Loss: 0.002264 | EVM: 4.485\n",
      "0:00:04 | Epoch: 207/500 | train Loss: 0.00228 | EVM: 4.486\n",
      "0:00:03 | Epoch: 208/500 | train Loss: 0.001978 | EVM: 4.171\n",
      "0:00:04 | Epoch: 209/500 | train Loss: 0.001855 | EVM: 4.031\n",
      "0:00:04 | Epoch: 210/500 | train Loss: 0.002204 | EVM: 4.423\n",
      "0:00:04 | Epoch: 211/500 | train Loss: 0.00276 | EVM: 4.932\n",
      "0:00:04 | Epoch: 212/500 | train Loss: 0.002263 | EVM: 4.457\n",
      "0:00:04 | Epoch: 213/500 | train Loss: 0.002066 | EVM: 4.237\n",
      "0:00:03 | Epoch: 214/500 | train Loss: 0.001555 | EVM: 3.707\n",
      "0:00:03 | Epoch: 215/500 | train Loss: 0.001978 | EVM: 4.141\n",
      "0:00:03 | Epoch: 216/500 | train Loss: 0.002108 | EVM: 4.288\n",
      "0:00:03 | Epoch: 217/500 | train Loss: 0.002072 | EVM: 4.248\n",
      "0:00:04 | Epoch: 218/500 | train Loss: 0.002192 | EVM: 4.406\n",
      "0:00:04 | Epoch: 219/500 | train Loss: 0.001898 | EVM: 4.106\n",
      "0:00:04 | Epoch: 220/500 | train Loss: 0.002106 | EVM: 4.295\n",
      "0:00:04 | Epoch: 221/500 | train Loss: 0.001893 | EVM: 4.074\n",
      "0:00:04 | Epoch: 222/500 | train Loss: 0.001908 | EVM: 4.098\n",
      "0:00:04 | Epoch: 223/500 | train Loss: 0.002276 | EVM: 4.431\n",
      "0:00:04 | Epoch: 224/500 | train Loss: 0.002419 | EVM: 4.62\n",
      "0:00:04 | Epoch: 225/500 | train Loss: 0.002987 | EVM: 5.113\n",
      "0:00:03 | Epoch: 226/500 | train Loss: 0.002454 | EVM: 4.636\n",
      "0:00:03 | Epoch: 227/500 | train Loss: 0.002453 | EVM: 4.635\n",
      "0:00:04 | Epoch: 228/500 | train Loss: 0.002025 | EVM: 4.203\n",
      "0:00:03 | Epoch: 229/500 | train Loss: 0.002228 | EVM: 4.413\n",
      "0:00:04 | Epoch: 230/500 | train Loss: 0.002141 | EVM: 4.35\n",
      "0:00:04 | Epoch: 231/500 | train Loss: 0.001884 | EVM: 4.042\n",
      "0:00:04 | Epoch: 232/500 | train Loss: 0.002088 | EVM: 4.302\n",
      "0:00:04 | Epoch: 233/500 | train Loss: 0.001926 | EVM: 4.131\n",
      "0:00:03 | Epoch: 234/500 | train Loss: 0.001787 | EVM: 3.943\n",
      "0:00:03 | Epoch: 235/500 | train Loss: 0.001913 | EVM: 4.11\n",
      "0:00:04 | Epoch: 236/500 | train Loss: 0.002166 | EVM: 4.369\n",
      "0:00:03 | Epoch: 237/500 | train Loss: 0.002163 | EVM: 4.36\n",
      "0:00:03 | Epoch: 238/500 | train Loss: 0.00208 | EVM: 4.282\n",
      "0:00:04 | Epoch: 239/500 | train Loss: 0.002947 | EVM: 5.095\n",
      "0:00:03 | Epoch: 240/500 | train Loss: 0.002444 | EVM: 4.65\n",
      "0:00:04 | Epoch: 241/500 | train Loss: 0.001909 | EVM: 4.038\n",
      "0:00:04 | Epoch: 242/500 | train Loss: 0.002051 | EVM: 4.2\n",
      "0:00:04 | Epoch: 243/500 | train Loss: 0.001697 | EVM: 3.876\n",
      "0:00:04 | Epoch: 244/500 | train Loss: 0.001548 | EVM: 3.696\n",
      "0:00:04 | Epoch: 245/500 | train Loss: 0.001914 | EVM: 4.117\n",
      "0:00:04 | Epoch: 246/500 | train Loss: 0.001898 | EVM: 4.083\n",
      "0:00:04 | Epoch: 247/500 | train Loss: 0.001619 | EVM: 3.747\n",
      "0:00:04 | Epoch: 248/500 | train Loss: 0.001848 | EVM: 4.005\n",
      "0:00:04 | Epoch: 249/500 | train Loss: 0.002084 | EVM: 4.29\n",
      "0:00:04 | Epoch: 250/500 | train Loss: 0.002163 | EVM: 4.33\n",
      "0:00:03 | Epoch: 251/500 | train Loss: 0.001962 | EVM: 4.188\n",
      "0:00:04 | Epoch: 252/500 | train Loss: 0.002328 | EVM: 4.496\n",
      "0:00:03 | Epoch: 253/500 | train Loss: 0.002293 | EVM: 4.517\n",
      "0:00:03 | Epoch: 254/500 | train Loss: 0.00233 | EVM: 4.551\n",
      "0:00:04 | Epoch: 255/500 | train Loss: 0.001961 | EVM: 4.134\n",
      "0:00:03 | Epoch: 256/500 | train Loss: 0.001553 | EVM: 3.661\n",
      "0:00:04 | Epoch: 257/500 | train Loss: 0.001389 | EVM: 3.508\n",
      "0:00:03 | Epoch: 258/500 | train Loss: 0.001671 | EVM: 3.833\n",
      "0:00:04 | Epoch: 259/500 | train Loss: 0.001899 | EVM: 4.125\n",
      "0:00:03 | Epoch: 260/500 | train Loss: 0.00177 | EVM: 3.983\n",
      "0:00:04 | Epoch: 261/500 | train Loss: 0.001794 | EVM: 3.991\n",
      "0:00:04 | Epoch: 262/500 | train Loss: 0.002352 | EVM: 4.52\n",
      "0:00:03 | Epoch: 263/500 | train Loss: 0.001909 | EVM: 4.054\n",
      "0:00:04 | Epoch: 264/500 | train Loss: 0.001854 | EVM: 4.036\n",
      "0:00:04 | Epoch: 265/500 | train Loss: 0.001906 | EVM: 4.089\n",
      "0:00:04 | Epoch: 266/500 | train Loss: 0.001726 | EVM: 3.892\n",
      "0:00:04 | Epoch: 267/500 | train Loss: 0.00243 | EVM: 4.617\n",
      "0:00:03 | Epoch: 268/500 | train Loss: 0.002333 | EVM: 4.56\n",
      "0:00:04 | Epoch: 269/500 | train Loss: 0.002072 | EVM: 4.267\n",
      "0:00:03 | Epoch: 270/500 | train Loss: 0.001626 | EVM: 3.766\n",
      "0:00:03 | Epoch: 271/500 | train Loss: 0.001823 | EVM: 4.01\n",
      "0:00:04 | Epoch: 272/500 | train Loss: 0.001957 | EVM: 4.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03 | Epoch: 273/500 | train Loss: 0.001787 | EVM: 3.966\n",
      "0:00:03 | Epoch: 274/500 | train Loss: 0.002044 | EVM: 4.214\n",
      "0:00:03 | Epoch: 275/500 | train Loss: 0.001887 | EVM: 4.025\n",
      "0:00:04 | Epoch: 276/500 | train Loss: 0.001711 | EVM: 3.886\n",
      "0:00:04 | Epoch: 277/500 | train Loss: 0.001828 | EVM: 3.995\n",
      "0:00:04 | Epoch: 278/500 | train Loss: 0.001609 | EVM: 3.772\n",
      "0:00:03 | Epoch: 279/500 | train Loss: 0.00163 | EVM: 3.814\n",
      "0:00:03 | Epoch: 280/500 | train Loss: 0.001975 | EVM: 4.191\n",
      "0:00:03 | Epoch: 281/500 | train Loss: 0.002272 | EVM: 4.469\n",
      "0:00:04 | Epoch: 282/500 | train Loss: 0.002013 | EVM: 4.216\n",
      "0:00:04 | Epoch: 283/500 | train Loss: 0.002186 | EVM: 4.37\n",
      "0:00:04 | Epoch: 284/500 | train Loss: 0.001858 | EVM: 4.002\n",
      "0:00:04 | Epoch: 285/500 | train Loss: 0.00159 | EVM: 3.72\n",
      "0:00:03 | Epoch: 286/500 | train Loss: 0.001737 | EVM: 3.966\n",
      "0:00:03 | Epoch: 287/500 | train Loss: 0.001917 | EVM: 4.111\n",
      "0:00:04 | Epoch: 288/500 | train Loss: 0.001861 | EVM: 4.051\n",
      "0:00:04 | Epoch: 289/500 | train Loss: 0.001799 | EVM: 3.979\n",
      "0:00:04 | Epoch: 290/500 | train Loss: 0.002105 | EVM: 4.35\n",
      "0:00:03 | Epoch: 291/500 | train Loss: 0.001788 | EVM: 3.972\n",
      "0:00:03 | Epoch: 292/500 | train Loss: 0.001684 | EVM: 3.878\n",
      "0:00:03 | Epoch: 293/500 | train Loss: 0.001999 | EVM: 4.215\n",
      "0:00:03 | Epoch: 294/500 | train Loss: 0.001738 | EVM: 3.926\n",
      "0:00:03 | Epoch: 295/500 | train Loss: 0.001887 | EVM: 4.047\n",
      "0:00:03 | Epoch: 296/500 | train Loss: 0.001953 | EVM: 4.118\n",
      "0:00:04 | Epoch: 297/500 | train Loss: 0.001925 | EVM: 4.107\n",
      "0:00:04 | Epoch: 298/500 | train Loss: 0.001716 | EVM: 3.885\n",
      "0:00:04 | Epoch: 299/500 | train Loss: 0.001464 | EVM: 3.572\n",
      "0:00:04 | Epoch: 300/500 | train Loss: 0.001781 | EVM: 3.939\n",
      "0:00:03 | Epoch: 301/500 | train Loss: 0.001812 | EVM: 4.012\n",
      "0:00:04 | Epoch: 302/500 | train Loss: 0.001818 | EVM: 3.994\n",
      "0:00:03 | Epoch: 303/500 | train Loss: 0.001583 | EVM: 3.735\n",
      "0:00:03 | Epoch: 304/500 | train Loss: 0.001374 | EVM: 3.459\n",
      "0:00:04 | Epoch: 305/500 | train Loss: 0.001854 | EVM: 4.056\n",
      "0:00:04 | Epoch: 306/500 | train Loss: 0.00256 | EVM: 4.715\n",
      "0:00:03 | Epoch: 307/500 | train Loss: 0.002377 | EVM: 4.549\n",
      "0:00:03 | Epoch: 308/500 | train Loss: 0.002031 | EVM: 4.194\n",
      "0:00:04 | Epoch: 309/500 | train Loss: 0.00201 | EVM: 4.214\n",
      "0:00:03 | Epoch: 310/500 | train Loss: 0.001649 | EVM: 3.796\n",
      "0:00:04 | Epoch: 311/500 | train Loss: 0.001527 | EVM: 3.621\n",
      "0:00:03 | Epoch: 312/500 | train Loss: 0.001249 | EVM: 3.288\n",
      "0:00:03 | Epoch: 313/500 | train Loss: 0.001266 | EVM: 3.354\n",
      "0:00:04 | Epoch: 314/500 | train Loss: 0.001699 | EVM: 3.849\n",
      "0:00:04 | Epoch: 315/500 | train Loss: 0.002862 | EVM: 4.958\n",
      "0:00:04 | Epoch: 316/500 | train Loss: 0.002493 | EVM: 4.683\n",
      "0:00:03 | Epoch: 317/500 | train Loss: 0.001826 | EVM: 3.995\n",
      "0:00:04 | Epoch: 318/500 | train Loss: 0.001647 | EVM: 3.823\n",
      "0:00:03 | Epoch: 319/500 | train Loss: 0.001505 | EVM: 3.629\n",
      "0:00:03 | Epoch: 320/500 | train Loss: 0.001332 | EVM: 3.431\n",
      "0:00:03 | Epoch: 321/500 | train Loss: 0.001335 | EVM: 3.418\n",
      "0:00:03 | Epoch: 322/500 | train Loss: 0.00156 | EVM: 3.695\n",
      "0:00:04 | Epoch: 323/500 | train Loss: 0.001477 | EVM: 3.566\n",
      "0:00:04 | Epoch: 324/500 | train Loss: 0.001353 | EVM: 3.46\n",
      "0:00:04 | Epoch: 325/500 | train Loss: 0.001252 | EVM: 3.315\n",
      "0:00:04 | Epoch: 326/500 | train Loss: 0.00161 | EVM: 3.779\n",
      "0:00:03 | Epoch: 327/500 | train Loss: 0.001788 | EVM: 3.962\n",
      "0:00:03 | Epoch: 328/500 | train Loss: 0.001878 | EVM: 4.081\n",
      "0:00:03 | Epoch: 329/500 | train Loss: 0.001907 | EVM: 4.131\n",
      "0:00:03 | Epoch: 330/500 | train Loss: 0.002085 | EVM: 4.269\n",
      "0:00:04 | Epoch: 331/500 | train Loss: 0.001762 | EVM: 3.894\n",
      "0:00:04 | Epoch: 332/500 | train Loss: 0.001826 | EVM: 4.019\n",
      "0:00:03 | Epoch: 333/500 | train Loss: 0.001534 | EVM: 3.657\n",
      "0:00:04 | Epoch: 334/500 | train Loss: 0.001502 | EVM: 3.647\n",
      "0:00:03 | Epoch: 335/500 | train Loss: 0.001699 | EVM: 3.832\n",
      "0:00:04 | Epoch: 336/500 | train Loss: 0.001967 | EVM: 4.181\n",
      "0:00:03 | Epoch: 337/500 | train Loss: 0.001691 | EVM: 3.863\n",
      "0:00:03 | Epoch: 338/500 | train Loss: 0.001913 | EVM: 4.134\n",
      "0:00:04 | Epoch: 339/500 | train Loss: 0.002193 | EVM: 4.364\n",
      "0:00:04 | Epoch: 340/500 | train Loss: 0.00204 | EVM: 4.251\n",
      "0:00:04 | Epoch: 341/500 | train Loss: 0.001493 | EVM: 3.608\n",
      "0:00:03 | Epoch: 342/500 | train Loss: 0.001232 | EVM: 3.287\n",
      "0:00:03 | Epoch: 343/500 | train Loss: 0.001342 | EVM: 3.448\n",
      "0:00:03 | Epoch: 344/500 | train Loss: 0.001338 | EVM: 3.437\n",
      "0:00:03 | Epoch: 345/500 | train Loss: 0.001399 | EVM: 3.512\n",
      "0:00:03 | Epoch: 346/500 | train Loss: 0.001457 | EVM: 3.611\n",
      "0:00:03 | Epoch: 347/500 | train Loss: 0.002105 | EVM: 4.26\n",
      "0:00:04 | Epoch: 348/500 | train Loss: 0.002133 | EVM: 4.292\n",
      "0:00:04 | Epoch: 349/500 | train Loss: 0.001863 | EVM: 4.053\n",
      "0:00:04 | Epoch: 350/500 | train Loss: 0.001557 | EVM: 3.692\n",
      "0:00:03 | Epoch: 351/500 | train Loss: 0.001462 | EVM: 3.568\n",
      "0:00:04 | Epoch: 352/500 | train Loss: 0.001452 | EVM: 3.576\n",
      "0:00:04 | Epoch: 353/500 | train Loss: 0.001242 | EVM: 3.299\n",
      "0:00:04 | Epoch: 354/500 | train Loss: 0.001504 | EVM: 3.619\n",
      "0:00:04 | Epoch: 355/500 | train Loss: 0.001577 | EVM: 3.719\n",
      "0:00:04 | Epoch: 356/500 | train Loss: 0.001758 | EVM: 3.955\n",
      "0:00:03 | Epoch: 357/500 | train Loss: 0.002131 | EVM: 4.323\n",
      "0:00:03 | Epoch: 358/500 | train Loss: 0.002635 | EVM: 4.781\n",
      "0:00:03 | Epoch: 359/500 | train Loss: 0.001701 | EVM: 3.85\n",
      "0:00:03 | Epoch: 360/500 | train Loss: 0.001656 | EVM: 3.833\n",
      "0:00:04 | Epoch: 361/500 | train Loss: 0.001662 | EVM: 3.808\n",
      "0:00:04 | Epoch: 362/500 | train Loss: 0.001387 | EVM: 3.464\n",
      "0:00:03 | Epoch: 363/500 | train Loss: 0.00119 | EVM: 3.211\n",
      "0:00:03 | Epoch: 364/500 | train Loss: 0.001059 | EVM: 3.08\n",
      "0:00:04 | Epoch: 365/500 | train Loss: 0.001205 | EVM: 3.243\n",
      "0:00:04 | Epoch: 366/500 | train Loss: 0.001528 | EVM: 3.655\n",
      "0:00:04 | Epoch: 367/500 | train Loss: 0.001737 | EVM: 3.902\n",
      "0:00:03 | Epoch: 368/500 | train Loss: 0.001905 | EVM: 4.048\n",
      "0:00:04 | Epoch: 369/500 | train Loss: 0.001528 | EVM: 3.678\n",
      "0:00:03 | Epoch: 370/500 | train Loss: 0.001743 | EVM: 3.894\n",
      "0:00:04 | Epoch: 371/500 | train Loss: 0.001941 | EVM: 4.131\n",
      "0:00:04 | Epoch: 372/500 | train Loss: 0.001771 | EVM: 3.934\n",
      "0:00:03 | Epoch: 373/500 | train Loss: 0.001795 | EVM: 3.99\n",
      "0:00:04 | Epoch: 374/500 | train Loss: 0.001946 | EVM: 4.16\n",
      "0:00:03 | Epoch: 375/500 | train Loss: 0.002174 | EVM: 4.338\n",
      "0:00:04 | Epoch: 376/500 | train Loss: 0.00175 | EVM: 3.934\n",
      "0:00:03 | Epoch: 377/500 | train Loss: 0.001504 | EVM: 3.638\n",
      "0:00:03 | Epoch: 378/500 | train Loss: 0.001143 | EVM: 3.193\n",
      "0:00:04 | Epoch: 379/500 | train Loss: 0.001319 | EVM: 3.386\n",
      "0:00:04 | Epoch: 380/500 | train Loss: 0.001253 | EVM: 3.319\n",
      "0:00:04 | Epoch: 381/500 | train Loss: 0.001306 | EVM: 3.389\n",
      "0:00:04 | Epoch: 382/500 | train Loss: 0.001431 | EVM: 3.558\n",
      "0:00:03 | Epoch: 383/500 | train Loss: 0.001788 | EVM: 3.946\n",
      "0:00:04 | Epoch: 384/500 | train Loss: 0.002087 | EVM: 4.283\n",
      "0:00:03 | Epoch: 385/500 | train Loss: 0.001664 | EVM: 3.84\n",
      "0:00:04 | Epoch: 386/500 | train Loss: 0.001665 | EVM: 3.79\n",
      "0:00:04 | Epoch: 387/500 | train Loss: 0.001654 | EVM: 3.816\n",
      "0:00:03 | Epoch: 388/500 | train Loss: 0.001568 | EVM: 3.722\n",
      "0:00:03 | Epoch: 389/500 | train Loss: 0.001635 | EVM: 3.813\n",
      "0:00:03 | Epoch: 390/500 | train Loss: 0.001899 | EVM: 4.098\n",
      "0:00:03 | Epoch: 391/500 | train Loss: 0.001488 | EVM: 3.636\n",
      "0:00:03 | Epoch: 392/500 | train Loss: 0.001332 | EVM: 3.393\n",
      "0:00:04 | Epoch: 393/500 | train Loss: 0.001871 | EVM: 4.05\n",
      "0:00:04 | Epoch: 394/500 | train Loss: 0.001871 | EVM: 4.041\n",
      "0:00:04 | Epoch: 395/500 | train Loss: 0.00127 | EVM: 3.311\n",
      "0:00:03 | Epoch: 396/500 | train Loss: 0.001513 | EVM: 3.644\n",
      "0:00:04 | Epoch: 397/500 | train Loss: 0.001341 | EVM: 3.429\n",
      "0:00:04 | Epoch: 398/500 | train Loss: 0.001419 | EVM: 3.551\n",
      "0:00:03 | Epoch: 399/500 | train Loss: 0.001385 | EVM: 3.45\n",
      "0:00:03 | Epoch: 400/500 | train Loss: 0.001479 | EVM: 3.603\n",
      "0:00:03 | Epoch: 401/500 | train Loss: 0.00152 | EVM: 3.652\n",
      "0:00:03 | Epoch: 402/500 | train Loss: 0.002035 | EVM: 4.249\n",
      "0:00:03 | Epoch: 403/500 | train Loss: 0.001427 | EVM: 3.532\n",
      "0:00:03 | Epoch: 404/500 | train Loss: 0.00179 | EVM: 3.961\n",
      "0:00:03 | Epoch: 405/500 | train Loss: 0.001627 | EVM: 3.782\n",
      "0:00:03 | Epoch: 406/500 | train Loss: 0.001591 | EVM: 3.735\n",
      "0:00:03 | Epoch: 407/500 | train Loss: 0.001343 | EVM: 3.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04 | Epoch: 408/500 | train Loss: 0.001282 | EVM: 3.351\n",
      "0:00:03 | Epoch: 409/500 | train Loss: 0.001741 | EVM: 3.925\n",
      "0:00:03 | Epoch: 410/500 | train Loss: 0.001354 | EVM: 3.459\n",
      "0:00:03 | Epoch: 411/500 | train Loss: 0.0014 | EVM: 3.457\n",
      "0:00:03 | Epoch: 412/500 | train Loss: 0.001562 | EVM: 3.668\n",
      "0:00:04 | Epoch: 413/500 | train Loss: 0.001172 | EVM: 3.215\n",
      "0:00:04 | Epoch: 414/500 | train Loss: 0.001572 | EVM: 3.694\n",
      "0:00:03 | Epoch: 415/500 | train Loss: 0.00172 | EVM: 3.869\n",
      "0:00:03 | Epoch: 416/500 | train Loss: 0.001592 | EVM: 3.754\n",
      "0:00:03 | Epoch: 417/500 | train Loss: 0.001467 | EVM: 3.572\n",
      "0:00:04 | Epoch: 418/500 | train Loss: 0.00192 | EVM: 4.059\n",
      "0:00:03 | Epoch: 419/500 | train Loss: 0.001387 | EVM: 3.472\n",
      "0:00:03 | Epoch: 420/500 | train Loss: 0.00117 | EVM: 3.231\n",
      "0:00:04 | Epoch: 421/500 | train Loss: 0.001447 | EVM: 3.554\n",
      "0:00:03 | Epoch: 422/500 | train Loss: 0.001485 | EVM: 3.592\n",
      "0:00:04 | Epoch: 423/500 | train Loss: 0.001261 | EVM: 3.323\n",
      "0:00:04 | Epoch: 424/500 | train Loss: 0.001385 | EVM: 3.464\n",
      "0:00:03 | Epoch: 425/500 | train Loss: 0.001314 | EVM: 3.419\n",
      "0:00:04 | Epoch: 426/500 | train Loss: 0.001436 | EVM: 3.569\n",
      "0:00:03 | Epoch: 427/500 | train Loss: 0.001498 | EVM: 3.622\n",
      "0:00:04 | Epoch: 428/500 | train Loss: 0.001591 | EVM: 3.736\n",
      "0:00:03 | Epoch: 429/500 | train Loss: 0.001727 | EVM: 3.892\n",
      "0:00:03 | Epoch: 430/500 | train Loss: 0.001655 | EVM: 3.79\n",
      "0:00:03 | Epoch: 431/500 | train Loss: 0.001719 | EVM: 3.866\n",
      "0:00:03 | Epoch: 432/500 | train Loss: 0.001854 | EVM: 3.996\n",
      "0:00:03 | Epoch: 433/500 | train Loss: 0.001563 | EVM: 3.708\n",
      "0:00:03 | Epoch: 434/500 | train Loss: 0.001613 | EVM: 3.739\n",
      "0:00:03 | Epoch: 435/500 | train Loss: 0.001438 | EVM: 3.57\n",
      "0:00:04 | Epoch: 436/500 | train Loss: 0.001716 | EVM: 3.902\n",
      "0:00:03 | Epoch: 437/500 | train Loss: 0.001572 | EVM: 3.7\n",
      "0:00:04 | Epoch: 438/500 | train Loss: 0.001208 | EVM: 3.263\n",
      "0:00:03 | Epoch: 439/500 | train Loss: 0.001427 | EVM: 3.52\n",
      "0:00:03 | Epoch: 440/500 | train Loss: 0.00237 | EVM: 4.547\n",
      "0:00:04 | Epoch: 441/500 | train Loss: 0.001917 | EVM: 4.103\n",
      "0:00:04 | Epoch: 442/500 | train Loss: 0.001426 | EVM: 3.562\n",
      "0:00:04 | Epoch: 443/500 | train Loss: 0.001133 | EVM: 3.16\n",
      "0:00:03 | Epoch: 444/500 | train Loss: 0.001226 | EVM: 3.257\n",
      "0:00:04 | Epoch: 445/500 | train Loss: 0.001349 | EVM: 3.404\n",
      "0:00:03 | Epoch: 446/500 | train Loss: 0.001199 | EVM: 3.277\n",
      "0:00:03 | Epoch: 447/500 | train Loss: 0.00117 | EVM: 3.221\n",
      "0:00:03 | Epoch: 448/500 | train Loss: 0.001476 | EVM: 3.597\n",
      "0:00:04 | Epoch: 449/500 | train Loss: 0.001429 | EVM: 3.532\n",
      "0:00:03 | Epoch: 450/500 | train Loss: 0.001391 | EVM: 3.475\n",
      "0:00:03 | Epoch: 451/500 | train Loss: 0.001983 | EVM: 4.149\n",
      "0:00:03 | Epoch: 452/500 | train Loss: 0.001793 | EVM: 3.944\n",
      "0:00:04 | Epoch: 453/500 | train Loss: 0.001365 | EVM: 3.456\n",
      "0:00:03 | Epoch: 454/500 | train Loss: 0.001324 | EVM: 3.426\n",
      "0:00:03 | Epoch: 455/500 | train Loss: 0.001408 | EVM: 3.52\n",
      "0:00:04 | Epoch: 456/500 | train Loss: 0.001552 | EVM: 3.687\n",
      "0:00:03 | Epoch: 457/500 | train Loss: 0.001646 | EVM: 3.808\n",
      "0:00:03 | Epoch: 458/500 | train Loss: 0.001619 | EVM: 3.738\n",
      "0:00:03 | Epoch: 459/500 | train Loss: 0.001307 | EVM: 3.419\n",
      "0:00:04 | Epoch: 460/500 | train Loss: 0.001286 | EVM: 3.346\n",
      "0:00:03 | Epoch: 461/500 | train Loss: 0.001156 | EVM: 3.184\n",
      "0:00:04 | Epoch: 462/500 | train Loss: 0.001261 | EVM: 3.336\n",
      "0:00:04 | Epoch: 463/500 | train Loss: 0.001271 | EVM: 3.343\n",
      "0:00:03 | Epoch: 464/500 | train Loss: 0.001366 | EVM: 3.47\n",
      "0:00:03 | Epoch: 465/500 | train Loss: 0.001662 | EVM: 3.834\n",
      "0:00:04 | Epoch: 466/500 | train Loss: 0.001629 | EVM: 3.791\n",
      "0:00:04 | Epoch: 467/500 | train Loss: 0.001758 | EVM: 3.929\n",
      "0:00:03 | Epoch: 468/500 | train Loss: 0.001836 | EVM: 4.011\n",
      "0:00:03 | Epoch: 469/500 | train Loss: 0.002065 | EVM: 4.283\n",
      "0:00:04 | Epoch: 470/500 | train Loss: 0.001296 | EVM: 3.387\n",
      "0:00:03 | Epoch: 471/500 | train Loss: 0.001373 | EVM: 3.516\n",
      "0:00:03 | Epoch: 472/500 | train Loss: 0.000985 | EVM: 2.929\n",
      "0:00:04 | Epoch: 473/500 | train Loss: 0.001176 | EVM: 3.223\n",
      "0:00:03 | Epoch: 474/500 | train Loss: 0.001135 | EVM: 3.172\n",
      "0:00:03 | Epoch: 475/500 | train Loss: 0.001583 | EVM: 3.704\n",
      "0:00:04 | Epoch: 476/500 | train Loss: 0.001368 | EVM: 3.453\n",
      "0:00:04 | Epoch: 477/500 | train Loss: 0.001835 | EVM: 3.993\n",
      "0:00:03 | Epoch: 478/500 | train Loss: 0.001541 | EVM: 3.66\n",
      "0:00:03 | Epoch: 479/500 | train Loss: 0.001267 | EVM: 3.347\n",
      "0:00:03 | Epoch: 480/500 | train Loss: 0.001573 | EVM: 3.711\n",
      "0:00:03 | Epoch: 481/500 | train Loss: 0.001452 | EVM: 3.571\n",
      "0:00:03 | Epoch: 482/500 | train Loss: 0.00147 | EVM: 3.6\n",
      "0:00:03 | Epoch: 483/500 | train Loss: 0.001219 | EVM: 3.253\n",
      "0:00:03 | Epoch: 484/500 | train Loss: 0.001508 | EVM: 3.626\n",
      "0:00:03 | Epoch: 485/500 | train Loss: 0.001552 | EVM: 3.693\n",
      "0:00:03 | Epoch: 486/500 | train Loss: 0.001387 | EVM: 3.491\n",
      "0:00:03 | Epoch: 487/500 | train Loss: 0.001092 | EVM: 3.097\n",
      "0:00:03 | Epoch: 488/500 | train Loss: 0.001079 | EVM: 3.067\n",
      "0:00:04 | Epoch: 489/500 | train Loss: 0.001057 | EVM: 3.05\n",
      "0:00:04 | Epoch: 490/500 | train Loss: 0.001271 | EVM: 3.341\n",
      "0:00:04 | Epoch: 491/500 | train Loss: 0.001392 | EVM: 3.499\n",
      "0:00:03 | Epoch: 492/500 | train Loss: 0.001114 | EVM: 3.125\n",
      "0:00:04 | Epoch: 493/500 | train Loss: 0.00146 | EVM: 3.62\n",
      "0:00:04 | Epoch: 494/500 | train Loss: 0.001619 | EVM: 3.783\n",
      "0:00:04 | Epoch: 495/500 | train Loss: 0.001488 | EVM: 3.638\n",
      "0:00:03 | Epoch: 496/500 | train Loss: 0.001474 | EVM: 3.592\n",
      "0:00:03 | Epoch: 497/500 | train Loss: 0.001348 | EVM: 3.431\n",
      "0:00:04 | Epoch: 498/500 | train Loss: 0.001579 | EVM: 3.713\n",
      "0:00:04 | Epoch: 499/500 | train Loss: 0.001682 | EVM: 3.865\n",
      "0:00:04 | Epoch: 500/500 | train Loss: 0.001542 | EVM: 3.684\n"
     ]
    }
   ],
   "source": [
    "model_info = {'linear_compensation': True,\n",
    "                          'sampling': 4,\n",
    "                          'batch_size': 100,\n",
    "                          'neuron': 320,\n",
    "                          'epochs': 500,\n",
    "                          'lr': 0.001,\n",
    "                          'activation': 'ReLU',\n",
    "                          'form': 'RZ16QAM',\n",
    "                          'Lmax': 2500}\n",
    "\n",
    "signal_info_random = {'signal_type': 'random',\n",
    "                                         'seed': '1234',\n",
    "                                         'bit_num': 50000}\n",
    "\n",
    "signal_info_image0 = {'signal_type': 'image',\n",
    "                                     'target_dir': 'train_0',\n",
    "                                     'step': 60,\n",
    "                                     'image_number': '0, 1, 2, 3, 4, 5, 6, 7, 8, 9',\n",
    "                                     'ebtb': True}\n",
    "\n",
    "signal_info_image1 = {'signal_type': 'image',\n",
    "                                     'target_dir': 'train_0',\n",
    "                                     'step': 60,\n",
    "                                     'image_number': '0, 5, 6, 12, 17, 33, 35, 45, 52, 53',\n",
    "                                     'ebtb': True}\n",
    "\n",
    "signal_info_image2 = {'signal_type': 'image',\n",
    "                                     'target_dir': 'train_0',\n",
    "                                     'step': 60,\n",
    "                                     'image_number': '0, 5, 6, 12, 17, 33, 35, 45, 52, 53, 174, 195, 198, 254, 255, 319, 341, 433, 439, 442, 451, 484, 535, 576, 582, 616, 640, 654, 670, 724, 747, 750, 771, 823, 825, 832, 870, 877, 902, 955, 974, 982, 1038, 1077, 1167, 1202, 1204, 1214, 1302, 1361, 1393, 1422, 1437, 1441, 1578, 1621, 1674, 1685, 1762, 1769, 1790, 1814, 1845, 1899, 1900, 1937, 1945, 1962, 2025, 2184, 2191, 2196, 2270, 2276, 2286, 2345, 2348, 2360, 2371, 2375, 2394, 2428, 2446, 2459, 2465, 2474, 2478, 2506, 2523, 2549, 2568, 2594, 2602, 2642, 2648, 2668, 2676, 2696, 2707, 2724',\n",
    "                                     'ebtb': True}\n",
    "\n",
    "for tap in [25]:\n",
    "    train_ann_with_save(model_info, signal_info_image1, tap, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
