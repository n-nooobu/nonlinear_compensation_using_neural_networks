{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3層ANNによる非線形歪補償\n",
    "最も基本的な、入力層・中間層・出力層からなる3層ANNによる補償"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "sys.path.append('../')\n",
    "from pyopt.util import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 データの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shaping(input_signal, signal, sampling, tap, max_tap, n):\n",
    "    \"\"\"\n",
    "    input_signal: 伝送前の信号\n",
    "    signal: 伝送後の信号\n",
    "    max_tap: 最大の同時入力シンボル数\n",
    "    tap: 同時入力シンボル数\n",
    "    \n",
    "    signal = [x_0, x_1, ... , x_(n-1)]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[x_0, x_1, ... , x_tap-1],\n",
    "            [x_1, x_2, ..., x_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [x_(n-tap), x_(n-tap+1), ..., x(n-1)]]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[i_0, q_0, i_1, q_1, ... , i_(tap-1), q_(tap-1)],\n",
    "            [i_1, q_1, i_2, q_2, ... , i_tap, q_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [i_(n-tap), q_(n-tap), i_(n-tap+1), q_(n-tap+1), ..., i_(n-1), q_(n-1)]] (batch, input_dim) input_dim = tap * 2\n",
    "    \n",
    "    y  (batch, output_dim) output_dim = 2\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.zeros((len(input_signal) // n - (max_tap - 1), sampling * tap * 2), dtype=float)\n",
    "    y = np.zeros((len(input_signal) // n - (max_tap - 1), 2), dtype=float)\n",
    "    if sampling == 1:\n",
    "        for i, center in enumerate(range(max_tap // 2, len(input_signal) // n - max_tap // 2)):\n",
    "            for j, symbol in enumerate(range(tap)):\n",
    "                x[i, j * 2] = signal[n * (center - tap // 2 + j) + n // 2].real\n",
    "                x[i, j * 2 + 1] = signal[n * (center - tap // 2 + j) + n // 2].imag\n",
    "            y[i, 0] = input_signal[n // 2 + n * center].real\n",
    "            y[i, 1] = input_signal[n // 2 + n * center].imag\n",
    "    else:\n",
    "        for i, center in enumerate(range(max_tap // 2, len(input_signal) // n - max_tap // 2)):\n",
    "            for j, symbol in enumerate(range(tap)):\n",
    "                for k, sample in enumerate([round(_ * n / sampling) for _ in range(sampling)]):\n",
    "                    x[i, j * sampling * 2 + k * 2] = signal[n * (center - tap // 2 + j) + sample].real\n",
    "                    x[i, j * sampling * 2 + k * 2 + 1] = signal[n * (center - tap // 2 + j) + sample].imag\n",
    "            y[i, 0] = input_signal[n // 2 + n * center].real\n",
    "            y[i, 1] = input_signal[n // 2 + n * center].imag\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size:  (1548, 306)\n",
      "y size:  (1548, 2)\n",
      "[ 3.32045355e+02 -2.75519561e+02  4.60798224e+04 -4.66110424e+04\n",
      "  4.21489600e+04 -4.67112229e+04 -2.32276054e+03  3.07608289e+03\n",
      " -4.51780310e+04 -3.78998500e+04 -4.76122063e+04 -4.59213781e+04\n",
      " -4.30312746e+03  5.16168853e+02 -4.71965222e+04  5.23620751e+04\n",
      " -4.90156310e+04  4.78102035e+04 -2.11024062e+03 -1.27503787e+03\n",
      "  3.04625620e+04  7.02327156e+03  3.32956474e+04  4.77377947e+03\n",
      " -5.24451737e+02 -3.21177869e+03 -4.58767073e+04  4.41633798e+04\n",
      " -4.02995504e+04  4.46267546e+04  3.18925268e+03 -2.47473771e+02\n",
      " -8.17551172e+04 -2.76568296e+04 -8.44275255e+04 -2.73195821e+04\n",
      " -1.24965302e+01  6.39903865e+02  6.71308196e+04 -1.32647465e+04\n",
      "  6.34534868e+04 -1.13760122e+04  1.77276951e+03 -1.29113052e+03\n",
      "  1.22564189e+04  6.37524278e+04  1.17292734e+04  6.21289954e+04\n",
      "  3.36816206e+02  1.70855464e+02  9.66458066e+03  7.04518322e+04\n",
      "  8.50997421e+03  6.33176591e+04  4.41145849e+02  3.15510735e+03\n",
      " -2.46742537e+04 -7.34993019e+03 -2.48112644e+04 -1.03964673e+04\n",
      " -3.90033822e+03 -7.21752961e+02 -1.08389738e+04 -6.65034997e+04\n",
      " -8.87908216e+03 -6.73213119e+04  7.13816855e+00  3.42239998e+02\n",
      " -4.70250927e+04 -4.49640606e+04 -4.61192789e+04 -4.16110950e+04\n",
      "  4.72988212e+03  1.24523425e+03  2.42318744e+04 -8.18089954e+04\n",
      "  2.85358275e+04 -8.20175530e+04 -9.90552350e+02  1.95030006e+03\n",
      "  5.81079575e+03  6.39442604e+04  1.15286728e+04  6.08774830e+04\n",
      " -4.84180117e+02  2.28750490e+03  8.37920873e+04  2.81499650e+04\n",
      "  8.39637993e+04  3.10408525e+04 -1.86027119e+02 -1.35211075e+03\n",
      " -4.08047219e+04 -4.50303954e+04 -4.55120486e+04 -4.68882816e+04\n",
      "  2.13356392e+03  1.54401100e+03  9.15253451e+03 -2.44307766e+04\n",
      "  1.08443820e+04 -2.59165815e+04  2.57089816e+02  1.24604373e+03\n",
      "  2.48185541e+04  8.99318015e+03  2.93637504e+04  9.12224959e+03\n",
      " -7.54156886e+02  6.81946289e+03  6.90808136e+03 -2.75577469e+04\n",
      "  5.32146609e+03 -2.82429774e+04 -1.24658647e+03 -1.80191779e+03\n",
      "  2.31189220e+04 -8.13105073e+04  2.53777360e+04 -8.09490811e+04\n",
      " -1.73290221e+03 -1.25002230e+03  8.81998222e+03 -3.28764374e+04\n",
      "  9.21176409e+03 -2.54999676e+04 -2.61977059e+03  8.04075691e+02\n",
      "  2.59479479e+04 -7.96862434e+04  2.92836347e+04 -8.11292489e+04\n",
      " -1.71236369e+03  3.01779520e+03 -4.73710004e+04 -4.96109932e+04\n",
      " -5.14265785e+04 -5.08166866e+04  1.12386576e+03 -2.57368574e+03\n",
      "  2.60916536e+04  9.12311796e+03  2.53540058e+04  6.42796615e+03\n",
      "  4.14075379e+02 -1.17365426e+03 -1.27604725e+04  2.71874921e+04\n",
      " -1.05661874e+04  2.78303741e+04  2.33268189e+03  2.04412925e+03\n",
      "  8.66132113e+04  2.69695552e+04  8.45211186e+04  2.54157516e+04\n",
      " -5.49166818e+02 -4.18430513e+03 -2.15459032e+04  8.30796044e+04\n",
      " -2.51084508e+04  8.28115994e+04 -2.84551899e+02  4.28974779e+03\n",
      " -4.52587627e+04  4.99250802e+04 -4.36806033e+04  4.95340150e+04\n",
      "  3.68851072e+01  2.83131697e+03 -2.64332603e+04 -7.54420913e+03\n",
      " -2.56205808e+04 -7.66280302e+03 -1.63458715e+03  1.62010934e+03\n",
      " -7.99683475e+04 -2.85498791e+04 -8.11733306e+04 -2.87000030e+04\n",
      "  2.03796042e+03  1.96356657e+03  2.84244832e+04  1.01544884e+04\n",
      "  2.71645653e+04  6.74953727e+03  1.38525154e+02  1.65878737e+03\n",
      "  2.46323137e+04  8.38549236e+03  2.60056369e+04  6.06721551e+03\n",
      " -1.57056096e+03  4.33145091e+03  5.10403416e+04  4.55674755e+04\n",
      "  4.75064913e+04  4.51240854e+04  8.82823223e+02 -1.59336889e+03\n",
      " -8.72997849e+04 -2.51665311e+04 -8.27454183e+04 -2.42123908e+04\n",
      "  1.86080521e+03  3.51768050e+03 -3.12697592e+04 -8.12374471e+03\n",
      " -2.76794579e+04 -1.10031487e+04  1.42643104e+03  5.56680656e+02\n",
      "  6.66141424e+04 -9.28668407e+03  6.11534402e+04 -1.14722715e+04\n",
      "  2.00570338e+02 -9.41969756e+02 -4.65144029e+04  4.47745086e+04\n",
      " -4.85917645e+04  4.26519018e+04  2.52279079e+03  1.62726184e+03\n",
      "  8.29489918e+04  2.82133674e+04  7.92664570e+04  2.73878092e+04\n",
      " -1.08447167e+03 -6.76918971e+02 -6.36115951e+04  8.03251456e+03\n",
      " -6.27420834e+04  1.41194012e+04  1.21654336e+03 -2.16447136e+03\n",
      " -6.79322395e+04  1.12138359e+04 -6.23313950e+04  6.40062510e+03\n",
      " -1.04825888e+03 -1.43596659e+03  6.16675499e+04 -9.94075807e+03\n",
      "  6.19866212e+04 -1.18299655e+04 -3.72250372e+03 -5.37954712e+02\n",
      " -8.30669465e+04 -2.40051258e+04 -7.98169225e+04 -2.63163393e+04\n",
      "  1.59971195e+02  9.73601992e+01 -1.03180678e+04  3.03623751e+04\n",
      " -1.08704334e+04  2.64513244e+04 -9.04078604e+02  5.35702446e+02\n",
      " -2.81105310e+04 -1.22749974e+04 -3.20849262e+04 -1.10112739e+04\n",
      " -1.33610755e+02 -1.12192167e+03  5.09700623e+04 -4.76953327e+04\n",
      "  4.67810827e+04 -4.41862359e+04 -3.99368400e+03  3.42150923e+03\n",
      "  6.46803856e+04 -9.19397202e+03  6.38207511e+04 -1.12047091e+04\n",
      "  6.23366351e+02 -5.57269505e+02 -2.38260144e+04  8.31586738e+04\n",
      " -2.52584837e+04  8.30293409e+04  1.55241712e+03 -1.98538335e+03\n",
      " -6.85660051e+04  1.08056785e+04 -6.50783081e+04  1.27607210e+04\n",
      " -3.46964956e+02 -1.43479685e+03 -1.07954779e+04  3.20283639e+04\n",
      " -1.14392804e+04  3.13400136e+04  2.31624369e+03 -1.38730458e+03\n",
      "  4.68354965e+04  4.37590223e+04  4.53304681e+04  4.43524221e+04\n",
      "  7.60731373e+02  3.06697784e+03 -8.18468950e+03 -6.90333435e+04\n",
      " -1.10430112e+04 -6.87647114e+04]\n",
      "[70474.95606832 70474.95606832]\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "sampling = 3\n",
    "tap = 51\n",
    "max_tap = 501\n",
    "\n",
    "df_dir = '../data/input/prbs.csv'\n",
    "df = pd.read_csv(df_dir, index_col=0)  # dataframe読み込み\n",
    "condition = (df['N']==13) & (df['itr']==1) & (df['form']=='RZ16QAM') & (df['n']==32) & (df['equalize']==False) & (df['baudrate']==28) & (df['PdBm']==1)\n",
    "sgnl = load_pickle(df[condition].iloc[0]['data_path'])  # dataframeから条件と合う行を取得し,pickleの保存先(data_path)にアクセス\n",
    "lc = sgnl.linear_compensation(500, sgnl.signal['x_500'])\n",
    "x, y = data_shaping(sgnl.signal['x_0'], lc, sampling, tap, max_tap, 32)  # ANNに入力できるようにデータを整形\n",
    "\n",
    "print('x size: ', x.shape)\n",
    "print('y size: ', y.shape)\n",
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 平均,標準偏差の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  1053.2765739234778\n",
      "std:  45950.91990246874\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "\n",
    "print('mean: ', mean)\n",
    "print('std: ', std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, mean, std):\n",
    "        self.x, self.y, self.mean, self.std = x, y, mean, std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        x = (x - self.mean) / self.std\n",
    "        y = (y - self.mean) / self.std\n",
    "        return torch.Tensor(x), torch.Tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  0.03935981\n",
      "std:  0.9990706\n",
      "tensor([ 0.1744, -0.6305,  0.2542, -0.6643,  0.1498, -0.5816,  0.0621, -0.5425,\n",
      "         0.0989, -0.6737,  0.2707, -0.7228,  0.5879, -1.8054,  0.5348, -1.8017,\n",
      "         1.4744, -0.2758,  1.3161, -0.2410,  1.7203,  0.5624,  1.7064,  0.5428,\n",
      "        -0.6141, -0.2306, -0.6262, -0.2575,  1.8602,  0.5342,  1.7956,  0.5487,\n",
      "        -0.6887,  1.8563, -0.6805,  1.8318,  1.7734,  0.5692,  1.8469,  0.4622,\n",
      "         0.1909, -0.5909,  0.1415, -0.5378,  1.0256, -1.0119,  0.9728, -1.0440,\n",
      "        -0.6777,  1.8656, -0.6665,  1.8169, -0.6359,  1.8979, -0.5313,  1.8349,\n",
      "         0.6288,  0.2404,  0.5757,  0.2335,  0.0350,  1.3691,  0.1842,  1.3636,\n",
      "         0.5889,  0.1623,  0.4928,  0.1936, -1.5795,  0.1956, -1.4978,  0.2328,\n",
      "        -1.4946,  0.1612, -1.4766,  0.1482,  1.3541, -0.1792,  1.3138, -0.2410,\n",
      "         0.6693,  0.0918,  0.5981,  0.1094,  0.1877, -0.6334,  0.1373, -0.6857,\n",
      "         0.1281, -0.7059,  0.1780, -0.6310, -1.4345,  0.1194, -1.4554,  0.1487,\n",
      "        -1.0567,  0.9861, -1.0175,  0.9582, -1.0534,  1.0651, -0.9946,  0.8584,\n",
      "         0.6258, -1.8519,  0.5814, -1.8388, -0.3147,  0.5872, -0.3128,  0.6085,\n",
      "        -0.9721,  0.9487, -0.9926,  1.0160, -0.2349, -1.4616, -0.2106, -1.4232,\n",
      "        -0.1222,  0.6249, -0.3570,  0.5721, -0.9767,  1.0222, -0.9368,  0.8951,\n",
      "        -1.8920, -0.6365, -1.8180, -0.6650, -0.9942,  0.9424, -1.0756,  0.9713,\n",
      "        -1.3181,  0.2100, -1.3924,  0.2597,  1.8347,  0.5703,  1.8313,  0.5678,\n",
      "         0.9322, -0.9259,  0.9901, -1.0064, -1.8963, -0.6826, -1.6828, -0.6674,\n",
      "        -0.6219, -0.3288, -0.6863, -0.2532,  0.1582, -0.6396,  0.1476, -0.6192,\n",
      "         1.0003,  0.9253,  1.0361,  0.9888, -1.4005,  0.1922, -1.4542,  0.1440,\n",
      "        -0.0970, -1.4383, -0.1806, -1.5318, -0.1594, -1.4511, -0.2324, -1.3888,\n",
      "        -0.9514,  1.0526, -0.9514,  0.9613,  1.0373,  0.9032,  1.0107,  0.9216,\n",
      "        -1.0290, -0.9567, -1.0048, -1.0088, -0.5480,  1.8265, -0.6128,  1.8537,\n",
      "         0.2205,  1.4553,  0.2521,  1.3858,  1.3612, -0.1437,  1.3794, -0.1965,\n",
      "         1.7403,  0.4873,  1.7683,  0.6537])\n",
      "tensor([-1.5566,  0.4883])\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "\n",
    "index = 0\n",
    "x_normalized, y_normalized = train_dataset.__getitem__(index)\n",
    "x_array = x_normalized.detach().numpy()\n",
    "\n",
    "print('mean: ', np.mean(x_array))\n",
    "print('std: ', np.std(x_array))\n",
    "print(x_normalized)\n",
    "print(y_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_neuron, activation):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_neuron)\n",
    "        self.fc2 = nn.Linear(hidden_neuron, output_dim)\n",
    "        if activation == 'ReLU':\n",
    "            self.activation = F.relu\n",
    "        elif activation == 'Sigmoid':\n",
    "            self.activation = torch.sigmoid\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "torch.Size([100, 204])\n",
      "tensor([[-0.0459,  0.0695],\n",
      "        [ 0.0309, -0.0350],\n",
      "        [-0.0725,  0.1273],\n",
      "        [-0.0221,  0.0749],\n",
      "        [-0.1046,  0.1126],\n",
      "        [-0.0534,  0.1939]], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "hidden_neuron = 300\n",
    "activation = 'Sigmoid'\n",
    "device = torch.device('cpu') # 'cuda' if torch.cuda.is_available() else \n",
    "print('Device available now:', device)\n",
    "\n",
    "model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=hidden_neuron, activation=activation).to(device)\n",
    "for x, y in train_dataloader:\n",
    "    print(x.shape)\n",
    "    output = model(x)\n",
    "    print(output[:6])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evm_score(y_pred, y_true):\n",
    "    tmp = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        tmp += ((y_pred[i][0] - y_true[i][0]) ** 2 + (y_pred[i][1] - y_true[i][1]) ** 2) / (y_true[i][0] ** 2 + y_true[i][1] ** 2)\n",
    "    evm = torch.sqrt(tmp / len(y_pred))\n",
    "    return evm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, model, dataloaders_dict, criterion, optimizer, epochs, epochs_section=None):\n",
    "    \"\"\"\n",
    "    epochs_section: [start_epoch, end_epoch]\n",
    "    \"\"\"\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        if epochs_section is not None:\n",
    "            epoch += epochs_section[0]\n",
    "            end_epoch = epochs_section[1]\n",
    "        else:\n",
    "            end_epoch = epochs\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for phase in dataloaders_dict.keys():\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_evms = 0.0\n",
    "            \n",
    "            for x, y in dataloaders_dict[phase]:\n",
    "                x = x.to(device)\n",
    "                y = y.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(x)\n",
    "                    loss = criterion(outputs, y)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item() * x.size(0)\n",
    "                    epoch_evms += (evm_score(outputs, y)) ** 2 * x.size(0)\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_evm = torch.sqrt(epoch_evms / len(dataloaders_dict[phase].dataset)) * 100\n",
    "            \n",
    "            duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "            print('{} | Epoch: {}/{} | {} Loss: {:.4} | EVM: {:.4}'.format(duration, epoch + 1, end_epoch, phase, epoch_loss, epoch_evm))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 | Epoch: 1/5 | train Loss: 0.9742 | EVM: 99.0\n",
      "0:00:00 | Epoch: 2/5 | train Loss: 0.8474 | EVM: 92.44\n",
      "0:00:00 | Epoch: 3/5 | train Loss: 0.733 | EVM: 86.64\n",
      "0:00:00 | Epoch: 4/5 | train Loss: 0.6156 | EVM: 79.79\n",
      "0:00:00 | Epoch: 5/5 | train Loss: 0.4839 | EVM: 71.19\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    if signal_info['signal_type'] == 'prbs':\n",
    "        return load_prbs(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    elif signal_info['signal_type'] == 'random':\n",
    "        return load_random(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    elif signal_info['signal_type'] == 'image':\n",
    "        return load_image(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prbs(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    N = signal_info['N']\n",
    "    itr = signal_info['itr']\n",
    "    signal_condition = 'N=='+str(N)+'&itr=='+str(itr)\n",
    "    signal_list = [N, itr] + [None] * 6\n",
    "    \n",
    "    # prbs.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'prbs.csv', index_col=0)\n",
    "    \n",
    "    # prbs.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "    t_query = t_df.query(signal_condition + '&' + trans_condition)\n",
    "    \n",
    "    # if prbs.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "    if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "        print('指定された伝送条件の信号が存在しません')\n",
    "        return\n",
    "    else:\n",
    "        # 伝送信号を学習データに整形する\n",
    "        sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "        if lc:\n",
    "            sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "        else:\n",
    "            sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "        x, y = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "        return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    seed = signal_info['seed']\n",
    "    bit_num = signal_info['bit_num']\n",
    "    signal_condition = 'seed=='+str(seed)+'&bit_num=='+str(bit_num)\n",
    "    signal_list = [None] * 2 + [seed, bit_num] + [None] * 4\n",
    "    \n",
    "    # random.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'random.csv', index_col=0)\n",
    "    \n",
    "    # random.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "    t_query = t_df.query(signal_condition + '&' + trans_condition)\n",
    "    \n",
    "    # if random.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "    if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "        print('指定された伝送条件の信号が存在しません')\n",
    "        return\n",
    "    else:\n",
    "        # 伝送信号を学習データに整形する\n",
    "        sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "        if lc:\n",
    "            sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "        else:\n",
    "            sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "        x, y = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "        return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    target_dir = signal_info['target_dir']\n",
    "    step = signal_info['step']\n",
    "    image_number = signal_info['image_number']\n",
    "    image_number_split = image_number.split(', ')\n",
    "    ebtb = signal_info['ebtb']\n",
    "    signal_condition = 'target_dir==\"'+str(target_dir)+'\"&step=='+str(step)+'&image_number==\"'+image_number+'\"&ebtb=='+str(ebtb)\n",
    "    signal_list = [None] * 4 + [target_dir, step, image_number, ebtb]\n",
    "    \n",
    "    # image.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'image.csv', index_col=0)\n",
    "    \n",
    "    x = None\n",
    "    y = None\n",
    "    for i in range(len(image_number_split)):\n",
    "        # image.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "        t_query = t_df.query('target_dir==\"'+str(target_dir)+'\"&step=='+str(step)+'&image_number=='+image_number_split[i]+'&ebtb=='+str(ebtb) + '&' + trans_condition)\n",
    "        \n",
    "        # if image.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "        if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "            print('指定された伝送条件の信号が存在しません')\n",
    "            return\n",
    "        else:\n",
    "            # 伝送信号を学習データに整形する\n",
    "            sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "            if lc:\n",
    "                sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "            else:\n",
    "                sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "            if len(sgnl.signal['x_0']) // n - (max_tap - 1) > 0:\n",
    "                x_tmp, y_tmp = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "            if x is None:\n",
    "                x = x_tmp\n",
    "                y = y_tmp\n",
    "            else:\n",
    "                x = np.concatenate([x, x_tmp])\n",
    "                y = np.concatenate([y, y_tmp])\n",
    "    return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(learn_condition, trans_condition, signal_condition, device, sampling, tap, neuron, epochs, activation, Lmax):\n",
    "    # if ANN.csv がある: pandasで読み込む if ANN.csvがない: 新しいDataFrameを作る\n",
    "    l_df_dir = '../data/params/ANN.csv'\n",
    "    if os.path.exists(l_df_dir):\n",
    "        l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "    else:\n",
    "        cols = ['linear_compensation', 'sampling', 'tap', 'max_tap', 'batch_size', 'neuron', 'epochs', 'learning_rate', 'activation', 'N', 'itr', 'seed', 'bit_num', 'target_dir', 'step', 'image_number', 'ebtb', 'form', 'n', 'equalize', 'baudrate', 'PdBm', 'Ledfa', 'stepedfa', 'gamma', 'D', 'Alpha', 'NF', 'Lmax', 'ase', 'params_path', 'train_samples']\n",
    "        l_df = pd.DataFrame(index=[], columns=cols)\n",
    "        l_df.to_csv(l_df_dir)\n",
    "\n",
    "    # ANN.csvにおいて、指定した条件を満たす行だけqueryとして抜き出す\n",
    "    l_query = l_df.query(learn_condition + '&' + signal_condition + '&' + trans_condition + '&Lmax=='+str(Lmax))\n",
    "    \n",
    "    #if epochsを含む指定された条件を満たす結果がある: 何もしない\n",
    "    if len(l_query) > 0 and l_query['epochs'].max() >= epochs:\n",
    "        print('指定された条件の学習結果はすでに存在します')\n",
    "        return None, None, None\n",
    "    else:\n",
    "        # if epochs以外の指定された条件を満たす結果がある: パラメータを読み込む if ない: 新しくモデルを作成する\n",
    "        if len(l_query) > 0:\n",
    "            index = l_query['epochs'].idxmax()\n",
    "            trained_epochs = l_query['epochs'][index]\n",
    "            model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=neuron, activation=activation).to(device)\n",
    "            model.load_state_dict(torch.load(l_query['params_path'][index]))\n",
    "        else:\n",
    "            trained_epochs = 0\n",
    "            model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=neuron, activation=activation).to(device)\n",
    "    return model, l_df_dir, trained_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果と条件を保存しない\n",
    "def train_ann(model_info, signal_info, tap, PdBm):\n",
    "    device = torch.device('cpu') #'cuda' if torch.cuda.is_available() else \n",
    "    print('Device available now:', device)\n",
    "    \n",
    "    lc = model_info['linear_compensation']\n",
    "    sampling = model_info['sampling']\n",
    "    #tap = model_info['tap']\n",
    "    batch_size = model_info['batch_size']\n",
    "    neuron = model_info['neuron']\n",
    "    epochs = model_info['epochs']\n",
    "    lr = model_info['lr']\n",
    "    activation = model_info['activation']\n",
    "    form = model_info['form']\n",
    "    #PdBm = model_info['PdBm']\n",
    "    Lmax = model_info['Lmax']\n",
    "\n",
    "    max_tap = 501\n",
    "    n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "    equalize = False  # 各シンボル数を均等にするか\n",
    "    baudrate = 28  # ボーレート[GBaud]\n",
    "    Ledfa = 100  # EDFAスパン[km]\n",
    "    stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "    gamma = 2.8  # 非線形係数[/W/km]\n",
    "    D = 16  # 分散パラメータ[ps/nm/km]\n",
    "    Alpha = 0.16  # 伝送損失[dB/km]\n",
    "    NF = 4  # ASE雑音指数[dB]\n",
    "    ase = True  # ASE雑音を考慮するか\n",
    "\n",
    "    # 指定した学習条件と伝送条件\n",
    "    trans_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                                    gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "\n",
    "    x, y, _, _ = load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    \n",
    "    # 平均,標準偏差の計算\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    \n",
    "    model = ANN(input_dim=sampling*tap*2, output_dim=2, hidden_neuron=neuron, activation=activation).to(device)\n",
    "\n",
    "    # dataset, dataloaderの作成\n",
    "    train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "    train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dataloaders_dict = {'train': train_dataloader}\n",
    "\n",
    "    # 損失関数, オプティマイザの作成\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "    # モデルのトレーニング\n",
    "    model = train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果と条件を../data/params/ANN.csvに保存する\n",
    "def train_ann_with_save(model_info, signal_info, tap, PdBm):\n",
    "    device = torch.device('cpu') #'cuda' if torch.cuda.is_available() else \n",
    "    print('Device available now:', device)\n",
    "    \n",
    "    lc = model_info['linear_compensation']\n",
    "    sampling = model_info['sampling']\n",
    "    #tap = model_info['tap']\n",
    "    batch_size = model_info['batch_size']\n",
    "    neuron = model_info['neuron']\n",
    "    epochs = model_info['epochs']\n",
    "    lr = model_info['lr']\n",
    "    activation = model_info['activation']\n",
    "    form = model_info['form']\n",
    "    #PdBm = model_info['PdBm']\n",
    "    Lmax = model_info['Lmax']\n",
    "    \n",
    "    max_tap = 501\n",
    "    n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "    equalize = False  # 各シンボル数を均等にするか\n",
    "    baudrate = 28  # ボーレート[GBaud]\n",
    "    Ledfa = 100  # EDFAスパン[km]\n",
    "    stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "    gamma = 2.8  # 非線形係数[/W/km]\n",
    "    D = 16  # 分散パラメータ[ps/nm/km]\n",
    "    Alpha = 0.16  # 伝送損失[dB/km]\n",
    "    NF = 4  # ASE雑音指数[dB]\n",
    "    ase = True  # ASE雑音を考慮するか\n",
    "\n",
    "    # 指定した学習条件と伝送条件\n",
    "    learn_condition = 'linear_compensation=='+str(lc)+'&sampling=='+str(sampling)+'&tap=='+str(tap)+'&max_tap=='+str(max_tap)+'&batch_size=='+str(batch_size)+'&neuron=='+str(neuron)+'&learning_rate=='+str(lr)+'&activation==\"'+str(activation)+'\"'\n",
    "    trans_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                                    gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "    \n",
    "    x, y, signal_condition, signal_list = load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    if x is not None:\n",
    "        model, l_df_dir, trained_epochs = load_model(learn_condition, trans_condition, signal_condition, device, sampling, tap, neuron, epochs, activation, Lmax)\n",
    "        \n",
    "        if model is not None:\n",
    "            train_samples = len(x)\n",
    "    \n",
    "            # 平均,標準偏差の計算\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            \n",
    "            # dataset, dataloaderの作成\n",
    "            train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "            train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            dataloaders_dict = {'train': train_dataloader}\n",
    "\n",
    "            # 損失関数, オプティマイザの作成\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "            # モデルのトレーニング(50epochsずつ学習し、50epochsずつパラメータを保存する)\n",
    "            for epoch in range(trained_epochs, epochs, 50):\n",
    "                model = train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=50, epochs_section=[epoch, epochs])\n",
    "\n",
    "                # 学習済みパラメータを保存し、ANN.csvに保存先を記入する\n",
    "                l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "                params_path = '../data/params/ANN/params_' + str(len(l_df)).zfill(10) + '.pth'\n",
    "                torch.save(model.state_dict(), params_path)\n",
    "                sr = pd.Series([lc, sampling, tap, max_tap, batch_size, neuron, epoch + 50, lr, activation] + signal_list + [form, n, equalize, baudrate, PdBm, Ledfa, stepedfa, gamma, D, Alpha, NF, Lmax, ase, params_path, train_samples], index=l_df.columns)\n",
    "                l_df = l_df.append(sr, ignore_index=True)\n",
    "                l_df.to_csv(l_df_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "0:00:04 | Epoch: 1/500 | train Loss: 0.4403 | EVM: 50.33\n",
      "0:00:04 | Epoch: 2/500 | train Loss: 0.03639 | EVM: 17.55\n",
      "0:00:04 | Epoch: 3/500 | train Loss: 0.02976 | EVM: 15.89\n",
      "0:00:03 | Epoch: 4/500 | train Loss: 0.0266 | EVM: 14.97\n",
      "0:00:03 | Epoch: 5/500 | train Loss: 0.02521 | EVM: 14.61\n",
      "0:00:03 | Epoch: 6/500 | train Loss: 0.02347 | EVM: 14.06\n",
      "0:00:03 | Epoch: 7/500 | train Loss: 0.02212 | EVM: 13.64\n",
      "0:00:03 | Epoch: 8/500 | train Loss: 0.02117 | EVM: 13.38\n",
      "0:00:04 | Epoch: 9/500 | train Loss: 0.02027 | EVM: 13.08\n",
      "0:00:04 | Epoch: 10/500 | train Loss: 0.01963 | EVM: 12.93\n",
      "0:00:03 | Epoch: 11/500 | train Loss: 0.01873 | EVM: 12.57\n",
      "0:00:03 | Epoch: 12/500 | train Loss: 0.01792 | EVM: 12.32\n",
      "0:00:04 | Epoch: 13/500 | train Loss: 0.0179 | EVM: 12.27\n",
      "0:00:03 | Epoch: 14/500 | train Loss: 0.01696 | EVM: 12.0\n",
      "0:00:04 | Epoch: 15/500 | train Loss: 0.01695 | EVM: 12.0\n",
      "0:00:03 | Epoch: 16/500 | train Loss: 0.01605 | EVM: 11.7\n",
      "0:00:03 | Epoch: 17/500 | train Loss: 0.01544 | EVM: 11.43\n",
      "0:00:04 | Epoch: 18/500 | train Loss: 0.01513 | EVM: 11.34\n",
      "0:00:03 | Epoch: 19/500 | train Loss: 0.01494 | EVM: 11.32\n",
      "0:00:04 | Epoch: 20/500 | train Loss: 0.01456 | EVM: 11.25\n",
      "0:00:04 | Epoch: 21/500 | train Loss: 0.01449 | EVM: 11.11\n",
      "0:00:04 | Epoch: 22/500 | train Loss: 0.01376 | EVM: 10.84\n",
      "0:00:03 | Epoch: 23/500 | train Loss: 0.01303 | EVM: 10.59\n",
      "0:00:03 | Epoch: 24/500 | train Loss: 0.01296 | EVM: 10.54\n",
      "0:00:04 | Epoch: 25/500 | train Loss: 0.01263 | EVM: 10.41\n",
      "0:00:03 | Epoch: 26/500 | train Loss: 0.01245 | EVM: 10.23\n",
      "0:00:03 | Epoch: 27/500 | train Loss: 0.01199 | EVM: 10.16\n",
      "0:00:03 | Epoch: 28/500 | train Loss: 0.01158 | EVM: 9.959\n",
      "0:00:03 | Epoch: 29/500 | train Loss: 0.01202 | EVM: 10.22\n",
      "0:00:04 | Epoch: 30/500 | train Loss: 0.01126 | EVM: 9.872\n",
      "0:00:04 | Epoch: 31/500 | train Loss: 0.01147 | EVM: 9.957\n",
      "0:00:03 | Epoch: 32/500 | train Loss: 0.0106 | EVM: 9.585\n",
      "0:00:03 | Epoch: 33/500 | train Loss: 0.01006 | EVM: 9.388\n",
      "0:00:04 | Epoch: 34/500 | train Loss: 0.01004 | EVM: 9.332\n",
      "0:00:03 | Epoch: 35/500 | train Loss: 0.009946 | EVM: 9.232\n",
      "0:00:04 | Epoch: 36/500 | train Loss: 0.009991 | EVM: 9.306\n",
      "0:00:03 | Epoch: 37/500 | train Loss: 0.009545 | EVM: 9.105\n",
      "0:00:03 | Epoch: 38/500 | train Loss: 0.009551 | EVM: 9.063\n",
      "0:00:03 | Epoch: 39/500 | train Loss: 0.009504 | EVM: 9.051\n",
      "0:00:03 | Epoch: 40/500 | train Loss: 0.009059 | EVM: 8.874\n",
      "0:00:03 | Epoch: 41/500 | train Loss: 0.008932 | EVM: 8.82\n",
      "0:00:04 | Epoch: 42/500 | train Loss: 0.008568 | EVM: 8.624\n",
      "0:00:03 | Epoch: 43/500 | train Loss: 0.008622 | EVM: 8.636\n",
      "0:00:03 | Epoch: 44/500 | train Loss: 0.008027 | EVM: 8.333\n",
      "0:00:04 | Epoch: 45/500 | train Loss: 0.007781 | EVM: 8.242\n",
      "0:00:03 | Epoch: 46/500 | train Loss: 0.008073 | EVM: 8.337\n",
      "0:00:04 | Epoch: 47/500 | train Loss: 0.007726 | EVM: 8.19\n",
      "0:00:03 | Epoch: 48/500 | train Loss: 0.007753 | EVM: 8.218\n",
      "0:00:04 | Epoch: 49/500 | train Loss: 0.008003 | EVM: 8.331\n",
      "0:00:03 | Epoch: 50/500 | train Loss: 0.007338 | EVM: 8.016\n",
      "0:00:03 | Epoch: 51/500 | train Loss: 0.007392 | EVM: 8.026\n",
      "0:00:03 | Epoch: 52/500 | train Loss: 0.007016 | EVM: 7.822\n",
      "0:00:03 | Epoch: 53/500 | train Loss: 0.006948 | EVM: 7.761\n",
      "0:00:04 | Epoch: 54/500 | train Loss: 0.007141 | EVM: 7.865\n",
      "0:00:03 | Epoch: 55/500 | train Loss: 0.00711 | EVM: 7.946\n",
      "0:00:03 | Epoch: 56/500 | train Loss: 0.006723 | EVM: 7.716\n",
      "0:00:03 | Epoch: 57/500 | train Loss: 0.006867 | EVM: 7.683\n",
      "0:00:03 | Epoch: 58/500 | train Loss: 0.006629 | EVM: 7.619\n",
      "0:00:03 | Epoch: 59/500 | train Loss: 0.006352 | EVM: 7.437\n",
      "0:00:04 | Epoch: 60/500 | train Loss: 0.00648 | EVM: 7.464\n",
      "0:00:04 | Epoch: 61/500 | train Loss: 0.006016 | EVM: 7.227\n",
      "0:00:04 | Epoch: 62/500 | train Loss: 0.005782 | EVM: 7.164\n",
      "0:00:03 | Epoch: 63/500 | train Loss: 0.005968 | EVM: 7.191\n",
      "0:00:04 | Epoch: 64/500 | train Loss: 0.005823 | EVM: 7.103\n",
      "0:00:04 | Epoch: 65/500 | train Loss: 0.006142 | EVM: 7.304\n",
      "0:00:04 | Epoch: 66/500 | train Loss: 0.006241 | EVM: 7.314\n",
      "0:00:03 | Epoch: 67/500 | train Loss: 0.005985 | EVM: 7.225\n",
      "0:00:04 | Epoch: 68/500 | train Loss: 0.005837 | EVM: 7.143\n",
      "0:00:03 | Epoch: 69/500 | train Loss: 0.005548 | EVM: 6.973\n",
      "0:00:03 | Epoch: 70/500 | train Loss: 0.0055 | EVM: 6.954\n",
      "0:00:04 | Epoch: 71/500 | train Loss: 0.005655 | EVM: 6.987\n",
      "0:00:03 | Epoch: 72/500 | train Loss: 0.005321 | EVM: 6.858\n",
      "0:00:03 | Epoch: 73/500 | train Loss: 0.005118 | EVM: 6.7\n",
      "0:00:03 | Epoch: 74/500 | train Loss: 0.005405 | EVM: 6.905\n",
      "0:00:03 | Epoch: 75/500 | train Loss: 0.004868 | EVM: 6.525\n",
      "0:00:04 | Epoch: 76/500 | train Loss: 0.005347 | EVM: 6.824\n",
      "0:00:04 | Epoch: 77/500 | train Loss: 0.005301 | EVM: 6.786\n",
      "0:00:03 | Epoch: 78/500 | train Loss: 0.005195 | EVM: 6.752\n",
      "0:00:03 | Epoch: 79/500 | train Loss: 0.005149 | EVM: 6.722\n",
      "0:00:04 | Epoch: 80/500 | train Loss: 0.004389 | EVM: 6.2\n",
      "0:00:04 | Epoch: 81/500 | train Loss: 0.00471 | EVM: 6.427\n",
      "0:00:04 | Epoch: 82/500 | train Loss: 0.004738 | EVM: 6.469\n",
      "0:00:04 | Epoch: 83/500 | train Loss: 0.004514 | EVM: 6.269\n",
      "0:00:04 | Epoch: 84/500 | train Loss: 0.00429 | EVM: 6.085\n",
      "0:00:03 | Epoch: 85/500 | train Loss: 0.004686 | EVM: 6.361\n",
      "0:00:03 | Epoch: 86/500 | train Loss: 0.005044 | EVM: 6.664\n",
      "0:00:03 | Epoch: 87/500 | train Loss: 0.004319 | EVM: 6.106\n",
      "0:00:03 | Epoch: 88/500 | train Loss: 0.00446 | EVM: 6.248\n",
      "0:00:03 | Epoch: 89/500 | train Loss: 0.004474 | EVM: 6.232\n",
      "0:00:04 | Epoch: 90/500 | train Loss: 0.004228 | EVM: 6.067\n",
      "0:00:04 | Epoch: 91/500 | train Loss: 0.004085 | EVM: 6.049\n",
      "0:00:03 | Epoch: 92/500 | train Loss: 0.004283 | EVM: 6.092\n",
      "0:00:03 | Epoch: 93/500 | train Loss: 0.00418 | EVM: 6.083\n",
      "0:00:03 | Epoch: 94/500 | train Loss: 0.004074 | EVM: 5.957\n",
      "0:00:03 | Epoch: 95/500 | train Loss: 0.004061 | EVM: 5.924\n",
      "0:00:04 | Epoch: 96/500 | train Loss: 0.003991 | EVM: 5.915\n",
      "0:00:04 | Epoch: 97/500 | train Loss: 0.003719 | EVM: 5.69\n",
      "0:00:03 | Epoch: 98/500 | train Loss: 0.003876 | EVM: 5.815\n",
      "0:00:04 | Epoch: 99/500 | train Loss: 0.003875 | EVM: 5.81\n",
      "0:00:03 | Epoch: 100/500 | train Loss: 0.003978 | EVM: 5.938\n",
      "0:00:03 | Epoch: 101/500 | train Loss: 0.004134 | EVM: 6.038\n",
      "0:00:04 | Epoch: 102/500 | train Loss: 0.00404 | EVM: 5.956\n",
      "0:00:03 | Epoch: 103/500 | train Loss: 0.004145 | EVM: 6.028\n",
      "0:00:04 | Epoch: 104/500 | train Loss: 0.003799 | EVM: 5.798\n",
      "0:00:04 | Epoch: 105/500 | train Loss: 0.003941 | EVM: 5.888\n",
      "0:00:04 | Epoch: 106/500 | train Loss: 0.004243 | EVM: 6.066\n",
      "0:00:04 | Epoch: 107/500 | train Loss: 0.003776 | EVM: 5.754\n",
      "0:00:04 | Epoch: 108/500 | train Loss: 0.003905 | EVM: 5.811\n",
      "0:00:04 | Epoch: 109/500 | train Loss: 0.003858 | EVM: 5.83\n",
      "0:00:03 | Epoch: 110/500 | train Loss: 0.00348 | EVM: 5.51\n",
      "0:00:04 | Epoch: 111/500 | train Loss: 0.003171 | EVM: 5.318\n",
      "0:00:03 | Epoch: 112/500 | train Loss: 0.00352 | EVM: 5.559\n",
      "0:00:03 | Epoch: 113/500 | train Loss: 0.003551 | EVM: 5.544\n",
      "0:00:03 | Epoch: 114/500 | train Loss: 0.003136 | EVM: 5.242\n",
      "0:00:04 | Epoch: 115/500 | train Loss: 0.003219 | EVM: 5.288\n",
      "0:00:04 | Epoch: 116/500 | train Loss: 0.003287 | EVM: 5.33\n",
      "0:00:03 | Epoch: 117/500 | train Loss: 0.003128 | EVM: 5.218\n",
      "0:00:03 | Epoch: 118/500 | train Loss: 0.003656 | EVM: 5.655\n",
      "0:00:03 | Epoch: 119/500 | train Loss: 0.003894 | EVM: 5.852\n",
      "0:00:04 | Epoch: 120/500 | train Loss: 0.003068 | EVM: 5.185\n",
      "0:00:04 | Epoch: 121/500 | train Loss: 0.003679 | EVM: 5.674\n",
      "0:00:04 | Epoch: 122/500 | train Loss: 0.003733 | EVM: 5.741\n",
      "0:00:03 | Epoch: 123/500 | train Loss: 0.003335 | EVM: 5.407\n",
      "0:00:03 | Epoch: 124/500 | train Loss: 0.003067 | EVM: 5.199\n",
      "0:00:04 | Epoch: 125/500 | train Loss: 0.003315 | EVM: 5.391\n",
      "0:00:04 | Epoch: 126/500 | train Loss: 0.003095 | EVM: 5.209\n",
      "0:00:03 | Epoch: 127/500 | train Loss: 0.003055 | EVM: 5.245\n",
      "0:00:03 | Epoch: 128/500 | train Loss: 0.00289 | EVM: 5.101\n",
      "0:00:04 | Epoch: 129/500 | train Loss: 0.002864 | EVM: 5.04\n",
      "0:00:03 | Epoch: 130/500 | train Loss: 0.003267 | EVM: 5.387\n",
      "0:00:03 | Epoch: 131/500 | train Loss: 0.003246 | EVM: 5.323\n",
      "0:00:03 | Epoch: 132/500 | train Loss: 0.003667 | EVM: 5.66\n",
      "0:00:04 | Epoch: 133/500 | train Loss: 0.004316 | EVM: 6.126\n",
      "0:00:03 | Epoch: 134/500 | train Loss: 0.003296 | EVM: 5.374\n",
      "0:00:03 | Epoch: 135/500 | train Loss: 0.002982 | EVM: 5.097\n",
      "0:00:04 | Epoch: 136/500 | train Loss: 0.003043 | EVM: 5.184\n",
      "0:00:03 | Epoch: 137/500 | train Loss: 0.003054 | EVM: 5.141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03 | Epoch: 138/500 | train Loss: 0.003062 | EVM: 5.199\n",
      "0:00:04 | Epoch: 139/500 | train Loss: 0.003239 | EVM: 5.332\n",
      "0:00:04 | Epoch: 140/500 | train Loss: 0.002703 | EVM: 4.892\n",
      "0:00:04 | Epoch: 141/500 | train Loss: 0.003016 | EVM: 5.135\n",
      "0:00:04 | Epoch: 142/500 | train Loss: 0.002841 | EVM: 4.993\n",
      "0:00:04 | Epoch: 143/500 | train Loss: 0.002737 | EVM: 4.869\n",
      "0:00:04 | Epoch: 144/500 | train Loss: 0.002718 | EVM: 4.906\n",
      "0:00:04 | Epoch: 145/500 | train Loss: 0.00286 | EVM: 5.051\n",
      "0:00:04 | Epoch: 146/500 | train Loss: 0.003218 | EVM: 5.285\n",
      "0:00:03 | Epoch: 147/500 | train Loss: 0.003347 | EVM: 5.398\n",
      "0:00:03 | Epoch: 148/500 | train Loss: 0.002906 | EVM: 4.99\n",
      "0:00:03 | Epoch: 149/500 | train Loss: 0.002671 | EVM: 4.804\n",
      "0:00:04 | Epoch: 150/500 | train Loss: 0.002686 | EVM: 4.861\n",
      "0:00:04 | Epoch: 151/500 | train Loss: 0.002686 | EVM: 4.877\n",
      "0:00:03 | Epoch: 152/500 | train Loss: 0.002649 | EVM: 4.854\n",
      "0:00:03 | Epoch: 153/500 | train Loss: 0.002956 | EVM: 5.117\n",
      "0:00:03 | Epoch: 154/500 | train Loss: 0.003271 | EVM: 5.39\n",
      "0:00:03 | Epoch: 155/500 | train Loss: 0.003084 | EVM: 5.209\n",
      "0:00:03 | Epoch: 156/500 | train Loss: 0.00286 | EVM: 5.057\n",
      "0:00:03 | Epoch: 157/500 | train Loss: 0.002592 | EVM: 4.756\n",
      "0:00:03 | Epoch: 158/500 | train Loss: 0.002496 | EVM: 4.667\n",
      "0:00:04 | Epoch: 159/500 | train Loss: 0.002783 | EVM: 4.958\n",
      "0:00:03 | Epoch: 160/500 | train Loss: 0.003034 | EVM: 5.185\n",
      "0:00:04 | Epoch: 161/500 | train Loss: 0.002615 | EVM: 4.813\n",
      "0:00:03 | Epoch: 162/500 | train Loss: 0.003163 | EVM: 5.313\n",
      "0:00:04 | Epoch: 163/500 | train Loss: 0.002615 | EVM: 4.787\n",
      "0:00:04 | Epoch: 164/500 | train Loss: 0.002655 | EVM: 4.843\n",
      "0:00:03 | Epoch: 165/500 | train Loss: 0.00249 | EVM: 4.707\n",
      "0:00:03 | Epoch: 166/500 | train Loss: 0.002311 | EVM: 4.52\n",
      "0:00:03 | Epoch: 167/500 | train Loss: 0.002545 | EVM: 4.708\n",
      "0:00:04 | Epoch: 168/500 | train Loss: 0.003094 | EVM: 5.251\n",
      "0:00:04 | Epoch: 169/500 | train Loss: 0.002679 | EVM: 4.882\n",
      "0:00:03 | Epoch: 170/500 | train Loss: 0.002602 | EVM: 4.836\n",
      "0:00:03 | Epoch: 171/500 | train Loss: 0.002419 | EVM: 4.618\n",
      "0:00:03 | Epoch: 172/500 | train Loss: 0.002249 | EVM: 4.449\n",
      "0:00:03 | Epoch: 173/500 | train Loss: 0.002288 | EVM: 4.436\n",
      "0:00:04 | Epoch: 174/500 | train Loss: 0.00218 | EVM: 4.4\n",
      "0:00:03 | Epoch: 175/500 | train Loss: 0.002478 | EVM: 4.666\n",
      "0:00:03 | Epoch: 176/500 | train Loss: 0.002785 | EVM: 4.952\n",
      "0:00:03 | Epoch: 177/500 | train Loss: 0.002584 | EVM: 4.786\n",
      "0:00:04 | Epoch: 178/500 | train Loss: 0.002502 | EVM: 4.713\n",
      "0:00:04 | Epoch: 179/500 | train Loss: 0.002278 | EVM: 4.456\n",
      "0:00:03 | Epoch: 180/500 | train Loss: 0.002446 | EVM: 4.638\n",
      "0:00:03 | Epoch: 181/500 | train Loss: 0.003007 | EVM: 5.12\n",
      "0:00:04 | Epoch: 182/500 | train Loss: 0.002426 | EVM: 4.604\n",
      "0:00:03 | Epoch: 183/500 | train Loss: 0.002725 | EVM: 4.87\n",
      "0:00:03 | Epoch: 184/500 | train Loss: 0.002723 | EVM: 4.846\n",
      "0:00:03 | Epoch: 185/500 | train Loss: 0.00301 | EVM: 5.145\n",
      "0:00:03 | Epoch: 186/500 | train Loss: 0.002624 | EVM: 4.826\n",
      "0:00:04 | Epoch: 187/500 | train Loss: 0.002226 | EVM: 4.444\n",
      "0:00:03 | Epoch: 188/500 | train Loss: 0.002302 | EVM: 4.483\n",
      "0:00:04 | Epoch: 189/500 | train Loss: 0.002245 | EVM: 4.411\n",
      "0:00:04 | Epoch: 190/500 | train Loss: 0.001853 | EVM: 4.018\n",
      "0:00:04 | Epoch: 191/500 | train Loss: 0.002039 | EVM: 4.229\n",
      "0:00:04 | Epoch: 192/500 | train Loss: 0.00236 | EVM: 4.57\n",
      "0:00:03 | Epoch: 193/500 | train Loss: 0.002765 | EVM: 4.941\n",
      "0:00:03 | Epoch: 194/500 | train Loss: 0.002989 | EVM: 5.12\n",
      "0:00:03 | Epoch: 195/500 | train Loss: 0.002341 | EVM: 4.522\n",
      "0:00:03 | Epoch: 196/500 | train Loss: 0.002009 | EVM: 4.242\n",
      "0:00:03 | Epoch: 197/500 | train Loss: 0.002257 | EVM: 4.491\n",
      "0:00:03 | Epoch: 198/500 | train Loss: 0.002509 | EVM: 4.648\n",
      "0:00:03 | Epoch: 199/500 | train Loss: 0.002411 | EVM: 4.586\n",
      "0:00:03 | Epoch: 200/500 | train Loss: 0.002004 | EVM: 4.195\n",
      "0:00:03 | Epoch: 201/500 | train Loss: 0.001962 | EVM: 4.159\n",
      "0:00:03 | Epoch: 202/500 | train Loss: 0.002258 | EVM: 4.405\n",
      "0:00:03 | Epoch: 203/500 | train Loss: 0.002643 | EVM: 4.839\n",
      "0:00:03 | Epoch: 204/500 | train Loss: 0.0024 | EVM: 4.607\n",
      "0:00:03 | Epoch: 205/500 | train Loss: 0.002037 | EVM: 4.242\n",
      "0:00:04 | Epoch: 206/500 | train Loss: 0.002264 | EVM: 4.485\n",
      "0:00:04 | Epoch: 207/500 | train Loss: 0.00228 | EVM: 4.486\n",
      "0:00:03 | Epoch: 208/500 | train Loss: 0.001978 | EVM: 4.171\n",
      "0:00:04 | Epoch: 209/500 | train Loss: 0.001855 | EVM: 4.031\n",
      "0:00:04 | Epoch: 210/500 | train Loss: 0.002204 | EVM: 4.423\n",
      "0:00:04 | Epoch: 211/500 | train Loss: 0.00276 | EVM: 4.932\n",
      "0:00:04 | Epoch: 212/500 | train Loss: 0.002263 | EVM: 4.457\n",
      "0:00:04 | Epoch: 213/500 | train Loss: 0.002066 | EVM: 4.237\n",
      "0:00:03 | Epoch: 214/500 | train Loss: 0.001555 | EVM: 3.707\n",
      "0:00:03 | Epoch: 215/500 | train Loss: 0.001978 | EVM: 4.141\n",
      "0:00:03 | Epoch: 216/500 | train Loss: 0.002108 | EVM: 4.288\n",
      "0:00:03 | Epoch: 217/500 | train Loss: 0.002072 | EVM: 4.248\n",
      "0:00:04 | Epoch: 218/500 | train Loss: 0.002192 | EVM: 4.406\n",
      "0:00:04 | Epoch: 219/500 | train Loss: 0.001898 | EVM: 4.106\n",
      "0:00:04 | Epoch: 220/500 | train Loss: 0.002106 | EVM: 4.295\n",
      "0:00:04 | Epoch: 221/500 | train Loss: 0.001893 | EVM: 4.074\n",
      "0:00:04 | Epoch: 222/500 | train Loss: 0.001908 | EVM: 4.098\n",
      "0:00:04 | Epoch: 223/500 | train Loss: 0.002276 | EVM: 4.431\n",
      "0:00:04 | Epoch: 224/500 | train Loss: 0.002419 | EVM: 4.62\n",
      "0:00:04 | Epoch: 225/500 | train Loss: 0.002987 | EVM: 5.113\n",
      "0:00:03 | Epoch: 226/500 | train Loss: 0.002454 | EVM: 4.636\n",
      "0:00:03 | Epoch: 227/500 | train Loss: 0.002453 | EVM: 4.635\n",
      "0:00:04 | Epoch: 228/500 | train Loss: 0.002025 | EVM: 4.203\n",
      "0:00:03 | Epoch: 229/500 | train Loss: 0.002228 | EVM: 4.413\n",
      "0:00:04 | Epoch: 230/500 | train Loss: 0.002141 | EVM: 4.35\n",
      "0:00:04 | Epoch: 231/500 | train Loss: 0.001884 | EVM: 4.042\n",
      "0:00:04 | Epoch: 232/500 | train Loss: 0.002088 | EVM: 4.302\n",
      "0:00:04 | Epoch: 233/500 | train Loss: 0.001926 | EVM: 4.131\n",
      "0:00:03 | Epoch: 234/500 | train Loss: 0.001787 | EVM: 3.943\n",
      "0:00:03 | Epoch: 235/500 | train Loss: 0.001913 | EVM: 4.11\n",
      "0:00:04 | Epoch: 236/500 | train Loss: 0.002166 | EVM: 4.369\n",
      "0:00:03 | Epoch: 237/500 | train Loss: 0.002163 | EVM: 4.36\n",
      "0:00:03 | Epoch: 238/500 | train Loss: 0.00208 | EVM: 4.282\n",
      "0:00:04 | Epoch: 239/500 | train Loss: 0.002947 | EVM: 5.095\n",
      "0:00:03 | Epoch: 240/500 | train Loss: 0.002444 | EVM: 4.65\n",
      "0:00:04 | Epoch: 241/500 | train Loss: 0.001909 | EVM: 4.038\n",
      "0:00:04 | Epoch: 242/500 | train Loss: 0.002051 | EVM: 4.2\n",
      "0:00:04 | Epoch: 243/500 | train Loss: 0.001697 | EVM: 3.876\n",
      "0:00:04 | Epoch: 244/500 | train Loss: 0.001548 | EVM: 3.696\n",
      "0:00:04 | Epoch: 245/500 | train Loss: 0.001914 | EVM: 4.117\n",
      "0:00:04 | Epoch: 246/500 | train Loss: 0.001898 | EVM: 4.083\n",
      "0:00:04 | Epoch: 247/500 | train Loss: 0.001619 | EVM: 3.747\n",
      "0:00:04 | Epoch: 248/500 | train Loss: 0.001848 | EVM: 4.005\n",
      "0:00:04 | Epoch: 249/500 | train Loss: 0.002084 | EVM: 4.29\n",
      "0:00:04 | Epoch: 250/500 | train Loss: 0.002163 | EVM: 4.33\n",
      "0:00:03 | Epoch: 251/500 | train Loss: 0.001962 | EVM: 4.188\n",
      "0:00:04 | Epoch: 252/500 | train Loss: 0.002328 | EVM: 4.496\n",
      "0:00:03 | Epoch: 253/500 | train Loss: 0.002293 | EVM: 4.517\n",
      "0:00:03 | Epoch: 254/500 | train Loss: 0.00233 | EVM: 4.551\n",
      "0:00:04 | Epoch: 255/500 | train Loss: 0.001961 | EVM: 4.134\n",
      "0:00:03 | Epoch: 256/500 | train Loss: 0.001553 | EVM: 3.661\n",
      "0:00:04 | Epoch: 257/500 | train Loss: 0.001389 | EVM: 3.508\n",
      "0:00:03 | Epoch: 258/500 | train Loss: 0.001671 | EVM: 3.833\n",
      "0:00:04 | Epoch: 259/500 | train Loss: 0.001899 | EVM: 4.125\n",
      "0:00:03 | Epoch: 260/500 | train Loss: 0.00177 | EVM: 3.983\n",
      "0:00:04 | Epoch: 261/500 | train Loss: 0.001794 | EVM: 3.991\n",
      "0:00:04 | Epoch: 262/500 | train Loss: 0.002352 | EVM: 4.52\n",
      "0:00:03 | Epoch: 263/500 | train Loss: 0.001909 | EVM: 4.054\n",
      "0:00:04 | Epoch: 264/500 | train Loss: 0.001854 | EVM: 4.036\n",
      "0:00:04 | Epoch: 265/500 | train Loss: 0.001906 | EVM: 4.089\n",
      "0:00:04 | Epoch: 266/500 | train Loss: 0.001726 | EVM: 3.892\n",
      "0:00:04 | Epoch: 267/500 | train Loss: 0.00243 | EVM: 4.617\n",
      "0:00:03 | Epoch: 268/500 | train Loss: 0.002333 | EVM: 4.56\n",
      "0:00:04 | Epoch: 269/500 | train Loss: 0.002072 | EVM: 4.267\n",
      "0:00:03 | Epoch: 270/500 | train Loss: 0.001626 | EVM: 3.766\n",
      "0:00:03 | Epoch: 271/500 | train Loss: 0.001823 | EVM: 4.01\n",
      "0:00:04 | Epoch: 272/500 | train Loss: 0.001957 | EVM: 4.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:03 | Epoch: 273/500 | train Loss: 0.001787 | EVM: 3.966\n",
      "0:00:03 | Epoch: 274/500 | train Loss: 0.002044 | EVM: 4.214\n",
      "0:00:03 | Epoch: 275/500 | train Loss: 0.001887 | EVM: 4.025\n",
      "0:00:04 | Epoch: 276/500 | train Loss: 0.001711 | EVM: 3.886\n",
      "0:00:04 | Epoch: 277/500 | train Loss: 0.001828 | EVM: 3.995\n",
      "0:00:04 | Epoch: 278/500 | train Loss: 0.001609 | EVM: 3.772\n",
      "0:00:03 | Epoch: 279/500 | train Loss: 0.00163 | EVM: 3.814\n",
      "0:00:03 | Epoch: 280/500 | train Loss: 0.001975 | EVM: 4.191\n",
      "0:00:03 | Epoch: 281/500 | train Loss: 0.002272 | EVM: 4.469\n",
      "0:00:04 | Epoch: 282/500 | train Loss: 0.002013 | EVM: 4.216\n",
      "0:00:04 | Epoch: 283/500 | train Loss: 0.002186 | EVM: 4.37\n",
      "0:00:04 | Epoch: 284/500 | train Loss: 0.001858 | EVM: 4.002\n",
      "0:00:04 | Epoch: 285/500 | train Loss: 0.00159 | EVM: 3.72\n",
      "0:00:03 | Epoch: 286/500 | train Loss: 0.001737 | EVM: 3.966\n",
      "0:00:03 | Epoch: 287/500 | train Loss: 0.001917 | EVM: 4.111\n",
      "0:00:04 | Epoch: 288/500 | train Loss: 0.001861 | EVM: 4.051\n",
      "0:00:04 | Epoch: 289/500 | train Loss: 0.001799 | EVM: 3.979\n",
      "0:00:04 | Epoch: 290/500 | train Loss: 0.002105 | EVM: 4.35\n",
      "0:00:03 | Epoch: 291/500 | train Loss: 0.001788 | EVM: 3.972\n",
      "0:00:03 | Epoch: 292/500 | train Loss: 0.001684 | EVM: 3.878\n",
      "0:00:03 | Epoch: 293/500 | train Loss: 0.001999 | EVM: 4.215\n",
      "0:00:03 | Epoch: 294/500 | train Loss: 0.001738 | EVM: 3.926\n",
      "0:00:03 | Epoch: 295/500 | train Loss: 0.001887 | EVM: 4.047\n",
      "0:00:03 | Epoch: 296/500 | train Loss: 0.001953 | EVM: 4.118\n",
      "0:00:04 | Epoch: 297/500 | train Loss: 0.001925 | EVM: 4.107\n",
      "0:00:04 | Epoch: 298/500 | train Loss: 0.001716 | EVM: 3.885\n",
      "0:00:04 | Epoch: 299/500 | train Loss: 0.001464 | EVM: 3.572\n",
      "0:00:04 | Epoch: 300/500 | train Loss: 0.001781 | EVM: 3.939\n",
      "0:00:03 | Epoch: 301/500 | train Loss: 0.001812 | EVM: 4.012\n",
      "0:00:04 | Epoch: 302/500 | train Loss: 0.001818 | EVM: 3.994\n",
      "0:00:03 | Epoch: 303/500 | train Loss: 0.001583 | EVM: 3.735\n",
      "0:00:03 | Epoch: 304/500 | train Loss: 0.001374 | EVM: 3.459\n",
      "0:00:04 | Epoch: 305/500 | train Loss: 0.001854 | EVM: 4.056\n",
      "0:00:04 | Epoch: 306/500 | train Loss: 0.00256 | EVM: 4.715\n",
      "0:00:03 | Epoch: 307/500 | train Loss: 0.002377 | EVM: 4.549\n",
      "0:00:03 | Epoch: 308/500 | train Loss: 0.002031 | EVM: 4.194\n",
      "0:00:04 | Epoch: 309/500 | train Loss: 0.00201 | EVM: 4.214\n",
      "0:00:03 | Epoch: 310/500 | train Loss: 0.001649 | EVM: 3.796\n",
      "0:00:04 | Epoch: 311/500 | train Loss: 0.001527 | EVM: 3.621\n",
      "0:00:03 | Epoch: 312/500 | train Loss: 0.001249 | EVM: 3.288\n",
      "0:00:03 | Epoch: 313/500 | train Loss: 0.001266 | EVM: 3.354\n",
      "0:00:04 | Epoch: 314/500 | train Loss: 0.001699 | EVM: 3.849\n",
      "0:00:04 | Epoch: 315/500 | train Loss: 0.002862 | EVM: 4.958\n",
      "0:00:04 | Epoch: 316/500 | train Loss: 0.002493 | EVM: 4.683\n",
      "0:00:03 | Epoch: 317/500 | train Loss: 0.001826 | EVM: 3.995\n",
      "0:00:04 | Epoch: 318/500 | train Loss: 0.001647 | EVM: 3.823\n",
      "0:00:03 | Epoch: 319/500 | train Loss: 0.001505 | EVM: 3.629\n",
      "0:00:03 | Epoch: 320/500 | train Loss: 0.001332 | EVM: 3.431\n",
      "0:00:03 | Epoch: 321/500 | train Loss: 0.001335 | EVM: 3.418\n",
      "0:00:03 | Epoch: 322/500 | train Loss: 0.00156 | EVM: 3.695\n",
      "0:00:04 | Epoch: 323/500 | train Loss: 0.001477 | EVM: 3.566\n",
      "0:00:04 | Epoch: 324/500 | train Loss: 0.001353 | EVM: 3.46\n",
      "0:00:04 | Epoch: 325/500 | train Loss: 0.001252 | EVM: 3.315\n",
      "0:00:04 | Epoch: 326/500 | train Loss: 0.00161 | EVM: 3.779\n",
      "0:00:03 | Epoch: 327/500 | train Loss: 0.001788 | EVM: 3.962\n",
      "0:00:03 | Epoch: 328/500 | train Loss: 0.001878 | EVM: 4.081\n",
      "0:00:03 | Epoch: 329/500 | train Loss: 0.001907 | EVM: 4.131\n",
      "0:00:03 | Epoch: 330/500 | train Loss: 0.002085 | EVM: 4.269\n",
      "0:00:04 | Epoch: 331/500 | train Loss: 0.001762 | EVM: 3.894\n",
      "0:00:04 | Epoch: 332/500 | train Loss: 0.001826 | EVM: 4.019\n",
      "0:00:03 | Epoch: 333/500 | train Loss: 0.001534 | EVM: 3.657\n",
      "0:00:04 | Epoch: 334/500 | train Loss: 0.001502 | EVM: 3.647\n",
      "0:00:03 | Epoch: 335/500 | train Loss: 0.001699 | EVM: 3.832\n",
      "0:00:04 | Epoch: 336/500 | train Loss: 0.001967 | EVM: 4.181\n",
      "0:00:03 | Epoch: 337/500 | train Loss: 0.001691 | EVM: 3.863\n",
      "0:00:03 | Epoch: 338/500 | train Loss: 0.001913 | EVM: 4.134\n",
      "0:00:04 | Epoch: 339/500 | train Loss: 0.002193 | EVM: 4.364\n",
      "0:00:04 | Epoch: 340/500 | train Loss: 0.00204 | EVM: 4.251\n",
      "0:00:04 | Epoch: 341/500 | train Loss: 0.001493 | EVM: 3.608\n",
      "0:00:03 | Epoch: 342/500 | train Loss: 0.001232 | EVM: 3.287\n",
      "0:00:03 | Epoch: 343/500 | train Loss: 0.001342 | EVM: 3.448\n",
      "0:00:03 | Epoch: 344/500 | train Loss: 0.001338 | EVM: 3.437\n",
      "0:00:03 | Epoch: 345/500 | train Loss: 0.001399 | EVM: 3.512\n",
      "0:00:03 | Epoch: 346/500 | train Loss: 0.001457 | EVM: 3.611\n",
      "0:00:03 | Epoch: 347/500 | train Loss: 0.002105 | EVM: 4.26\n",
      "0:00:04 | Epoch: 348/500 | train Loss: 0.002133 | EVM: 4.292\n",
      "0:00:04 | Epoch: 349/500 | train Loss: 0.001863 | EVM: 4.053\n",
      "0:00:04 | Epoch: 350/500 | train Loss: 0.001557 | EVM: 3.692\n",
      "0:00:03 | Epoch: 351/500 | train Loss: 0.001462 | EVM: 3.568\n",
      "0:00:04 | Epoch: 352/500 | train Loss: 0.001452 | EVM: 3.576\n",
      "0:00:04 | Epoch: 353/500 | train Loss: 0.001242 | EVM: 3.299\n",
      "0:00:04 | Epoch: 354/500 | train Loss: 0.001504 | EVM: 3.619\n",
      "0:00:04 | Epoch: 355/500 | train Loss: 0.001577 | EVM: 3.719\n",
      "0:00:04 | Epoch: 356/500 | train Loss: 0.001758 | EVM: 3.955\n",
      "0:00:03 | Epoch: 357/500 | train Loss: 0.002131 | EVM: 4.323\n",
      "0:00:03 | Epoch: 358/500 | train Loss: 0.002635 | EVM: 4.781\n",
      "0:00:03 | Epoch: 359/500 | train Loss: 0.001701 | EVM: 3.85\n",
      "0:00:03 | Epoch: 360/500 | train Loss: 0.001656 | EVM: 3.833\n",
      "0:00:04 | Epoch: 361/500 | train Loss: 0.001662 | EVM: 3.808\n",
      "0:00:04 | Epoch: 362/500 | train Loss: 0.001387 | EVM: 3.464\n",
      "0:00:03 | Epoch: 363/500 | train Loss: 0.00119 | EVM: 3.211\n",
      "0:00:03 | Epoch: 364/500 | train Loss: 0.001059 | EVM: 3.08\n",
      "0:00:04 | Epoch: 365/500 | train Loss: 0.001205 | EVM: 3.243\n",
      "0:00:04 | Epoch: 366/500 | train Loss: 0.001528 | EVM: 3.655\n",
      "0:00:04 | Epoch: 367/500 | train Loss: 0.001737 | EVM: 3.902\n",
      "0:00:03 | Epoch: 368/500 | train Loss: 0.001905 | EVM: 4.048\n",
      "0:00:04 | Epoch: 369/500 | train Loss: 0.001528 | EVM: 3.678\n",
      "0:00:03 | Epoch: 370/500 | train Loss: 0.001743 | EVM: 3.894\n",
      "0:00:04 | Epoch: 371/500 | train Loss: 0.001941 | EVM: 4.131\n",
      "0:00:04 | Epoch: 372/500 | train Loss: 0.001771 | EVM: 3.934\n",
      "0:00:03 | Epoch: 373/500 | train Loss: 0.001795 | EVM: 3.99\n",
      "0:00:04 | Epoch: 374/500 | train Loss: 0.001946 | EVM: 4.16\n",
      "0:00:03 | Epoch: 375/500 | train Loss: 0.002174 | EVM: 4.338\n",
      "0:00:04 | Epoch: 376/500 | train Loss: 0.00175 | EVM: 3.934\n",
      "0:00:03 | Epoch: 377/500 | train Loss: 0.001504 | EVM: 3.638\n",
      "0:00:03 | Epoch: 378/500 | train Loss: 0.001143 | EVM: 3.193\n",
      "0:00:04 | Epoch: 379/500 | train Loss: 0.001319 | EVM: 3.386\n",
      "0:00:04 | Epoch: 380/500 | train Loss: 0.001253 | EVM: 3.319\n",
      "0:00:04 | Epoch: 381/500 | train Loss: 0.001306 | EVM: 3.389\n",
      "0:00:04 | Epoch: 382/500 | train Loss: 0.001431 | EVM: 3.558\n",
      "0:00:03 | Epoch: 383/500 | train Loss: 0.001788 | EVM: 3.946\n",
      "0:00:04 | Epoch: 384/500 | train Loss: 0.002087 | EVM: 4.283\n",
      "0:00:03 | Epoch: 385/500 | train Loss: 0.001664 | EVM: 3.84\n",
      "0:00:04 | Epoch: 386/500 | train Loss: 0.001665 | EVM: 3.79\n",
      "0:00:04 | Epoch: 387/500 | train Loss: 0.001654 | EVM: 3.816\n",
      "0:00:03 | Epoch: 388/500 | train Loss: 0.001568 | EVM: 3.722\n",
      "0:00:03 | Epoch: 389/500 | train Loss: 0.001635 | EVM: 3.813\n",
      "0:00:03 | Epoch: 390/500 | train Loss: 0.001899 | EVM: 4.098\n",
      "0:00:03 | Epoch: 391/500 | train Loss: 0.001488 | EVM: 3.636\n",
      "0:00:03 | Epoch: 392/500 | train Loss: 0.001332 | EVM: 3.393\n",
      "0:00:04 | Epoch: 393/500 | train Loss: 0.001871 | EVM: 4.05\n",
      "0:00:04 | Epoch: 394/500 | train Loss: 0.001871 | EVM: 4.041\n",
      "0:00:04 | Epoch: 395/500 | train Loss: 0.00127 | EVM: 3.311\n",
      "0:00:03 | Epoch: 396/500 | train Loss: 0.001513 | EVM: 3.644\n",
      "0:00:04 | Epoch: 397/500 | train Loss: 0.001341 | EVM: 3.429\n",
      "0:00:04 | Epoch: 398/500 | train Loss: 0.001419 | EVM: 3.551\n",
      "0:00:03 | Epoch: 399/500 | train Loss: 0.001385 | EVM: 3.45\n",
      "0:00:03 | Epoch: 400/500 | train Loss: 0.001479 | EVM: 3.603\n",
      "0:00:03 | Epoch: 401/500 | train Loss: 0.00152 | EVM: 3.652\n",
      "0:00:03 | Epoch: 402/500 | train Loss: 0.002035 | EVM: 4.249\n",
      "0:00:03 | Epoch: 403/500 | train Loss: 0.001427 | EVM: 3.532\n",
      "0:00:03 | Epoch: 404/500 | train Loss: 0.00179 | EVM: 3.961\n",
      "0:00:03 | Epoch: 405/500 | train Loss: 0.001627 | EVM: 3.782\n",
      "0:00:03 | Epoch: 406/500 | train Loss: 0.001591 | EVM: 3.735\n",
      "0:00:03 | Epoch: 407/500 | train Loss: 0.001343 | EVM: 3.441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:04 | Epoch: 408/500 | train Loss: 0.001282 | EVM: 3.351\n",
      "0:00:03 | Epoch: 409/500 | train Loss: 0.001741 | EVM: 3.925\n",
      "0:00:03 | Epoch: 410/500 | train Loss: 0.001354 | EVM: 3.459\n",
      "0:00:03 | Epoch: 411/500 | train Loss: 0.0014 | EVM: 3.457\n",
      "0:00:03 | Epoch: 412/500 | train Loss: 0.001562 | EVM: 3.668\n",
      "0:00:04 | Epoch: 413/500 | train Loss: 0.001172 | EVM: 3.215\n",
      "0:00:04 | Epoch: 414/500 | train Loss: 0.001572 | EVM: 3.694\n",
      "0:00:03 | Epoch: 415/500 | train Loss: 0.00172 | EVM: 3.869\n",
      "0:00:03 | Epoch: 416/500 | train Loss: 0.001592 | EVM: 3.754\n",
      "0:00:03 | Epoch: 417/500 | train Loss: 0.001467 | EVM: 3.572\n",
      "0:00:04 | Epoch: 418/500 | train Loss: 0.00192 | EVM: 4.059\n",
      "0:00:03 | Epoch: 419/500 | train Loss: 0.001387 | EVM: 3.472\n",
      "0:00:03 | Epoch: 420/500 | train Loss: 0.00117 | EVM: 3.231\n",
      "0:00:04 | Epoch: 421/500 | train Loss: 0.001447 | EVM: 3.554\n",
      "0:00:03 | Epoch: 422/500 | train Loss: 0.001485 | EVM: 3.592\n",
      "0:00:04 | Epoch: 423/500 | train Loss: 0.001261 | EVM: 3.323\n",
      "0:00:04 | Epoch: 424/500 | train Loss: 0.001385 | EVM: 3.464\n",
      "0:00:03 | Epoch: 425/500 | train Loss: 0.001314 | EVM: 3.419\n",
      "0:00:04 | Epoch: 426/500 | train Loss: 0.001436 | EVM: 3.569\n",
      "0:00:03 | Epoch: 427/500 | train Loss: 0.001498 | EVM: 3.622\n",
      "0:00:04 | Epoch: 428/500 | train Loss: 0.001591 | EVM: 3.736\n",
      "0:00:03 | Epoch: 429/500 | train Loss: 0.001727 | EVM: 3.892\n",
      "0:00:03 | Epoch: 430/500 | train Loss: 0.001655 | EVM: 3.79\n",
      "0:00:03 | Epoch: 431/500 | train Loss: 0.001719 | EVM: 3.866\n",
      "0:00:03 | Epoch: 432/500 | train Loss: 0.001854 | EVM: 3.996\n",
      "0:00:03 | Epoch: 433/500 | train Loss: 0.001563 | EVM: 3.708\n",
      "0:00:03 | Epoch: 434/500 | train Loss: 0.001613 | EVM: 3.739\n",
      "0:00:03 | Epoch: 435/500 | train Loss: 0.001438 | EVM: 3.57\n",
      "0:00:04 | Epoch: 436/500 | train Loss: 0.001716 | EVM: 3.902\n",
      "0:00:03 | Epoch: 437/500 | train Loss: 0.001572 | EVM: 3.7\n",
      "0:00:04 | Epoch: 438/500 | train Loss: 0.001208 | EVM: 3.263\n",
      "0:00:03 | Epoch: 439/500 | train Loss: 0.001427 | EVM: 3.52\n",
      "0:00:03 | Epoch: 440/500 | train Loss: 0.00237 | EVM: 4.547\n",
      "0:00:04 | Epoch: 441/500 | train Loss: 0.001917 | EVM: 4.103\n",
      "0:00:04 | Epoch: 442/500 | train Loss: 0.001426 | EVM: 3.562\n",
      "0:00:04 | Epoch: 443/500 | train Loss: 0.001133 | EVM: 3.16\n",
      "0:00:03 | Epoch: 444/500 | train Loss: 0.001226 | EVM: 3.257\n",
      "0:00:04 | Epoch: 445/500 | train Loss: 0.001349 | EVM: 3.404\n",
      "0:00:03 | Epoch: 446/500 | train Loss: 0.001199 | EVM: 3.277\n",
      "0:00:03 | Epoch: 447/500 | train Loss: 0.00117 | EVM: 3.221\n",
      "0:00:03 | Epoch: 448/500 | train Loss: 0.001476 | EVM: 3.597\n",
      "0:00:04 | Epoch: 449/500 | train Loss: 0.001429 | EVM: 3.532\n",
      "0:00:03 | Epoch: 450/500 | train Loss: 0.001391 | EVM: 3.475\n",
      "0:00:03 | Epoch: 451/500 | train Loss: 0.001983 | EVM: 4.149\n",
      "0:00:03 | Epoch: 452/500 | train Loss: 0.001793 | EVM: 3.944\n",
      "0:00:04 | Epoch: 453/500 | train Loss: 0.001365 | EVM: 3.456\n",
      "0:00:03 | Epoch: 454/500 | train Loss: 0.001324 | EVM: 3.426\n",
      "0:00:03 | Epoch: 455/500 | train Loss: 0.001408 | EVM: 3.52\n",
      "0:00:04 | Epoch: 456/500 | train Loss: 0.001552 | EVM: 3.687\n",
      "0:00:03 | Epoch: 457/500 | train Loss: 0.001646 | EVM: 3.808\n",
      "0:00:03 | Epoch: 458/500 | train Loss: 0.001619 | EVM: 3.738\n",
      "0:00:03 | Epoch: 459/500 | train Loss: 0.001307 | EVM: 3.419\n",
      "0:00:04 | Epoch: 460/500 | train Loss: 0.001286 | EVM: 3.346\n",
      "0:00:03 | Epoch: 461/500 | train Loss: 0.001156 | EVM: 3.184\n",
      "0:00:04 | Epoch: 462/500 | train Loss: 0.001261 | EVM: 3.336\n",
      "0:00:04 | Epoch: 463/500 | train Loss: 0.001271 | EVM: 3.343\n",
      "0:00:03 | Epoch: 464/500 | train Loss: 0.001366 | EVM: 3.47\n",
      "0:00:03 | Epoch: 465/500 | train Loss: 0.001662 | EVM: 3.834\n",
      "0:00:04 | Epoch: 466/500 | train Loss: 0.001629 | EVM: 3.791\n",
      "0:00:04 | Epoch: 467/500 | train Loss: 0.001758 | EVM: 3.929\n",
      "0:00:03 | Epoch: 468/500 | train Loss: 0.001836 | EVM: 4.011\n",
      "0:00:03 | Epoch: 469/500 | train Loss: 0.002065 | EVM: 4.283\n",
      "0:00:04 | Epoch: 470/500 | train Loss: 0.001296 | EVM: 3.387\n",
      "0:00:03 | Epoch: 471/500 | train Loss: 0.001373 | EVM: 3.516\n",
      "0:00:03 | Epoch: 472/500 | train Loss: 0.000985 | EVM: 2.929\n",
      "0:00:04 | Epoch: 473/500 | train Loss: 0.001176 | EVM: 3.223\n",
      "0:00:03 | Epoch: 474/500 | train Loss: 0.001135 | EVM: 3.172\n",
      "0:00:03 | Epoch: 475/500 | train Loss: 0.001583 | EVM: 3.704\n",
      "0:00:04 | Epoch: 476/500 | train Loss: 0.001368 | EVM: 3.453\n",
      "0:00:04 | Epoch: 477/500 | train Loss: 0.001835 | EVM: 3.993\n",
      "0:00:03 | Epoch: 478/500 | train Loss: 0.001541 | EVM: 3.66\n",
      "0:00:03 | Epoch: 479/500 | train Loss: 0.001267 | EVM: 3.347\n",
      "0:00:03 | Epoch: 480/500 | train Loss: 0.001573 | EVM: 3.711\n",
      "0:00:03 | Epoch: 481/500 | train Loss: 0.001452 | EVM: 3.571\n",
      "0:00:03 | Epoch: 482/500 | train Loss: 0.00147 | EVM: 3.6\n",
      "0:00:03 | Epoch: 483/500 | train Loss: 0.001219 | EVM: 3.253\n",
      "0:00:03 | Epoch: 484/500 | train Loss: 0.001508 | EVM: 3.626\n",
      "0:00:03 | Epoch: 485/500 | train Loss: 0.001552 | EVM: 3.693\n",
      "0:00:03 | Epoch: 486/500 | train Loss: 0.001387 | EVM: 3.491\n",
      "0:00:03 | Epoch: 487/500 | train Loss: 0.001092 | EVM: 3.097\n",
      "0:00:03 | Epoch: 488/500 | train Loss: 0.001079 | EVM: 3.067\n",
      "0:00:04 | Epoch: 489/500 | train Loss: 0.001057 | EVM: 3.05\n",
      "0:00:04 | Epoch: 490/500 | train Loss: 0.001271 | EVM: 3.341\n",
      "0:00:04 | Epoch: 491/500 | train Loss: 0.001392 | EVM: 3.499\n",
      "0:00:03 | Epoch: 492/500 | train Loss: 0.001114 | EVM: 3.125\n",
      "0:00:04 | Epoch: 493/500 | train Loss: 0.00146 | EVM: 3.62\n",
      "0:00:04 | Epoch: 494/500 | train Loss: 0.001619 | EVM: 3.783\n",
      "0:00:04 | Epoch: 495/500 | train Loss: 0.001488 | EVM: 3.638\n",
      "0:00:03 | Epoch: 496/500 | train Loss: 0.001474 | EVM: 3.592\n",
      "0:00:03 | Epoch: 497/500 | train Loss: 0.001348 | EVM: 3.431\n",
      "0:00:04 | Epoch: 498/500 | train Loss: 0.001579 | EVM: 3.713\n",
      "0:00:04 | Epoch: 499/500 | train Loss: 0.001682 | EVM: 3.865\n",
      "0:00:04 | Epoch: 500/500 | train Loss: 0.001542 | EVM: 3.684\n"
     ]
    }
   ],
   "source": [
    "model_info = {'linear_compensation': True, # True-->100%線形歪補償後の信号を学習する False-->線形歪補償無しの信号を学習する\n",
    "              'sampling': 4, # サンプリングレート\n",
    "              'batch_size': 100, # バッチサイズ\n",
    "              'neuron': 320, # 中間層ニューロンの数\n",
    "              'epochs': 500, # エポック\n",
    "              'lr': 0.001, # 学習率\n",
    "              'activation': 'ReLU', # 活性化関数 'ReLU' or 'Sigmoid'\n",
    "              'form': 'RZ16QAM', # 変調フォーマット\n",
    "              'Lmax': 2500} # 伝送距離\n",
    "\n",
    "signal_info_random = {'signal_type': 'random', # 符号の種類\n",
    "                      'seed': '1234', # 乱数シード\n",
    "                      'bit_num': 50000} # bit数\n",
    "\n",
    "signal_info_image0 = {'signal_type': 'image', # 符号の種類\n",
    "                      'target_dir': 'train_0', # data/image/train_0/*.jpg 使用したい画像の保存されているフォルダ\n",
    "                      'step': 60, # 画像を何分の1にリサイズするか step=10ならば(768, 1024) --> (76, 102)\n",
    "                      'image_number': '0, 1, 2, 3, 4, 5, 6, 7, 8, 9', # ディレクトリ内で名前順に数えて何番目の画像を使用するか(カンマ、スペース必須だったと思います？)\n",
    "                      'ebtb': True} # 8B10Bを行うか\n",
    "\n",
    "signal_info_image1 = {'signal_type': 'image',\n",
    "                      'target_dir': 'train_0',\n",
    "                      'step': 60,\n",
    "                      'image_number': '0, 5, 6, 12, 17, 33, 35, 45, 52, 53',\n",
    "                      'ebtb': True}\n",
    "\n",
    "signal_info_image2 = {'signal_type': 'image',\n",
    "                      'target_dir': 'train_0',\n",
    "                      'step': 60,\n",
    "                      'image_number': '0, 5, 6, 12, 17, 33, 35, 45, 52, 53, 174, 195, 198, 254, 255, 319, 341, 433, 439, 442, 451, 484, 535, 576, 582, 616, 640, 654, 670, 724, 747, 750, 771, 823, 825, 832, 870, 877, 902, 955, 974, 982, 1038, 1077, 1167, 1202, 1204, 1214, 1302, 1361, 1393, 1422, 1437, 1441, 1578, 1621, 1674, 1685, 1762, 1769, 1790, 1814, 1845, 1899, 1900, 1937, 1945, 1962, 2025, 2184, 2191, 2196, 2270, 2276, 2286, 2345, 2348, 2360, 2371, 2375, 2394, 2428, 2446, 2459, 2465, 2474, 2478, 2506, 2523, 2549, 2568, 2594, 2602, 2642, 2648, 2668, 2676, 2696, 2707, 2724',\n",
    "                      'ebtb': True}\n",
    "\n",
    "for tap in [25]:\n",
    "    train_ann_with_save(model_info, signal_info_image1, tap, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
