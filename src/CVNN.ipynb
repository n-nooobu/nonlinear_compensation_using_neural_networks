{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CVNNによる非線形歪補償\n",
    "複素数を入力とする3層ANNによる補償"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision\n",
    "from torchvision import models, transforms\n",
    "\n",
    "sys.path.append('../')\n",
    "from pyopt.util import save_pickle, load_pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 データの整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shaping(input_signal, signal, sampling, tap, max_tap, n):\n",
    "    \"\"\"\n",
    "    input_signal: 伝送前の信号\n",
    "    signal: 伝送後の信号\n",
    "    max_tap: 最大の同時入力シンボル数\n",
    "    tap: 同時入力シンボル数\n",
    "    \n",
    "    signal = [x_0, x_1, ... , x_(n-1)]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[x_0, x_1, ... , x_tap-1],\n",
    "            [x_1, x_2, ..., x_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [x_(n-tap), x_(n-tap+1), ..., x(n-1)]]\n",
    "      |\n",
    "      |\n",
    "      v\n",
    "    x = [[i_0, q_0, i_1, q_1, ... , i_(tap-1), q_(tap-1)],\n",
    "            [i_1, q_1, i_2, q_2, ... , i_tap, q_tap],\n",
    "                   .\n",
    "                   .\n",
    "                   .\n",
    "            [i_(n-tap), q_(n-tap), i_(n-tap+1), q_(n-tap+1), ..., i_(n-1), q_(n-1)]] (batch, input_dim) input_dim = tap * 2\n",
    "    \n",
    "    y  (batch, output_dim) output_dim = 2\n",
    "    \"\"\"\n",
    "    \n",
    "    x = np.zeros((len(input_signal) // n - (max_tap - 1), sampling * tap, 2), dtype=float)\n",
    "    y = np.zeros((len(input_signal) // n - (max_tap - 1), 2), dtype=float)\n",
    "    if sampling == 1:\n",
    "        for i, center in enumerate(range(max_tap // 2, len(input_signal) // n - max_tap // 2)):\n",
    "            for j, symbol in enumerate(range(tap)):\n",
    "                x[i, j, 0] = signal[n * (center - tap // 2 + j) + n // 2].real\n",
    "                x[i, j, 1] = signal[n * (center - tap // 2 + j) + n // 2].imag\n",
    "            y[i, 0] = input_signal[n // 2 + n * center].real\n",
    "            y[i, 1] = input_signal[n // 2 + n * center].imag\n",
    "    else:\n",
    "        for i, center in enumerate(range(max_tap // 2, len(input_signal) // n - max_tap // 2)):\n",
    "            for j, symbol in enumerate(range(tap)):\n",
    "                for k, sample in enumerate([round(_ * n / sampling) for _ in range(sampling)]):\n",
    "                    x[i, j * sampling + k, 0] = signal[n * (center - tap // 2 + j) + sample].real\n",
    "                    x[i, j * sampling + k, 1] = signal[n * (center - tap // 2 + j) + sample].imag\n",
    "            y[i, 0] = input_signal[n // 2 + n * center].real\n",
    "            y[i, 1] = input_signal[n // 2 + n * center].imag\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x size:  (1998, 153, 2)\n",
      "y size:  (1998, 2)\n",
      "[[  9850.68513614 -21219.80262024]\n",
      " [ 13204.64011713 -32959.409542  ]\n",
      " [  6948.9465661  -23474.70595918]\n",
      " [  6572.22992075 -19764.76810906]\n",
      " [  4963.7554057  -28359.94776034]\n",
      " [  4484.76229895 -21853.46310266]\n",
      " [  6797.53679687 -25291.13803704]\n",
      " [ 10767.82650196 -34408.70724833]\n",
      " [  9678.50727356 -23175.84758057]\n",
      " [ 24185.99583942 -63906.15879268]\n",
      " [ 28765.59632506 -95588.70645972]\n",
      " [ 18657.13045424 -67387.64694757]\n",
      " [ 56175.5509019  -10325.27176417]\n",
      " [ 71641.59997349 -13264.43479735]\n",
      " [ 47605.46488907  -6410.10234191]\n",
      " [ 70448.73916762  22469.73798232]\n",
      " [ 92211.70544456  31290.2122476 ]\n",
      " [ 62700.35070749  20206.6647782 ]\n",
      " [-23472.17369949  -8746.64263679]\n",
      " [-29586.19186635 -10544.86139771]\n",
      " [-20101.04150411  -5371.96315595]\n",
      " [ 68619.96000997  22685.84254411]\n",
      " [ 93962.83654914  31040.0557247 ]\n",
      " [ 64874.50621444  18833.08566138]\n",
      " [-23270.56758099  69767.8172635 ]\n",
      " [-32415.55573636  97552.01834647]\n",
      " [-22512.10891961  70694.09360485]\n",
      " [ 66383.09908837  20917.92990576]\n",
      " [ 95397.19055329  28467.02067506]\n",
      " [ 69149.71441814  21857.25304182]\n",
      " [ 11499.17346984 -22777.37790659]\n",
      " [ 10526.01181374 -32119.29365184]\n",
      " [  5915.7380358  -21513.77600657]\n",
      " [ 37160.62713156 -36822.76773862]\n",
      " [ 51598.75641186 -53403.3657517 ]\n",
      " [ 36896.1942185  -35963.35312315]\n",
      " [-23509.0194177   69370.77001323]\n",
      " [-32145.84759244  96508.43591778]\n",
      " [-21930.20441251  69493.59711927]\n",
      " [-24386.8339686   68981.23423682]\n",
      " [-30606.37446336  95283.58932182]\n",
      " [-20114.10288792  67085.91096302]\n",
      " [ 23630.3335101    8550.55411542]\n",
      " [ 32503.60952844  13910.52002391]\n",
      " [ 19775.71797271   8337.62622792]\n",
      " [  1505.54138879  52985.79015063]\n",
      " [  8248.62335619  73391.81300168]\n",
      " [  8803.9113899   52922.25779194]\n",
      " [ 23226.98657532   6173.82296349]\n",
      " [ 29107.6877347   14808.73597731]\n",
      " [ 21660.11322431  10290.7129009 ]\n",
      " [-59281.41002489   4788.94228463]\n",
      " [-78280.98856905  15366.79259349]\n",
      " [-52466.38237819  10645.34786092]\n",
      " [-57418.08518298   8294.79012923]\n",
      " [-76605.44555413  12791.23534176]\n",
      " [-53564.37800728   6091.43089672]\n",
      " [ 48181.33485736  -2661.24820898]\n",
      " [ 69345.95709822  -8729.55171237]\n",
      " [ 50466.10800318  -6293.11087073]\n",
      " [ 24157.9261167    5699.60735645]\n",
      " [ 36932.5922594   11156.38959978]\n",
      " [ 20997.33579011   3481.6740615 ]\n",
      " [  5710.64806606 -21210.34053508]\n",
      " [ 13056.01107017 -32846.73484666]\n",
      " [  6994.2248206  -22988.72176138]\n",
      " [ 10850.2652246  -22850.7982191 ]\n",
      " [ 10610.89876389 -34963.38298674]\n",
      " [  5831.52399779 -22056.48574842]\n",
      " [-51635.83653334   6352.24045788]\n",
      " [-73494.72750711   7190.0287674 ]\n",
      " [-52463.52960199   4038.43512234]\n",
      " [-34856.40893308  36435.22152105]\n",
      " [-49860.52436413  54128.52098679]\n",
      " [-33743.0765054   35367.32740222]\n",
      " [-35847.08681349  39208.95892715]\n",
      " [-53019.95429361  53670.26520552]\n",
      " [-35871.69130375  33280.79407437]\n",
      " [ 22197.99903746 -67982.577974  ]\n",
      " [ 32274.63575034 -91081.39804461]\n",
      " [ 20972.20154564 -64874.63871763]\n",
      " [-14311.5834803   21293.25249882]\n",
      " [-14385.94066463  30341.90659466]\n",
      " [ -8984.17670552  21588.61620719]\n",
      " [-35289.88915525  33018.18463125]\n",
      " [-47630.74129796  49235.95785073]\n",
      " [-35143.31136767  32291.89819905]\n",
      " [ -8089.28161592 -53276.10718567]\n",
      " [-11546.66807361 -75020.35362366]\n",
      " [-10005.53093473 -50920.28036557]\n",
      " [ -3237.54697927  23069.68768802]\n",
      " [-11274.86250656  31430.37354787]\n",
      " [-14828.9679435   22449.5916614 ]\n",
      " [-35678.23361096  39602.52203944]\n",
      " [-51761.20934421  52640.09062926]\n",
      " [-36048.52845084  31859.85585643]\n",
      " [-69456.05583387 -23863.8680078 ]\n",
      " [-92079.7374958  -28400.06490156]\n",
      " [-64572.86987252 -24530.42900586]\n",
      " [-36523.01300174  34383.66913155]\n",
      " [-54174.37271402  50576.41182636]\n",
      " [-38115.80465094  37278.58774462]\n",
      " [-48854.45836482   8177.92939211]\n",
      " [-67054.54768817  15313.41343857]\n",
      " [-50558.50566246   8993.36601387]\n",
      " [ 71164.56648515  18941.87167243]\n",
      " [ 96034.7954907   33242.87671139]\n",
      " [ 66839.77366154  21307.96121369]\n",
      " [ 35627.58903797 -36944.61015822]\n",
      " [ 50154.90489795 -49671.1420593 ]\n",
      " [ 39135.64088666 -35054.61938855]\n",
      " [-72399.7849235  -23739.67325888]\n",
      " [-93925.54099544 -34256.15458994]\n",
      " [-62718.99318472 -26602.24702001]\n",
      " [-17472.80168706 -10204.33215447]\n",
      " [-30446.56620013 -13048.71261142]\n",
      " [-25166.60632214  -7214.23961045]\n",
      " [  7096.98610434 -21626.32073831]\n",
      " [  9693.42456563 -29001.58083495]\n",
      " [  4693.54740246 -21547.61944372]\n",
      " [ 38572.51961269  35844.47585536]\n",
      " [ 53869.69339133  53203.79762369]\n",
      " [ 35305.63786238  36420.89221891]\n",
      " [-48959.91491411   5807.13120418]\n",
      " [-74834.99144475  12591.73272873]\n",
      " [-52090.29471337   7401.84468008]\n",
      " [ -3976.78984601 -51339.63074484]\n",
      " [ -8641.78225709 -76703.97959458]\n",
      " [ -9443.87352776 -56147.36256715]\n",
      " [ -6605.39076131 -53945.39847237]\n",
      " [-11908.29497623 -74391.14514142]\n",
      " [-10374.79667778 -51080.00934797]\n",
      " [-36370.59682235  40098.62154113]\n",
      " [-46928.71523324  54963.03408056]\n",
      " [-35251.84093241  38791.30153192]\n",
      " [ 35300.93752645  35050.78622443]\n",
      " [ 54320.21663862  47205.89456635]\n",
      " [ 35278.14743737  34920.07671749]\n",
      " [-35606.87507166 -31608.76890125]\n",
      " [-45992.22599903 -54129.65894991]\n",
      " [-31943.1955221  -33563.78701753]\n",
      " [-19615.26279683  69008.39349   ]\n",
      " [-28136.70645934  96224.01278557]\n",
      " [-21210.7171454   71003.54221669]\n",
      " [  9743.19837705  50482.56849787]\n",
      " [ 14839.32632175  73853.19972264]\n",
      " [  5108.26562964  50091.26653857]\n",
      " [ 51095.3018873   -4442.30745557]\n",
      " [ 70262.46021305  -6670.59929076]\n",
      " [ 52201.83025185  -4362.69841068]\n",
      " [ 62368.56825144  19187.38319638]\n",
      " [ 92504.06752568  29724.26459508]\n",
      " [ 64210.88050597  24404.98553067]]\n",
      "[-70474.95606832  23491.65202277]\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "sampling = 3\n",
    "tap = 51\n",
    "max_tap = 51\n",
    "\n",
    "df_dir = '../data/input/prbs.csv'\n",
    "df = pd.read_csv(df_dir, index_col=0)  # dataframe読み込み\n",
    "condition = (df['N']==13) & (df['itr']==1) & (df['form']=='RZ16QAM') & (df['n']==32) & (df['equalize']==False) & (df['baudrate']==28) & (df['PdBm']==1)\n",
    "sgnl = load_pickle(df[condition].iloc[0]['data_path'])  # dataframeから条件と合う行を取得し,pickleの保存先(data_path)にアクセス\n",
    "lc = sgnl.linear_compensation(500, sgnl.signal['x_500'])\n",
    "x, y = data_shaping(sgnl.signal['x_0'], lc, sampling, tap, max_tap, 32)  # ANNに入力できるようにデータを整形\n",
    "\n",
    "print('x size: ', x.shape)\n",
    "print('y size: ', y.shape)\n",
    "print(x[0])\n",
    "print(y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 平均,標準偏差の計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  1053.2765739234778\n",
      "std:  45950.91990246874\n"
     ]
    }
   ],
   "source": [
    "mean = np.mean(x)\n",
    "std = np.std(x)\n",
    "\n",
    "print('mean: ', mean)\n",
    "print('std: ', std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, x, y, mean, std):\n",
    "        self.x, self.y, self.mean, self.std = x, y, mean, std\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        x = self.x[index]\n",
    "        y = self.y[index]\n",
    "        \n",
    "        x = (x - self.mean) / self.std\n",
    "        y = (y - self.mean) / self.std\n",
    "        \n",
    "        x = torch.Tensor(x)\n",
    "        y = torch.Tensor(y)\n",
    "        \n",
    "        x_i = x[:, 0]\n",
    "        x_q = x[:, 1]\n",
    "        y_i = y[0]\n",
    "        y_q = y[1]\n",
    "        return x_i, x_q, y_i, y_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean:  -0.027470334\n",
      "std:  0.95101625\n",
      "tensor([ 0.1915,  0.2644,  0.1283,  0.1201,  0.0851,  0.0747,  0.1250,  0.2114,\n",
      "         0.1877,  0.5034,  0.6031,  0.3831,  1.1996,  1.5362,  1.0131,  1.5102,\n",
      "         1.9838,  1.3416, -0.5337, -0.6668, -0.4604,  1.4704,  2.0219,  1.3889,\n",
      "        -0.5293, -0.7284, -0.5128,  1.4217,  2.0531,  1.4819,  0.2273,  0.2061,\n",
      "         0.1058,  0.7858,  1.1000,  0.7800, -0.5345, -0.7225, -0.5002, -0.5536,\n",
      "        -0.6890, -0.4607,  0.4913,  0.6844,  0.4074,  0.0098,  0.1566,  0.1687,\n",
      "         0.4826,  0.6105,  0.4485, -1.3130, -1.7265, -1.1647, -1.2725, -1.6900,\n",
      "        -1.1886,  1.0256,  1.4862,  1.0753,  0.5028,  0.7808,  0.4340,  0.1014,\n",
      "         0.2612,  0.1293,  0.2132,  0.2080,  0.1040, -1.1466, -1.6223, -1.1647,\n",
      "        -0.7815, -1.1080, -0.7573, -0.8030, -1.1768, -0.8036,  0.4602,  0.6795,\n",
      "         0.4335, -0.3344, -0.3360, -0.2184, -0.7909, -1.0595, -0.7877, -0.1990,\n",
      "        -0.2742, -0.2407, -0.0934, -0.2683, -0.3456, -0.7994, -1.1494, -0.8074,\n",
      "        -1.5344, -2.0268, -1.4282, -0.8177, -1.2019, -0.8524, -1.0861, -1.4822,\n",
      "        -1.1232,  1.5258,  2.0670,  1.4317,  0.7524,  1.0686,  0.8288, -1.5985,\n",
      "        -2.0670, -1.3878, -0.4032, -0.6855, -0.5706,  0.1315,  0.1880,  0.0792,\n",
      "         0.8165,  1.1494,  0.7454, -1.0884, -1.6515, -1.1565, -0.1095, -0.2110,\n",
      "        -0.2284, -0.1667, -0.2821, -0.2487, -0.8144, -1.0442, -0.7901,  0.7453,\n",
      "         1.1592,  0.7448, -0.7978, -1.0238, -0.7181, -0.4498, -0.6352, -0.4845,\n",
      "         0.1891,  0.3000,  0.0882,  1.0890,  1.5062,  1.1131,  1.3344,  1.9902,\n",
      "         1.3745])\n",
      "tensor(-1.5566)\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "\n",
    "index = 0\n",
    "x_i, x_q, y_i, y_q = train_dataset.__getitem__(index)\n",
    "x_array = x_i.detach().numpy()\n",
    "\n",
    "print('mean: ', np.mean(x_array))\n",
    "print('std: ', np.std(x_array))\n",
    "print(x_i)\n",
    "print(y_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "dataloaders_dict = {'train': train_dataloader}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Model定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x_i, x_q):\n",
    "        x_i, x_q = x_i.clone(), x_q.clone()\n",
    "        x_i, x_q = torch.sigmoid(x_i), torch.sigmoid(x_q)\n",
    "        return x_i, x_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CReLU(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x_i, x_q):\n",
    "        x_i, x_q = x_i.clone(), x_q.clone()\n",
    "        x_i, x_q = F.relu(x_i), F.relu(x_q)\n",
    "        return x_i, x_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class modReLU(nn.Module):\n",
    "    def __init__(self, in_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.b = torch.tensor(-math.sqrt(1 / in_features), requires_grad=True)\n",
    "    \n",
    "    def forward(self, x_i, x_q):\n",
    "        x_i, x_q = x_i.clone(), x_q.clone()\n",
    "        norm = torch.sqrt(x_i ** 2 + x_q ** 2)\n",
    "        \n",
    "        out_i = F.relu(norm + self.b) * x_i / norm\n",
    "        out_q = F.relu(norm + self.b) * x_q / norm\n",
    "        return out_i, out_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexLinear(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        \n",
    "        # 重み定義 Xavierの初期値\n",
    "        k = 1 / in_features\n",
    "        weight_i = torch.empty(out_features, in_features).uniform_(-math.sqrt(k), math.sqrt(k))\n",
    "        self.weight_i = nn.Parameter(weight_i)\n",
    "        weight_q = torch.empty(out_features, in_features).uniform_(-math.sqrt(k), math.sqrt(k))\n",
    "        self.weight_q = nn.Parameter(weight_q)\n",
    "        \n",
    "        bias_i = torch.empty(out_features).uniform_(-k, k)\n",
    "        self.bias_i = nn.Parameter(bias_i)\n",
    "        bias_q = torch.empty(out_features).uniform_(-k, k)\n",
    "        self.bias_q = nn.Parameter(bias_q)\n",
    "        \n",
    "    def forward(self, x_i, x_q):\n",
    "        i = nn.functional.linear(x_i, self.weight_i) - nn.functional.linear(x_q, self.weight_q) + self.bias_i\n",
    "        q = nn.functional.linear(x_i, self.weight_q) + nn.functional.linear(x_q, self.weight_i) + self.bias_q\n",
    "        return i, q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVNN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, hidden_neuron, activation):\n",
    "        super().__init__()\n",
    "        self.fc1 = ComplexLinear(input_dim, hidden_neuron)\n",
    "        self.fc2 = ComplexLinear(hidden_neuron, output_dim)\n",
    "        if activation == 'CSigmoid':\n",
    "            self.activation = CSigmoid()\n",
    "        elif activation == 'ZReLU':\n",
    "            self.activation = ZReLU()\n",
    "        elif activation == 'CReLU':\n",
    "            self.activation = CReLU()\n",
    "        elif activation == 'modReLU':\n",
    "            self.activation = modReLU(input_dim)\n",
    "    \n",
    "    def forward(self, x_i, x_q):\n",
    "        x_i, x_q = self.fc1(x_i, x_q)\n",
    "        x_i, x_q = self.activation(x_i, x_q)\n",
    "        x_i, x_q = self.fc2(x_i, x_q)\n",
    "        return x_i, x_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "hidden_neuron = 300\n",
    "activation = 'CSigmoid'\n",
    "device = torch.device('cpu') # 'cuda' if torch.cuda.is_available() else \n",
    "print('Device available now:', device)\n",
    "\n",
    "model = CVNN(input_dim=sampling*tap, output_dim=1, hidden_neuron=hidden_neuron, activation=activation).to(device)\n",
    "for x_i, x_q, y_i, y_q in train_dataloader:\n",
    "    out_i, out_q = model(x_i, x_q)\n",
    "    print(out_i.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. train定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evm_score(x_i, x_q, y_i, y_q):\n",
    "    tmp = 0\n",
    "    for i in range(len(x_i)):\n",
    "        tmp += ((x_i[i] - y_i[i]) ** 2 + (x_q[i] - y_q[i]) ** 2) / (y_i[i] ** 2 + y_q[i] ** 2)\n",
    "    evm = torch.sqrt(tmp / len(x_i))\n",
    "    return evm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EVMLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    \n",
    "    def forward(self, x_i, x_q, y_i, y_q):\n",
    "        return evm_score(x_i, x_q, y_i, y_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(device, model, dataloaders_dict, criterion, optimizer, epochs, epochs_section=None):\n",
    "    for epoch in range(epochs):\n",
    "        if epochs_section is not None:\n",
    "            epoch += epochs_section[0]\n",
    "            end_epoch = epochs_section[1]\n",
    "        else:\n",
    "            end_epoch = epochs\n",
    "        \n",
    "        start_time = time.time()\n",
    "        \n",
    "        for phase in dataloaders_dict.keys():\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "            \n",
    "            epoch_loss = 0.0\n",
    "            epoch_evms = 0.0\n",
    "            \n",
    "            for x_i, x_q, y_i, y_q in dataloaders_dict[phase]:\n",
    "                x_i, x_q = x_i.to(device), x_q.to(device)\n",
    "                y_i, y_q = y_i.to(device), y_q.to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    out_i, out_q = model(x_i, x_q)\n",
    "                    loss = criterion(out_i, out_q, y_i, y_q)\n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                    \n",
    "                    epoch_loss += loss.item() * x_i.size(0)\n",
    "                    epoch_evms += (evm_score(out_i, out_q, y_i, y_q)) ** 2 * x_i.size(0)\n",
    "            \n",
    "            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n",
    "            epoch_evm = torch.sqrt(epoch_evms / len(dataloaders_dict[phase].dataset)) * 100\n",
    "            \n",
    "            duration = str(datetime.timedelta(seconds=time.time() - start_time))[:7]\n",
    "            print('{} | Epoch: {}/{} | {} Loss: {:.4} | EVM: {:.4}'.format(duration, epoch + 1, end_epoch, phase, epoch_loss, epoch_evm[0]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:00 | Epoch: 1/5 | train Loss: 0.1415 | EVM: 14.35\n",
      "0:00:00 | Epoch: 2/5 | train Loss: 0.1074 | EVM: 10.81\n",
      "0:00:00 | Epoch: 3/5 | train Loss: 0.09289 | EVM: 9.328\n",
      "0:00:00 | Epoch: 4/5 | train Loss: 0.09666 | EVM: 9.701\n",
      "0:00:00 | Epoch: 5/5 | train Loss: 0.0901 | EVM: 9.05\n"
     ]
    }
   ],
   "source": [
    "#動作確認\n",
    "epochs = 5\n",
    "lr = 0.001\n",
    "\n",
    "criterion = EVMLoss()\n",
    "optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. 実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    if signal_info['signal_type'] == 'prbs':\n",
    "        return load_prbs(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    elif signal_info['signal_type'] == 'random':\n",
    "        return load_random(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    elif signal_info['signal_type'] == 'image':\n",
    "        return load_image(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prbs(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    N = signal_info['N']\n",
    "    itr = signal_info['itr']\n",
    "    signal_condition = 'N=='+str(N)+'&itr=='+str(itr)\n",
    "    signal_list = [N, itr] + [None] * 6\n",
    "    \n",
    "    # prbs.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'prbs.csv', index_col=0)\n",
    "    \n",
    "    # prbs.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "    t_query = t_df.query(signal_condition + '&' + trans_condition)\n",
    "    \n",
    "    # if prbs.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "    if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "        print('指定された伝送条件の信号が存在しません')\n",
    "        return\n",
    "    else:\n",
    "        # 伝送信号を学習データに整形する\n",
    "        sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "        if lc:\n",
    "            sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "        else:\n",
    "            sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "        x, y = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "        return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_random(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    seed = signal_info['seed']\n",
    "    bit_num = signal_info['bit_num']\n",
    "    signal_condition = 'seed=='+str(seed)+'&bit_num=='+str(bit_num)\n",
    "    signal_list = [None] * 2 + [seed, bit_num] + [None] * 4\n",
    "    \n",
    "    # random.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'random.csv', index_col=0)\n",
    "    \n",
    "    # random.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "    t_query = t_df.query(signal_condition + '&' + trans_condition)\n",
    "    \n",
    "    # if random.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "    if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "        print('指定された伝送条件の信号が存在しません')\n",
    "        return\n",
    "    else:\n",
    "        # 伝送信号を学習データに整形する\n",
    "        sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "        if lc:\n",
    "            sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "        else:\n",
    "            sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "        x, y = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "        return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax):\n",
    "    target_dir = signal_info['target_dir']\n",
    "    step = signal_info['step']\n",
    "    image_number = signal_info['image_number']\n",
    "    image_number_split = image_number.split(', ')\n",
    "    ebtb = signal_info['ebtb']\n",
    "    signal_condition = 'target_dir==\"'+str(target_dir)+'\"&step=='+str(step)+'&image_number==\"'+image_number+'\"&ebtb=='+str(ebtb)\n",
    "    signal_list = [None] * 4 + [target_dir, step, image_number, ebtb]\n",
    "    \n",
    "    # image.csvをpandasで読み込む\n",
    "    t_df_dir = '../data/input/'\n",
    "    t_df = pd.read_csv(t_df_dir + 'image.csv', index_col=0)\n",
    "    \n",
    "    x = None\n",
    "    y = None\n",
    "    for i in range(len(image_number_split)):\n",
    "        # image.csvにおいて、指定した伝送条件を見たす行を抜き出す\n",
    "        t_query = t_df.query('target_dir==\"'+str(target_dir)+'\"&step=='+str(step)+'&image_number=='+image_number_split[i]+'&ebtb=='+str(ebtb) + '&' + trans_condition)\n",
    "        \n",
    "        # if image.csvに指定した伝送条件がない or Lmax以外は満たすがLmaxだけ指定した条件未満: 何もしない if ある: 続ける\n",
    "        if len(t_query) == 0 or t_query.iloc[0]['Lmax'] < Lmax:\n",
    "            print('指定された伝送条件の信号が存在しません')\n",
    "            return\n",
    "        else:\n",
    "            # 伝送信号を学習データに整形する\n",
    "            sgnl = load_pickle(t_query.iloc[0]['data_path'])\n",
    "            if lc:\n",
    "                sgnl_distorted = sgnl.linear_compensation(Lmax, sgnl.signal['x_' + str(Lmax)])\n",
    "            else:\n",
    "                sgnl_distorted = sgnl.signal['x_' + str(Lmax)]\n",
    "            x_tmp, y_tmp = data_shaping(sgnl.signal['x_0'], sgnl_distorted, sampling, tap, max_tap, n)\n",
    "            if x is None:\n",
    "                x = x_tmp\n",
    "                y = y_tmp\n",
    "            else:\n",
    "                x = np.concatenate([x, x_tmp])\n",
    "                y = np.concatenate([y, y_tmp])\n",
    "    return x, y, signal_condition, signal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(learn_condition, trans_condition, signal_condition, device, sampling, tap, neuron, epochs, activation, Lmax):\n",
    "    # if CVNN.csv がある: pandasで読み込む if CVNN.csvがない: 新しいDataFrameを作る\n",
    "    l_df_dir = '../data/params/CVNN.csv'\n",
    "    if os.path.exists(l_df_dir):\n",
    "        l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "    else:\n",
    "        cols = ['linear_compensation', 'sampling', 'tap', 'max_tap', 'batch_size', 'neuron', 'epochs', 'learning_rate', 'activation', 'N', 'itr', 'seed', 'bit_num', 'target_dir', 'step', 'image_number', 'ebtb', 'form', 'n', 'equalize', 'baudrate', 'PdBm', 'Ledfa', 'stepedfa', 'gamma', 'D', 'Alpha', 'NF', 'Lmax', 'ase', 'params_path', 'train_samples']\n",
    "        l_df = pd.DataFrame(index=[], columns=cols)\n",
    "        l_df.to_csv(l_df_dir)\n",
    "\n",
    "    # ANN.csvにおいて、指定した条件を満たす行だけqueryとして抜き出す\n",
    "    l_query = l_df.query(learn_condition + '&' + signal_condition + '&' + trans_condition + '&Lmax=='+str(Lmax))\n",
    "\n",
    "    #if epochsを含む指定された条件を満たす結果がある: 何もしない\n",
    "    if len(l_query) > 0 and l_query['epochs'].max() >= epochs:\n",
    "        print('指定された条件の学習結果はすでに存在します')\n",
    "        return None, None, None\n",
    "    else:\n",
    "        # if epochs以外の指定された条件を満たす結果がある: パラメータを読み込む if ない: 新しくモデルを作成する\n",
    "        if len(l_query) > 0:\n",
    "            index = l_query['epochs'].idxmax()\n",
    "            trained_epochs = l_query['epochs'][index]\n",
    "            model = CVNN(input_dim=sampling*tap, output_dim=1, hidden_neuron=neuron, activation=activation).to(device)\n",
    "            model.load_state_dict(torch.load(l_query['params_path'][index]))\n",
    "        else:\n",
    "            trained_epochs = 0\n",
    "            model = CVNN(input_dim=sampling*tap, output_dim=1, hidden_neuron=neuron, activation=activation).to(device)\n",
    "    return model, l_df_dir, trained_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果と条件を保存しない\n",
    "def train_cvnn(model_info, signal_info, tap, PdBm):\n",
    "    device = torch.device('cpu') #'cuda' if torch.cuda.is_available() else \n",
    "    print('Device available now:', device)\n",
    "    \n",
    "    lc = model_info['linear_compensation']\n",
    "    sampling = model_info['sampling']\n",
    "    #tap = model_info['tap']\n",
    "    batch_size = model_info['batch_size']\n",
    "    neuron = model_info['neuron']\n",
    "    epochs = model_info['epochs']\n",
    "    lr = model_info['lr']\n",
    "    activation = model_info['activation']\n",
    "    form = model_info['form']\n",
    "    #PdBm = model_info['PdBm']\n",
    "    Lmax = model_info['Lmax']\n",
    "\n",
    "    max_tap = 501\n",
    "    n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "    equalize = False  # 各シンボル数を均等にするか\n",
    "    baudrate = 28  # ボーレート[GBaud]\n",
    "    Ledfa = 100  # EDFAスパン[km]\n",
    "    stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "    gamma = 2.8  # 非線形係数[/W/km]\n",
    "    D = 16  # 分散パラメータ[ps/nm/km]\n",
    "    Alpha = 0.16  # 伝送損失[dB/km]\n",
    "    NF = 4  # ASE雑音指数[dB]\n",
    "    ase = True  # ASE雑音を考慮するか\n",
    "\n",
    "    # 指定した学習条件と伝送条件\n",
    "    trans_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                                    gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "\n",
    "    x, y, _, _ = load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    \n",
    "    # 平均,標準偏差の計算\n",
    "    mean = np.mean(x)\n",
    "    std = np.std(x)\n",
    "    \n",
    "    model = CVNN(input_dim=sampling*tap, output_dim=1, hidden_neuron=neuron, activation=activation).to(device)\n",
    "\n",
    "    # dataset, dataloaderの作成\n",
    "    train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "    train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    dataloaders_dict = {'train': train_dataloader}\n",
    "\n",
    "    # 損失関数, オプティマイザの作成\n",
    "    criterion = EVMLoss()\n",
    "    optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "    # モデルのトレーニング\n",
    "    model = train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#結果と条件を../data/params/CVNN.csvに保存する\n",
    "def train_cvnn_with_save(model_info, signal_info, tap, PdBm):\n",
    "    device = torch.device('cpu') #'cuda' if torch.cuda.is_available() else \n",
    "    print('Device available now:', device)\n",
    "    \n",
    "    lc = model_info['linear_compensation']\n",
    "    sampling = model_info['sampling']\n",
    "    #tap = model_info['tap']\n",
    "    batch_size = model_info['batch_size']\n",
    "    neuron = model_info['neuron']\n",
    "    epochs = model_info['epochs']\n",
    "    lr = model_info['lr']\n",
    "    activation = model_info['activation']\n",
    "    form = model_info['form']\n",
    "    #PdBm = model_info['PdBm']\n",
    "    Lmax = model_info['Lmax']\n",
    "    \n",
    "    max_tap = 501\n",
    "    n = 32  # 1シンボルあたりのサンプリング数[/symbol]\n",
    "    equalize = False  # 各シンボル数を均等にするか\n",
    "    baudrate = 28  # ボーレート[GBaud]\n",
    "    Ledfa = 100  # EDFAスパン[km]\n",
    "    stepedfa = 30  # SSFMの繰り返し計算ステップ数\n",
    "    gamma = 2.8  # 非線形係数[/W/km]\n",
    "    D = 16  # 分散パラメータ[ps/nm/km]\n",
    "    Alpha = 0.16  # 伝送損失[dB/km]\n",
    "    NF = 4  # ASE雑音指数[dB]\n",
    "    ase = True  # ASE雑音を考慮するか\n",
    "\n",
    "    # 指定した学習条件と伝送条件\n",
    "    learn_condition = 'linear_compensation=='+str(lc)+'&sampling=='+str(sampling)+'&tap=='+str(tap)+'&max_tap=='+str(max_tap)+'&batch_size=='+str(batch_size)+'&neuron=='+str(neuron)+'&learning_rate=='+str(lr)+'&activation==\"'+str(activation)+'\"'\n",
    "    trans_condition = 'form==\"'+str(form)+'\"&n=='+str(n)+'&equalize=='+str(equalize)+'&baudrate=='+str(baudrate)+'&PdBm=='+str(PdBm)+'&Ledfa=='+str(Ledfa)+'&stepedfa=='+str(stepedfa)+'&\\\n",
    "                                    gamma=='+str(gamma)+'&D=='+str(D)+'&Alpha=='+str(Alpha)+'&NF=='+str(NF)+'&ase=='+str(ase)\n",
    "    \n",
    "    x, y, signal_condition, signal_list = load_signal(signal_info, trans_condition, lc, sampling, tap, max_tap, n, Lmax)\n",
    "    if x is not None:\n",
    "        model, l_df_dir, trained_epochs = load_model(learn_condition, trans_condition, signal_condition, device, sampling, tap, neuron, epochs, activation, Lmax)\n",
    "        \n",
    "        if model is not None:\n",
    "            train_samples = len(x)\n",
    "    \n",
    "            # 平均,標準偏差の計算\n",
    "            mean = np.mean(x)\n",
    "            std = np.std(x)\n",
    "            \n",
    "            # dataset, dataloaderの作成\n",
    "            train_dataset = Dataset(x=x, y=y, mean=mean, std=std)\n",
    "            train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            dataloaders_dict = {'train': train_dataloader}\n",
    "\n",
    "            # 損失関数, オプティマイザの作成\n",
    "            criterion = EVMLoss()\n",
    "            optimizer = optim.Adam(params=model.parameters(), lr=lr)\n",
    "\n",
    "            # モデルのトレーニング(50epochsずつ学習し、50epochsずつパラメータを保存する)\n",
    "            for epoch in range(trained_epochs, epochs, 50):\n",
    "                model = train_model(device=device, model=model, dataloaders_dict=dataloaders_dict, criterion=criterion, optimizer=optimizer, epochs=50, epochs_section=[epoch, epochs])\n",
    "\n",
    "                # 学習済みパラメータを保存し、CVNN.csvに保存先を記入する\n",
    "                l_df = pd.read_csv(l_df_dir, index_col=0)\n",
    "                params_path = '../data/params/CVNN/params_' + str(len(l_df)).zfill(10) + '.pth'\n",
    "                torch.save(model.state_dict(), params_path)\n",
    "                sr = pd.Series([lc, sampling, tap, max_tap, batch_size, neuron, epoch + 50, lr, activation] + signal_list + [form, n, equalize, baudrate, PdBm, Ledfa, stepedfa, gamma, D, Alpha, NF, Lmax, ase, params_path, train_samples], index=l_df.columns)\n",
    "                l_df = l_df.append(sr, ignore_index=True)\n",
    "                l_df.to_csv(l_df_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n",
      "0:00:06 | Epoch: 1/500 | train Loss: 0.3399 | EVM: 39.63\n",
      "0:00:06 | Epoch: 2/500 | train Loss: 0.1769 | EVM: 17.74\n",
      "0:00:06 | Epoch: 3/500 | train Loss: 0.154 | EVM: 15.44\n",
      "0:00:06 | Epoch: 4/500 | train Loss: 0.1434 | EVM: 14.37\n",
      "0:00:06 | Epoch: 5/500 | train Loss: 0.1353 | EVM: 13.56\n",
      "0:00:06 | Epoch: 6/500 | train Loss: 0.1305 | EVM: 13.08\n",
      "0:00:06 | Epoch: 7/500 | train Loss: 0.1271 | EVM: 12.74\n",
      "0:00:06 | Epoch: 8/500 | train Loss: 0.1238 | EVM: 12.4\n",
      "0:00:06 | Epoch: 9/500 | train Loss: 0.1225 | EVM: 12.27\n",
      "0:00:06 | Epoch: 10/500 | train Loss: 0.1186 | EVM: 11.88\n",
      "0:00:06 | Epoch: 11/500 | train Loss: 0.1177 | EVM: 11.8\n",
      "0:00:06 | Epoch: 12/500 | train Loss: 0.1193 | EVM: 11.95\n",
      "0:00:06 | Epoch: 13/500 | train Loss: 0.1127 | EVM: 11.3\n",
      "0:00:06 | Epoch: 14/500 | train Loss: 0.1117 | EVM: 11.2\n",
      "0:00:06 | Epoch: 15/500 | train Loss: 0.1126 | EVM: 11.28\n",
      "0:00:06 | Epoch: 16/500 | train Loss: 0.1089 | EVM: 10.92\n",
      "0:00:06 | Epoch: 17/500 | train Loss: 0.1096 | EVM: 10.98\n",
      "0:00:05 | Epoch: 18/500 | train Loss: 0.1061 | EVM: 10.63\n",
      "0:00:06 | Epoch: 19/500 | train Loss: 0.1072 | EVM: 10.75\n",
      "0:00:06 | Epoch: 20/500 | train Loss: 0.1057 | EVM: 10.59\n",
      "0:00:06 | Epoch: 21/500 | train Loss: 0.1019 | EVM: 10.22\n",
      "0:00:06 | Epoch: 22/500 | train Loss: 0.104 | EVM: 10.42\n",
      "0:00:05 | Epoch: 23/500 | train Loss: 0.1025 | EVM: 10.28\n",
      "0:00:05 | Epoch: 24/500 | train Loss: 0.1003 | EVM: 10.05\n",
      "0:00:06 | Epoch: 25/500 | train Loss: 0.09885 | EVM: 9.907\n",
      "0:00:06 | Epoch: 26/500 | train Loss: 0.09747 | EVM: 9.768\n",
      "0:00:06 | Epoch: 27/500 | train Loss: 0.0993 | EVM: 9.959\n",
      "0:00:06 | Epoch: 28/500 | train Loss: 0.09785 | EVM: 9.809\n",
      "0:00:06 | Epoch: 29/500 | train Loss: 0.09952 | EVM: 9.968\n",
      "0:00:06 | Epoch: 30/500 | train Loss: 0.09421 | EVM: 9.438\n",
      "0:00:06 | Epoch: 31/500 | train Loss: 0.09714 | EVM: 9.73\n",
      "0:00:06 | Epoch: 32/500 | train Loss: 0.09448 | EVM: 9.467\n",
      "0:00:07 | Epoch: 33/500 | train Loss: 0.09638 | EVM: 9.66\n",
      "0:00:07 | Epoch: 34/500 | train Loss: 0.09252 | EVM: 9.273\n",
      "0:00:07 | Epoch: 35/500 | train Loss: 0.09343 | EVM: 9.366\n",
      "0:00:06 | Epoch: 36/500 | train Loss: 0.09269 | EVM: 9.292\n",
      "0:00:06 | Epoch: 37/500 | train Loss: 0.09128 | EVM: 9.147\n",
      "0:00:06 | Epoch: 38/500 | train Loss: 0.0917 | EVM: 9.188\n",
      "0:00:06 | Epoch: 39/500 | train Loss: 0.08939 | EVM: 8.957\n",
      "0:00:07 | Epoch: 40/500 | train Loss: 0.09086 | EVM: 9.109\n",
      "0:00:08 | Epoch: 41/500 | train Loss: 0.08911 | EVM: 8.93\n",
      "0:00:08 | Epoch: 42/500 | train Loss: 0.08876 | EVM: 8.897\n",
      "0:00:08 | Epoch: 43/500 | train Loss: 0.09015 | EVM: 9.052\n",
      "0:00:08 | Epoch: 44/500 | train Loss: 0.08634 | EVM: 8.651\n",
      "0:00:08 | Epoch: 45/500 | train Loss: 0.08594 | EVM: 8.612\n",
      "0:00:08 | Epoch: 46/500 | train Loss: 0.08547 | EVM: 8.566\n",
      "0:00:09 | Epoch: 47/500 | train Loss: 0.08692 | EVM: 8.714\n",
      "0:00:08 | Epoch: 48/500 | train Loss: 0.08784 | EVM: 8.803\n",
      "0:00:08 | Epoch: 49/500 | train Loss: 0.08653 | EVM: 8.672\n",
      "0:00:08 | Epoch: 50/500 | train Loss: 0.08465 | EVM: 8.48\n",
      "0:00:09 | Epoch: 51/500 | train Loss: 0.08473 | EVM: 8.492\n",
      "0:00:08 | Epoch: 52/500 | train Loss: 0.08289 | EVM: 8.306\n",
      "0:00:08 | Epoch: 53/500 | train Loss: 0.08325 | EVM: 8.345\n",
      "0:00:08 | Epoch: 54/500 | train Loss: 0.0874 | EVM: 8.786\n",
      "0:00:08 | Epoch: 55/500 | train Loss: 0.0856 | EVM: 8.578\n",
      "0:00:08 | Epoch: 56/500 | train Loss: 0.08687 | EVM: 8.713\n",
      "0:00:08 | Epoch: 57/500 | train Loss: 0.08389 | EVM: 8.409\n",
      "0:00:08 | Epoch: 58/500 | train Loss: 0.08456 | EVM: 8.482\n",
      "0:00:08 | Epoch: 59/500 | train Loss: 0.07992 | EVM: 8.006\n",
      "0:00:08 | Epoch: 60/500 | train Loss: 0.08205 | EVM: 8.225\n",
      "0:00:08 | Epoch: 61/500 | train Loss: 0.08335 | EVM: 8.354\n",
      "0:00:08 | Epoch: 62/500 | train Loss: 0.08091 | EVM: 8.105\n",
      "0:00:08 | Epoch: 63/500 | train Loss: 0.08014 | EVM: 8.037\n",
      "0:00:08 | Epoch: 64/500 | train Loss: 0.08107 | EVM: 8.121\n",
      "0:00:08 | Epoch: 65/500 | train Loss: 0.07971 | EVM: 7.989\n",
      "0:00:08 | Epoch: 66/500 | train Loss: 0.07903 | EVM: 7.918\n",
      "0:00:08 | Epoch: 67/500 | train Loss: 0.07938 | EVM: 7.954\n",
      "0:00:08 | Epoch: 68/500 | train Loss: 0.08044 | EVM: 8.064\n",
      "0:00:08 | Epoch: 69/500 | train Loss: 0.07909 | EVM: 7.927\n",
      "0:00:08 | Epoch: 70/500 | train Loss: 0.07918 | EVM: 7.935\n",
      "0:00:07 | Epoch: 71/500 | train Loss: 0.07859 | EVM: 7.89\n",
      "0:00:06 | Epoch: 72/500 | train Loss: 0.07767 | EVM: 7.781\n",
      "0:00:08 | Epoch: 73/500 | train Loss: 0.07888 | EVM: 7.907\n",
      "0:00:08 | Epoch: 74/500 | train Loss: 0.08084 | EVM: 8.113\n",
      "0:00:08 | Epoch: 75/500 | train Loss: 0.08145 | EVM: 8.166\n",
      "0:00:08 | Epoch: 76/500 | train Loss: 0.07804 | EVM: 7.824\n",
      "0:00:08 | Epoch: 77/500 | train Loss: 0.07807 | EVM: 7.829\n",
      "0:00:08 | Epoch: 78/500 | train Loss: 0.07519 | EVM: 7.537\n",
      "0:00:08 | Epoch: 79/500 | train Loss: 0.07657 | EVM: 7.677\n",
      "0:00:08 | Epoch: 80/500 | train Loss: 0.07507 | EVM: 7.526\n",
      "0:00:08 | Epoch: 81/500 | train Loss: 0.07615 | EVM: 7.63\n",
      "0:00:08 | Epoch: 82/500 | train Loss: 0.07548 | EVM: 7.569\n",
      "0:00:08 | Epoch: 83/500 | train Loss: 0.07818 | EVM: 7.839\n",
      "0:00:08 | Epoch: 84/500 | train Loss: 0.07585 | EVM: 7.603\n",
      "0:00:08 | Epoch: 85/500 | train Loss: 0.07346 | EVM: 7.36\n",
      "0:00:08 | Epoch: 86/500 | train Loss: 0.07534 | EVM: 7.555\n",
      "0:00:08 | Epoch: 87/500 | train Loss: 0.07332 | EVM: 7.352\n",
      "0:00:08 | Epoch: 88/500 | train Loss: 0.07365 | EVM: 7.381\n",
      "0:00:08 | Epoch: 89/500 | train Loss: 0.07365 | EVM: 7.385\n",
      "0:00:08 | Epoch: 90/500 | train Loss: 0.07594 | EVM: 7.615\n",
      "0:00:08 | Epoch: 91/500 | train Loss: 0.07571 | EVM: 7.594\n",
      "0:00:08 | Epoch: 92/500 | train Loss: 0.07484 | EVM: 7.511\n",
      "0:00:08 | Epoch: 93/500 | train Loss: 0.07284 | EVM: 7.302\n",
      "0:00:08 | Epoch: 94/500 | train Loss: 0.07166 | EVM: 7.18\n",
      "0:00:08 | Epoch: 95/500 | train Loss: 0.07182 | EVM: 7.201\n",
      "0:00:08 | Epoch: 96/500 | train Loss: 0.07276 | EVM: 7.297\n",
      "0:00:08 | Epoch: 97/500 | train Loss: 0.07168 | EVM: 7.188\n",
      "0:00:08 | Epoch: 98/500 | train Loss: 0.07333 | EVM: 7.35\n",
      "0:00:08 | Epoch: 99/500 | train Loss: 0.07402 | EVM: 7.422\n",
      "0:00:08 | Epoch: 100/500 | train Loss: 0.07069 | EVM: 7.084\n",
      "0:00:08 | Epoch: 101/500 | train Loss: 0.07121 | EVM: 7.141\n",
      "0:00:08 | Epoch: 102/500 | train Loss: 0.0717 | EVM: 7.188\n",
      "0:00:08 | Epoch: 103/500 | train Loss: 0.07262 | EVM: 7.288\n",
      "0:00:08 | Epoch: 104/500 | train Loss: 0.07355 | EVM: 7.381\n",
      "0:00:08 | Epoch: 105/500 | train Loss: 0.07447 | EVM: 7.471\n",
      "0:00:08 | Epoch: 106/500 | train Loss: 0.0687 | EVM: 6.891\n",
      "0:00:08 | Epoch: 107/500 | train Loss: 0.07132 | EVM: 7.157\n",
      "0:00:08 | Epoch: 108/500 | train Loss: 0.06931 | EVM: 6.954\n",
      "0:00:08 | Epoch: 109/500 | train Loss: 0.07029 | EVM: 7.052\n",
      "0:00:08 | Epoch: 110/500 | train Loss: 0.06899 | EVM: 6.915\n",
      "0:00:08 | Epoch: 111/500 | train Loss: 0.07052 | EVM: 7.071\n",
      "0:00:08 | Epoch: 112/500 | train Loss: 0.07323 | EVM: 7.357\n",
      "0:00:08 | Epoch: 113/500 | train Loss: 0.06845 | EVM: 6.865\n",
      "0:00:08 | Epoch: 114/500 | train Loss: 0.06749 | EVM: 6.767\n",
      "0:00:08 | Epoch: 115/500 | train Loss: 0.06945 | EVM: 6.961\n",
      "0:00:08 | Epoch: 116/500 | train Loss: 0.06943 | EVM: 6.972\n",
      "0:00:08 | Epoch: 117/500 | train Loss: 0.06981 | EVM: 7.004\n",
      "0:00:08 | Epoch: 118/500 | train Loss: 0.07166 | EVM: 7.196\n",
      "0:00:08 | Epoch: 119/500 | train Loss: 0.0689 | EVM: 6.914\n",
      "0:00:08 | Epoch: 120/500 | train Loss: 0.06693 | EVM: 6.72\n",
      "0:00:08 | Epoch: 121/500 | train Loss: 0.0677 | EVM: 6.789\n",
      "0:00:08 | Epoch: 122/500 | train Loss: 0.06525 | EVM: 6.544\n",
      "0:00:08 | Epoch: 123/500 | train Loss: 0.06924 | EVM: 6.949\n",
      "0:00:08 | Epoch: 124/500 | train Loss: 0.06808 | EVM: 6.832\n",
      "0:00:08 | Epoch: 125/500 | train Loss: 0.06485 | EVM: 6.498\n",
      "0:00:08 | Epoch: 126/500 | train Loss: 0.0692 | EVM: 6.942\n",
      "0:00:08 | Epoch: 127/500 | train Loss: 0.06782 | EVM: 6.806\n",
      "0:00:08 | Epoch: 128/500 | train Loss: 0.06571 | EVM: 6.588\n",
      "0:00:08 | Epoch: 129/500 | train Loss: 0.06724 | EVM: 6.743\n",
      "0:00:08 | Epoch: 130/500 | train Loss: 0.06582 | EVM: 6.597\n",
      "0:00:08 | Epoch: 131/500 | train Loss: 0.06576 | EVM: 6.596\n",
      "0:00:08 | Epoch: 132/500 | train Loss: 0.06734 | EVM: 6.753\n",
      "0:00:08 | Epoch: 133/500 | train Loss: 0.06835 | EVM: 6.874\n",
      "0:00:08 | Epoch: 134/500 | train Loss: 0.06978 | EVM: 7.008\n",
      "0:00:08 | Epoch: 135/500 | train Loss: 0.06647 | EVM: 6.666\n",
      "0:00:08 | Epoch: 136/500 | train Loss: 0.06778 | EVM: 6.807\n",
      "0:00:08 | Epoch: 137/500 | train Loss: 0.0681 | EVM: 6.837\n",
      "0:00:08 | Epoch: 138/500 | train Loss: 0.06676 | EVM: 6.693\n",
      "0:00:08 | Epoch: 139/500 | train Loss: 0.06626 | EVM: 6.651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:09 | Epoch: 140/500 | train Loss: 0.06601 | EVM: 6.618\n",
      "0:00:08 | Epoch: 141/500 | train Loss: 0.06674 | EVM: 6.7\n",
      "0:00:08 | Epoch: 142/500 | train Loss: 0.06612 | EVM: 6.628\n",
      "0:00:08 | Epoch: 143/500 | train Loss: 0.06911 | EVM: 6.94\n",
      "0:00:08 | Epoch: 144/500 | train Loss: 0.06779 | EVM: 6.802\n",
      "0:00:08 | Epoch: 145/500 | train Loss: 0.06603 | EVM: 6.63\n",
      "0:00:08 | Epoch: 146/500 | train Loss: 0.06638 | EVM: 6.658\n",
      "0:00:08 | Epoch: 147/500 | train Loss: 0.06492 | EVM: 6.511\n",
      "0:00:08 | Epoch: 148/500 | train Loss: 0.06507 | EVM: 6.529\n",
      "0:00:08 | Epoch: 149/500 | train Loss: 0.06342 | EVM: 6.361\n",
      "0:00:08 | Epoch: 150/500 | train Loss: 0.06803 | EVM: 6.834\n",
      "0:00:09 | Epoch: 151/500 | train Loss: 0.06753 | EVM: 6.779\n",
      "0:00:08 | Epoch: 152/500 | train Loss: 0.06446 | EVM: 6.472\n",
      "0:00:08 | Epoch: 153/500 | train Loss: 0.06487 | EVM: 6.511\n",
      "0:00:08 | Epoch: 154/500 | train Loss: 0.06689 | EVM: 6.713\n",
      "0:00:08 | Epoch: 155/500 | train Loss: 0.06523 | EVM: 6.547\n",
      "0:00:08 | Epoch: 156/500 | train Loss: 0.06659 | EVM: 6.703\n",
      "0:00:08 | Epoch: 157/500 | train Loss: 0.0672 | EVM: 6.749\n",
      "0:00:08 | Epoch: 158/500 | train Loss: 0.06389 | EVM: 6.409\n",
      "0:00:08 | Epoch: 159/500 | train Loss: 0.06244 | EVM: 6.261\n",
      "0:00:08 | Epoch: 160/500 | train Loss: 0.06353 | EVM: 6.37\n",
      "0:00:08 | Epoch: 161/500 | train Loss: 0.06493 | EVM: 6.517\n",
      "0:00:08 | Epoch: 162/500 | train Loss: 0.06227 | EVM: 6.243\n",
      "0:00:08 | Epoch: 163/500 | train Loss: 0.06425 | EVM: 6.451\n",
      "0:00:08 | Epoch: 164/500 | train Loss: 0.0662 | EVM: 6.643\n",
      "0:00:08 | Epoch: 165/500 | train Loss: 0.064 | EVM: 6.419\n",
      "0:00:08 | Epoch: 166/500 | train Loss: 0.06336 | EVM: 6.356\n",
      "0:00:08 | Epoch: 167/500 | train Loss: 0.06412 | EVM: 6.451\n",
      "0:00:08 | Epoch: 168/500 | train Loss: 0.06539 | EVM: 6.558\n",
      "0:00:08 | Epoch: 169/500 | train Loss: 0.06459 | EVM: 6.478\n",
      "0:00:08 | Epoch: 170/500 | train Loss: 0.06328 | EVM: 6.349\n",
      "0:00:08 | Epoch: 171/500 | train Loss: 0.06113 | EVM: 6.134\n",
      "0:00:08 | Epoch: 172/500 | train Loss: 0.06361 | EVM: 6.383\n",
      "0:00:08 | Epoch: 173/500 | train Loss: 0.06578 | EVM: 6.605\n",
      "0:00:08 | Epoch: 174/500 | train Loss: 0.06073 | EVM: 6.088\n",
      "0:00:08 | Epoch: 175/500 | train Loss: 0.06374 | EVM: 6.392\n",
      "0:00:08 | Epoch: 176/500 | train Loss: 0.06716 | EVM: 6.742\n",
      "0:00:08 | Epoch: 177/500 | train Loss: 0.06492 | EVM: 6.523\n",
      "0:00:08 | Epoch: 178/500 | train Loss: 0.06225 | EVM: 6.247\n",
      "0:00:08 | Epoch: 179/500 | train Loss: 0.0656 | EVM: 6.623\n",
      "0:00:08 | Epoch: 180/500 | train Loss: 0.06197 | EVM: 6.226\n",
      "0:00:08 | Epoch: 181/500 | train Loss: 0.06397 | EVM: 6.423\n",
      "0:00:08 | Epoch: 182/500 | train Loss: 0.06187 | EVM: 6.216\n",
      "0:00:08 | Epoch: 183/500 | train Loss: 0.06235 | EVM: 6.261\n",
      "0:00:08 | Epoch: 184/500 | train Loss: 0.06215 | EVM: 6.243\n",
      "0:00:08 | Epoch: 185/500 | train Loss: 0.06105 | EVM: 6.123\n",
      "0:00:08 | Epoch: 186/500 | train Loss: 0.06398 | EVM: 6.422\n",
      "0:00:09 | Epoch: 187/500 | train Loss: 0.0634 | EVM: 6.364\n",
      "0:00:08 | Epoch: 188/500 | train Loss: 0.06084 | EVM: 6.101\n",
      "0:00:08 | Epoch: 189/500 | train Loss: 0.06276 | EVM: 6.296\n",
      "0:00:08 | Epoch: 190/500 | train Loss: 0.06102 | EVM: 6.12\n",
      "0:00:08 | Epoch: 191/500 | train Loss: 0.06079 | EVM: 6.098\n",
      "0:00:08 | Epoch: 192/500 | train Loss: 0.06403 | EVM: 6.428\n",
      "0:00:08 | Epoch: 193/500 | train Loss: 0.06194 | EVM: 6.213\n",
      "0:00:08 | Epoch: 194/500 | train Loss: 0.06032 | EVM: 6.052\n",
      "0:00:09 | Epoch: 195/500 | train Loss: 0.06369 | EVM: 6.399\n",
      "0:00:08 | Epoch: 196/500 | train Loss: 0.06071 | EVM: 6.088\n",
      "0:00:08 | Epoch: 197/500 | train Loss: 0.06139 | EVM: 6.16\n",
      "0:00:08 | Epoch: 198/500 | train Loss: 0.0588 | EVM: 5.9\n",
      "0:00:08 | Epoch: 199/500 | train Loss: 0.0618 | EVM: 6.214\n",
      "0:00:08 | Epoch: 200/500 | train Loss: 0.06242 | EVM: 6.266\n",
      "0:00:08 | Epoch: 201/500 | train Loss: 0.06459 | EVM: 6.496\n",
      "0:00:08 | Epoch: 202/500 | train Loss: 0.06512 | EVM: 6.554\n",
      "0:00:08 | Epoch: 203/500 | train Loss: 0.05981 | EVM: 6.001\n",
      "0:00:08 | Epoch: 204/500 | train Loss: 0.06046 | EVM: 6.068\n",
      "0:00:08 | Epoch: 205/500 | train Loss: 0.06029 | EVM: 6.049\n",
      "0:00:09 | Epoch: 206/500 | train Loss: 0.06118 | EVM: 6.141\n",
      "0:00:08 | Epoch: 207/500 | train Loss: 0.06145 | EVM: 6.166\n",
      "0:00:08 | Epoch: 208/500 | train Loss: 0.06021 | EVM: 6.039\n",
      "0:00:08 | Epoch: 209/500 | train Loss: 0.05989 | EVM: 6.007\n",
      "0:00:08 | Epoch: 210/500 | train Loss: 0.05938 | EVM: 5.96\n",
      "0:00:08 | Epoch: 211/500 | train Loss: 0.06044 | EVM: 6.066\n",
      "0:00:08 | Epoch: 212/500 | train Loss: 0.06111 | EVM: 6.147\n",
      "0:00:08 | Epoch: 213/500 | train Loss: 0.06104 | EVM: 6.121\n",
      "0:00:08 | Epoch: 214/500 | train Loss: 0.06302 | EVM: 6.329\n",
      "0:00:08 | Epoch: 215/500 | train Loss: 0.06405 | EVM: 6.441\n",
      "0:00:08 | Epoch: 216/500 | train Loss: 0.06093 | EVM: 6.116\n",
      "0:00:08 | Epoch: 217/500 | train Loss: 0.05861 | EVM: 5.885\n",
      "0:00:08 | Epoch: 218/500 | train Loss: 0.06237 | EVM: 6.271\n",
      "0:00:08 | Epoch: 219/500 | train Loss: 0.05934 | EVM: 5.949\n",
      "0:00:08 | Epoch: 220/500 | train Loss: 0.06135 | EVM: 6.16\n",
      "0:00:08 | Epoch: 221/500 | train Loss: 0.05901 | EVM: 5.919\n",
      "0:00:08 | Epoch: 222/500 | train Loss: 0.05868 | EVM: 5.887\n",
      "0:00:08 | Epoch: 223/500 | train Loss: 0.06066 | EVM: 6.088\n",
      "0:00:08 | Epoch: 224/500 | train Loss: 0.05936 | EVM: 5.961\n",
      "0:00:08 | Epoch: 225/500 | train Loss: 0.05974 | EVM: 6.01\n",
      "0:00:08 | Epoch: 226/500 | train Loss: 0.05893 | EVM: 5.913\n",
      "0:00:08 | Epoch: 227/500 | train Loss: 0.05812 | EVM: 5.831\n",
      "0:00:08 | Epoch: 228/500 | train Loss: 0.05863 | EVM: 5.879\n",
      "0:00:08 | Epoch: 229/500 | train Loss: 0.06306 | EVM: 6.341\n",
      "0:00:08 | Epoch: 230/500 | train Loss: 0.05904 | EVM: 5.925\n",
      "0:00:08 | Epoch: 231/500 | train Loss: 0.06051 | EVM: 6.077\n",
      "0:00:08 | Epoch: 232/500 | train Loss: 0.06006 | EVM: 6.026\n",
      "0:00:08 | Epoch: 233/500 | train Loss: 0.0601 | EVM: 6.035\n",
      "0:00:08 | Epoch: 234/500 | train Loss: 0.06102 | EVM: 6.122\n",
      "0:00:08 | Epoch: 235/500 | train Loss: 0.0586 | EVM: 5.886\n",
      "0:00:08 | Epoch: 236/500 | train Loss: 0.05924 | EVM: 5.949\n",
      "0:00:08 | Epoch: 237/500 | train Loss: 0.05801 | EVM: 5.825\n",
      "0:00:08 | Epoch: 238/500 | train Loss: 0.05912 | EVM: 5.943\n",
      "0:00:08 | Epoch: 239/500 | train Loss: 0.06071 | EVM: 6.098\n",
      "0:00:08 | Epoch: 240/500 | train Loss: 0.05948 | EVM: 5.967\n",
      "0:00:08 | Epoch: 241/500 | train Loss: 0.05878 | EVM: 5.907\n",
      "0:00:08 | Epoch: 242/500 | train Loss: 0.05815 | EVM: 5.834\n",
      "0:00:08 | Epoch: 243/500 | train Loss: 0.06024 | EVM: 6.051\n",
      "0:00:08 | Epoch: 244/500 | train Loss: 0.05884 | EVM: 5.904\n",
      "0:00:08 | Epoch: 245/500 | train Loss: 0.06096 | EVM: 6.133\n",
      "0:00:08 | Epoch: 246/500 | train Loss: 0.05746 | EVM: 5.77\n",
      "0:00:08 | Epoch: 247/500 | train Loss: 0.05739 | EVM: 5.753\n",
      "0:00:08 | Epoch: 248/500 | train Loss: 0.05801 | EVM: 5.824\n",
      "0:00:09 | Epoch: 249/500 | train Loss: 0.06195 | EVM: 6.221\n",
      "0:00:08 | Epoch: 250/500 | train Loss: 0.06021 | EVM: 6.051\n",
      "0:00:08 | Epoch: 251/500 | train Loss: 0.05826 | EVM: 5.848\n",
      "0:00:08 | Epoch: 252/500 | train Loss: 0.05742 | EVM: 5.764\n",
      "0:00:08 | Epoch: 253/500 | train Loss: 0.05737 | EVM: 5.762\n",
      "0:00:08 | Epoch: 254/500 | train Loss: 0.05817 | EVM: 5.846\n",
      "0:00:08 | Epoch: 255/500 | train Loss: 0.0606 | EVM: 6.09\n",
      "0:00:08 | Epoch: 256/500 | train Loss: 0.05947 | EVM: 5.977\n",
      "0:00:08 | Epoch: 257/500 | train Loss: 0.06095 | EVM: 6.116\n",
      "0:00:08 | Epoch: 258/500 | train Loss: 0.06038 | EVM: 6.068\n",
      "0:00:08 | Epoch: 259/500 | train Loss: 0.05841 | EVM: 5.857\n",
      "0:00:08 | Epoch: 260/500 | train Loss: 0.06141 | EVM: 6.175\n",
      "0:00:08 | Epoch: 261/500 | train Loss: 0.05836 | EVM: 5.857\n",
      "0:00:08 | Epoch: 262/500 | train Loss: 0.06085 | EVM: 6.115\n",
      "0:00:08 | Epoch: 263/500 | train Loss: 0.06048 | EVM: 6.078\n",
      "0:00:08 | Epoch: 264/500 | train Loss: 0.05695 | EVM: 5.715\n",
      "0:00:08 | Epoch: 265/500 | train Loss: 0.05661 | EVM: 5.677\n",
      "0:00:08 | Epoch: 266/500 | train Loss: 0.05815 | EVM: 5.835\n",
      "0:00:08 | Epoch: 267/500 | train Loss: 0.05773 | EVM: 5.791\n",
      "0:00:08 | Epoch: 268/500 | train Loss: 0.05872 | EVM: 5.894\n",
      "0:00:08 | Epoch: 269/500 | train Loss: 0.05987 | EVM: 6.022\n",
      "0:00:09 | Epoch: 270/500 | train Loss: 0.05792 | EVM: 5.815\n",
      "0:00:08 | Epoch: 271/500 | train Loss: 0.05605 | EVM: 5.628\n",
      "0:00:08 | Epoch: 272/500 | train Loss: 0.05931 | EVM: 5.952\n",
      "0:00:08 | Epoch: 273/500 | train Loss: 0.06181 | EVM: 6.206\n",
      "0:00:08 | Epoch: 274/500 | train Loss: 0.05961 | EVM: 6.006\n",
      "0:00:08 | Epoch: 275/500 | train Loss: 0.05874 | EVM: 5.905\n",
      "0:00:08 | Epoch: 276/500 | train Loss: 0.05672 | EVM: 5.694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:08 | Epoch: 277/500 | train Loss: 0.05625 | EVM: 5.647\n",
      "0:00:08 | Epoch: 278/500 | train Loss: 0.05544 | EVM: 5.567\n",
      "0:00:08 | Epoch: 279/500 | train Loss: 0.05864 | EVM: 5.889\n",
      "0:00:08 | Epoch: 280/500 | train Loss: 0.05766 | EVM: 5.788\n",
      "0:00:09 | Epoch: 281/500 | train Loss: 0.06046 | EVM: 6.072\n",
      "0:00:08 | Epoch: 282/500 | train Loss: 0.05712 | EVM: 5.733\n",
      "0:00:08 | Epoch: 283/500 | train Loss: 0.05642 | EVM: 5.67\n",
      "0:00:08 | Epoch: 284/500 | train Loss: 0.05804 | EVM: 5.833\n",
      "0:00:08 | Epoch: 285/500 | train Loss: 0.05928 | EVM: 5.955\n",
      "0:00:08 | Epoch: 286/500 | train Loss: 0.05687 | EVM: 5.71\n",
      "0:00:08 | Epoch: 287/500 | train Loss: 0.05532 | EVM: 5.569\n",
      "0:00:08 | Epoch: 288/500 | train Loss: 0.05747 | EVM: 5.787\n",
      "0:00:08 | Epoch: 289/500 | train Loss: 0.05816 | EVM: 5.841\n",
      "0:00:08 | Epoch: 290/500 | train Loss: 0.05616 | EVM: 5.639\n",
      "0:00:08 | Epoch: 291/500 | train Loss: 0.05654 | EVM: 5.678\n",
      "0:00:08 | Epoch: 292/500 | train Loss: 0.05618 | EVM: 5.651\n",
      "0:00:08 | Epoch: 293/500 | train Loss: 0.05527 | EVM: 5.546\n",
      "0:00:08 | Epoch: 294/500 | train Loss: 0.05873 | EVM: 5.904\n",
      "0:00:08 | Epoch: 295/500 | train Loss: 0.0585 | EVM: 5.876\n",
      "0:00:08 | Epoch: 296/500 | train Loss: 0.05457 | EVM: 5.477\n",
      "0:00:08 | Epoch: 297/500 | train Loss: 0.05689 | EVM: 5.719\n",
      "0:00:08 | Epoch: 298/500 | train Loss: 0.0568 | EVM: 5.722\n",
      "0:00:08 | Epoch: 299/500 | train Loss: 0.05614 | EVM: 5.634\n",
      "0:00:08 | Epoch: 300/500 | train Loss: 0.05775 | EVM: 5.802\n",
      "0:00:09 | Epoch: 301/500 | train Loss: 0.05571 | EVM: 5.598\n",
      "0:00:08 | Epoch: 302/500 | train Loss: 0.05689 | EVM: 5.717\n",
      "0:00:08 | Epoch: 303/500 | train Loss: 0.05675 | EVM: 5.699\n",
      "0:00:06 | Epoch: 304/500 | train Loss: 0.05889 | EVM: 5.922\n",
      "0:00:06 | Epoch: 305/500 | train Loss: 0.05756 | EVM: 5.793\n",
      "0:00:06 | Epoch: 306/500 | train Loss: 0.05715 | EVM: 5.74\n",
      "0:00:06 | Epoch: 307/500 | train Loss: 0.05471 | EVM: 5.494\n",
      "0:00:06 | Epoch: 308/500 | train Loss: 0.05708 | EVM: 5.745\n",
      "0:00:06 | Epoch: 309/500 | train Loss: 0.05979 | EVM: 6.028\n",
      "0:00:06 | Epoch: 310/500 | train Loss: 0.05554 | EVM: 5.579\n",
      "0:00:06 | Epoch: 311/500 | train Loss: 0.05955 | EVM: 5.981\n",
      "0:00:06 | Epoch: 312/500 | train Loss: 0.05671 | EVM: 5.703\n",
      "0:00:06 | Epoch: 313/500 | train Loss: 0.05885 | EVM: 5.923\n",
      "0:00:06 | Epoch: 314/500 | train Loss: 0.05606 | EVM: 5.636\n",
      "0:00:06 | Epoch: 315/500 | train Loss: 0.05489 | EVM: 5.508\n",
      "0:00:06 | Epoch: 316/500 | train Loss: 0.05723 | EVM: 5.763\n",
      "0:00:06 | Epoch: 317/500 | train Loss: 0.05692 | EVM: 5.715\n",
      "0:00:06 | Epoch: 318/500 | train Loss: 0.05865 | EVM: 5.899\n",
      "0:00:06 | Epoch: 319/500 | train Loss: 0.05709 | EVM: 5.734\n",
      "0:00:06 | Epoch: 320/500 | train Loss: 0.05539 | EVM: 5.564\n",
      "0:00:06 | Epoch: 321/500 | train Loss: 0.05853 | EVM: 5.887\n",
      "0:00:06 | Epoch: 322/500 | train Loss: 0.05694 | EVM: 5.737\n",
      "0:00:05 | Epoch: 323/500 | train Loss: 0.06065 | EVM: 6.109\n",
      "0:00:06 | Epoch: 324/500 | train Loss: 0.0572 | EVM: 5.75\n",
      "0:00:05 | Epoch: 325/500 | train Loss: 0.0543 | EVM: 5.452\n",
      "0:00:06 | Epoch: 326/500 | train Loss: 0.05733 | EVM: 5.756\n",
      "0:00:05 | Epoch: 327/500 | train Loss: 0.05607 | EVM: 5.649\n",
      "0:00:05 | Epoch: 328/500 | train Loss: 0.05526 | EVM: 5.548\n",
      "0:00:06 | Epoch: 329/500 | train Loss: 0.05646 | EVM: 5.673\n",
      "0:00:06 | Epoch: 330/500 | train Loss: 0.0548 | EVM: 5.505\n",
      "0:00:06 | Epoch: 331/500 | train Loss: 0.05461 | EVM: 5.487\n",
      "0:00:05 | Epoch: 332/500 | train Loss: 0.05344 | EVM: 5.366\n",
      "0:00:07 | Epoch: 333/500 | train Loss: 0.05804 | EVM: 5.833\n",
      "0:00:06 | Epoch: 334/500 | train Loss: 0.05668 | EVM: 5.704\n",
      "0:00:06 | Epoch: 335/500 | train Loss: 0.05682 | EVM: 5.701\n",
      "0:00:06 | Epoch: 336/500 | train Loss: 0.05742 | EVM: 5.761\n",
      "0:00:05 | Epoch: 337/500 | train Loss: 0.05603 | EVM: 5.633\n",
      "0:00:07 | Epoch: 338/500 | train Loss: 0.05514 | EVM: 5.534\n",
      "0:00:06 | Epoch: 339/500 | train Loss: 0.05663 | EVM: 5.697\n",
      "0:00:06 | Epoch: 340/500 | train Loss: 0.05516 | EVM: 5.545\n",
      "0:00:06 | Epoch: 341/500 | train Loss: 0.05518 | EVM: 5.541\n",
      "0:00:06 | Epoch: 342/500 | train Loss: 0.05325 | EVM: 5.35\n",
      "0:00:06 | Epoch: 343/500 | train Loss: 0.05248 | EVM: 5.264\n",
      "0:00:06 | Epoch: 344/500 | train Loss: 0.05342 | EVM: 5.362\n",
      "0:00:06 | Epoch: 345/500 | train Loss: 0.05313 | EVM: 5.332\n",
      "0:00:06 | Epoch: 346/500 | train Loss: 0.05499 | EVM: 5.528\n",
      "0:00:06 | Epoch: 347/500 | train Loss: 0.05659 | EVM: 5.684\n",
      "0:00:07 | Epoch: 348/500 | train Loss: 0.05487 | EVM: 5.509\n",
      "0:00:05 | Epoch: 349/500 | train Loss: 0.05648 | EVM: 5.679\n",
      "0:00:06 | Epoch: 350/500 | train Loss: 0.05542 | EVM: 5.559\n",
      "0:00:05 | Epoch: 351/500 | train Loss: 0.05348 | EVM: 5.372\n",
      "0:00:06 | Epoch: 352/500 | train Loss: 0.055 | EVM: 5.527\n",
      "0:00:06 | Epoch: 353/500 | train Loss: 0.05673 | EVM: 5.699\n",
      "0:00:06 | Epoch: 354/500 | train Loss: 0.05352 | EVM: 5.373\n",
      "0:00:06 | Epoch: 355/500 | train Loss: 0.05667 | EVM: 5.718\n",
      "0:00:06 | Epoch: 356/500 | train Loss: 0.05729 | EVM: 5.758\n",
      "0:00:05 | Epoch: 357/500 | train Loss: 0.05545 | EVM: 5.574\n",
      "0:00:06 | Epoch: 358/500 | train Loss: 0.05512 | EVM: 5.531\n",
      "0:00:06 | Epoch: 359/500 | train Loss: 0.05655 | EVM: 5.68\n",
      "0:00:06 | Epoch: 360/500 | train Loss: 0.05532 | EVM: 5.557\n",
      "0:00:06 | Epoch: 361/500 | train Loss: 0.05649 | EVM: 5.677\n",
      "0:00:06 | Epoch: 362/500 | train Loss: 0.05575 | EVM: 5.597\n",
      "0:00:05 | Epoch: 363/500 | train Loss: 0.05572 | EVM: 5.592\n",
      "0:00:06 | Epoch: 364/500 | train Loss: 0.05299 | EVM: 5.325\n",
      "0:00:05 | Epoch: 365/500 | train Loss: 0.054 | EVM: 5.425\n",
      "0:00:06 | Epoch: 366/500 | train Loss: 0.05705 | EVM: 5.741\n",
      "0:00:05 | Epoch: 367/500 | train Loss: 0.05515 | EVM: 5.54\n",
      "0:00:06 | Epoch: 368/500 | train Loss: 0.0539 | EVM: 5.408\n",
      "0:00:06 | Epoch: 369/500 | train Loss: 0.05218 | EVM: 5.241\n",
      "0:00:06 | Epoch: 370/500 | train Loss: 0.05339 | EVM: 5.361\n",
      "0:00:06 | Epoch: 371/500 | train Loss: 0.05302 | EVM: 5.321\n",
      "0:00:06 | Epoch: 372/500 | train Loss: 0.05657 | EVM: 5.694\n",
      "0:00:06 | Epoch: 373/500 | train Loss: 0.05579 | EVM: 5.599\n",
      "0:00:06 | Epoch: 374/500 | train Loss: 0.056 | EVM: 5.628\n",
      "0:00:06 | Epoch: 375/500 | train Loss: 0.05337 | EVM: 5.357\n",
      "0:00:05 | Epoch: 376/500 | train Loss: 0.05473 | EVM: 5.51\n",
      "0:00:06 | Epoch: 377/500 | train Loss: 0.05475 | EVM: 5.503\n",
      "0:00:06 | Epoch: 378/500 | train Loss: 0.05649 | EVM: 5.675\n",
      "0:00:06 | Epoch: 379/500 | train Loss: 0.05488 | EVM: 5.517\n",
      "0:00:06 | Epoch: 380/500 | train Loss: 0.05868 | EVM: 5.907\n",
      "0:00:05 | Epoch: 381/500 | train Loss: 0.05721 | EVM: 5.765\n",
      "0:00:06 | Epoch: 382/500 | train Loss: 0.05441 | EVM: 5.473\n",
      "0:00:06 | Epoch: 383/500 | train Loss: 0.05455 | EVM: 5.482\n",
      "0:00:06 | Epoch: 384/500 | train Loss: 0.05428 | EVM: 5.45\n",
      "0:00:06 | Epoch: 385/500 | train Loss: 0.05078 | EVM: 5.097\n",
      "0:00:05 | Epoch: 386/500 | train Loss: 0.05172 | EVM: 5.196\n",
      "0:00:06 | Epoch: 387/500 | train Loss: 0.05382 | EVM: 5.409\n",
      "0:00:05 | Epoch: 388/500 | train Loss: 0.05683 | EVM: 5.713\n",
      "0:00:06 | Epoch: 389/500 | train Loss: 0.05528 | EVM: 5.543\n",
      "0:00:06 | Epoch: 390/500 | train Loss: 0.05854 | EVM: 5.896\n",
      "0:00:05 | Epoch: 391/500 | train Loss: 0.0564 | EVM: 5.667\n",
      "0:00:06 | Epoch: 392/500 | train Loss: 0.05708 | EVM: 5.734\n",
      "0:00:06 | Epoch: 393/500 | train Loss: 0.05375 | EVM: 5.4\n",
      "0:00:06 | Epoch: 394/500 | train Loss: 0.05503 | EVM: 5.531\n",
      "0:00:05 | Epoch: 395/500 | train Loss: 0.05297 | EVM: 5.32\n",
      "0:00:06 | Epoch: 396/500 | train Loss: 0.055 | EVM: 5.531\n",
      "0:00:06 | Epoch: 397/500 | train Loss: 0.05433 | EVM: 5.462\n",
      "0:00:06 | Epoch: 398/500 | train Loss: 0.05442 | EVM: 5.457\n",
      "0:00:05 | Epoch: 399/500 | train Loss: 0.05081 | EVM: 5.106\n",
      "0:00:06 | Epoch: 400/500 | train Loss: 0.05474 | EVM: 5.503\n",
      "0:00:05 | Epoch: 401/500 | train Loss: 0.05147 | EVM: 5.167\n",
      "0:00:06 | Epoch: 402/500 | train Loss: 0.05528 | EVM: 5.553\n",
      "0:00:06 | Epoch: 403/500 | train Loss: 0.05598 | EVM: 5.628\n",
      "0:00:07 | Epoch: 404/500 | train Loss: 0.05653 | EVM: 5.684\n",
      "0:00:06 | Epoch: 405/500 | train Loss: 0.05825 | EVM: 5.883\n",
      "0:00:06 | Epoch: 406/500 | train Loss: 0.05308 | EVM: 5.328\n",
      "0:00:06 | Epoch: 407/500 | train Loss: 0.05473 | EVM: 5.501\n",
      "0:00:06 | Epoch: 408/500 | train Loss: 0.05405 | EVM: 5.434\n",
      "0:00:07 | Epoch: 409/500 | train Loss: 0.05183 | EVM: 5.207\n",
      "0:00:06 | Epoch: 410/500 | train Loss: 0.05281 | EVM: 5.316\n",
      "0:00:06 | Epoch: 411/500 | train Loss: 0.05262 | EVM: 5.283\n",
      "0:00:06 | Epoch: 412/500 | train Loss: 0.05537 | EVM: 5.56\n",
      "0:00:06 | Epoch: 413/500 | train Loss: 0.05401 | EVM: 5.428\n",
      "0:00:05 | Epoch: 414/500 | train Loss: 0.05368 | EVM: 5.398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:06 | Epoch: 415/500 | train Loss: 0.05018 | EVM: 5.039\n",
      "0:00:06 | Epoch: 416/500 | train Loss: 0.05166 | EVM: 5.187\n",
      "0:00:06 | Epoch: 417/500 | train Loss: 0.05665 | EVM: 5.69\n",
      "0:00:05 | Epoch: 418/500 | train Loss: 0.05468 | EVM: 5.492\n",
      "0:00:06 | Epoch: 419/500 | train Loss: 0.0543 | EVM: 5.463\n",
      "0:00:06 | Epoch: 420/500 | train Loss: 0.05201 | EVM: 5.229\n",
      "0:00:06 | Epoch: 421/500 | train Loss: 0.05211 | EVM: 5.231\n",
      "0:00:06 | Epoch: 422/500 | train Loss: 0.05577 | EVM: 5.605\n",
      "0:00:06 | Epoch: 423/500 | train Loss: 0.05461 | EVM: 5.488\n",
      "0:00:06 | Epoch: 424/500 | train Loss: 0.05532 | EVM: 5.568\n",
      "0:00:06 | Epoch: 425/500 | train Loss: 0.05281 | EVM: 5.299\n",
      "0:00:05 | Epoch: 426/500 | train Loss: 0.05344 | EVM: 5.373\n",
      "0:00:06 | Epoch: 427/500 | train Loss: 0.0541 | EVM: 5.439\n",
      "0:00:05 | Epoch: 428/500 | train Loss: 0.05254 | EVM: 5.276\n",
      "0:00:06 | Epoch: 429/500 | train Loss: 0.05517 | EVM: 5.551\n",
      "0:00:06 | Epoch: 430/500 | train Loss: 0.05405 | EVM: 5.428\n",
      "0:00:06 | Epoch: 431/500 | train Loss: 0.05545 | EVM: 5.58\n",
      "0:00:06 | Epoch: 432/500 | train Loss: 0.05191 | EVM: 5.217\n",
      "0:00:06 | Epoch: 433/500 | train Loss: 0.05852 | EVM: 5.881\n",
      "0:00:06 | Epoch: 434/500 | train Loss: 0.05662 | EVM: 5.689\n",
      "0:00:06 | Epoch: 435/500 | train Loss: 0.054 | EVM: 5.42\n",
      "0:00:06 | Epoch: 436/500 | train Loss: 0.05692 | EVM: 5.723\n",
      "0:00:06 | Epoch: 437/500 | train Loss: 0.05305 | EVM: 5.319\n",
      "0:00:06 | Epoch: 438/500 | train Loss: 0.05237 | EVM: 5.266\n",
      "0:00:06 | Epoch: 439/500 | train Loss: 0.05136 | EVM: 5.182\n",
      "0:00:06 | Epoch: 440/500 | train Loss: 0.05126 | EVM: 5.154\n",
      "0:00:05 | Epoch: 441/500 | train Loss: 0.05238 | EVM: 5.26\n",
      "0:00:06 | Epoch: 442/500 | train Loss: 0.05468 | EVM: 5.497\n",
      "0:00:05 | Epoch: 443/500 | train Loss: 0.0559 | EVM: 5.618\n",
      "0:00:06 | Epoch: 444/500 | train Loss: 0.05383 | EVM: 5.408\n",
      "0:00:06 | Epoch: 445/500 | train Loss: 0.05141 | EVM: 5.158\n",
      "0:00:06 | Epoch: 446/500 | train Loss: 0.05389 | EVM: 5.444\n",
      "0:00:06 | Epoch: 447/500 | train Loss: 0.05319 | EVM: 5.341\n",
      "0:00:06 | Epoch: 448/500 | train Loss: 0.05094 | EVM: 5.118\n",
      "0:00:06 | Epoch: 449/500 | train Loss: 0.05286 | EVM: 5.309\n",
      "0:00:05 | Epoch: 450/500 | train Loss: 0.05137 | EVM: 5.158\n",
      "0:00:06 | Epoch: 451/500 | train Loss: 0.05648 | EVM: 5.687\n",
      "0:00:05 | Epoch: 452/500 | train Loss: 0.05269 | EVM: 5.29\n",
      "0:00:06 | Epoch: 453/500 | train Loss: 0.05435 | EVM: 5.468\n",
      "0:00:06 | Epoch: 454/500 | train Loss: 0.05321 | EVM: 5.345\n",
      "0:00:06 | Epoch: 455/500 | train Loss: 0.05565 | EVM: 5.598\n",
      "0:00:05 | Epoch: 456/500 | train Loss: 0.05309 | EVM: 5.336\n",
      "0:00:05 | Epoch: 457/500 | train Loss: 0.0505 | EVM: 5.077\n",
      "0:00:06 | Epoch: 458/500 | train Loss: 0.05271 | EVM: 5.297\n",
      "0:00:06 | Epoch: 459/500 | train Loss: 0.05441 | EVM: 5.471\n",
      "0:00:06 | Epoch: 460/500 | train Loss: 0.05307 | EVM: 5.338\n",
      "0:00:06 | Epoch: 461/500 | train Loss: 0.05108 | EVM: 5.137\n",
      "0:00:06 | Epoch: 462/500 | train Loss: 0.05144 | EVM: 5.171\n",
      "0:00:06 | Epoch: 463/500 | train Loss: 0.05163 | EVM: 5.181\n",
      "0:00:06 | Epoch: 464/500 | train Loss: 0.05201 | EVM: 5.231\n",
      "0:00:06 | Epoch: 465/500 | train Loss: 0.05235 | EVM: 5.258\n",
      "0:00:06 | Epoch: 466/500 | train Loss: 0.05348 | EVM: 5.375\n",
      "0:00:05 | Epoch: 467/500 | train Loss: 0.05434 | EVM: 5.464\n",
      "0:00:06 | Epoch: 468/500 | train Loss: 0.05328 | EVM: 5.358\n",
      "0:00:06 | Epoch: 469/500 | train Loss: 0.05353 | EVM: 5.369\n",
      "0:00:06 | Epoch: 470/500 | train Loss: 0.04963 | EVM: 4.983\n",
      "0:00:07 | Epoch: 471/500 | train Loss: 0.05408 | EVM: 5.453\n",
      "0:00:06 | Epoch: 472/500 | train Loss: 0.05182 | EVM: 5.211\n",
      "0:00:06 | Epoch: 473/500 | train Loss: 0.05228 | EVM: 5.252\n",
      "0:00:05 | Epoch: 474/500 | train Loss: 0.05249 | EVM: 5.277\n",
      "0:00:06 | Epoch: 475/500 | train Loss: 0.05144 | EVM: 5.176\n",
      "0:00:06 | Epoch: 476/500 | train Loss: 0.05196 | EVM: 5.22\n",
      "0:00:06 | Epoch: 477/500 | train Loss: 0.05368 | EVM: 5.405\n",
      "0:00:06 | Epoch: 478/500 | train Loss: 0.05213 | EVM: 5.234\n",
      "0:00:06 | Epoch: 479/500 | train Loss: 0.05545 | EVM: 5.588\n",
      "0:00:06 | Epoch: 480/500 | train Loss: 0.05429 | EVM: 5.457\n",
      "0:00:06 | Epoch: 481/500 | train Loss: 0.05178 | EVM: 5.213\n",
      "0:00:06 | Epoch: 482/500 | train Loss: 0.05003 | EVM: 5.022\n",
      "0:00:06 | Epoch: 483/500 | train Loss: 0.0513 | EVM: 5.152\n",
      "0:00:06 | Epoch: 484/500 | train Loss: 0.05112 | EVM: 5.137\n",
      "0:00:05 | Epoch: 485/500 | train Loss: 0.05144 | EVM: 5.166\n",
      "0:00:05 | Epoch: 486/500 | train Loss: 0.05252 | EVM: 5.277\n",
      "0:00:06 | Epoch: 487/500 | train Loss: 0.05408 | EVM: 5.434\n",
      "0:00:06 | Epoch: 488/500 | train Loss: 0.05631 | EVM: 5.657\n",
      "0:00:06 | Epoch: 489/500 | train Loss: 0.05575 | EVM: 5.625\n",
      "0:00:05 | Epoch: 490/500 | train Loss: 0.05194 | EVM: 5.225\n",
      "0:00:06 | Epoch: 491/500 | train Loss: 0.0517 | EVM: 5.196\n",
      "0:00:05 | Epoch: 492/500 | train Loss: 0.05095 | EVM: 5.123\n",
      "0:00:06 | Epoch: 493/500 | train Loss: 0.052 | EVM: 5.222\n",
      "0:00:06 | Epoch: 494/500 | train Loss: 0.05368 | EVM: 5.406\n",
      "0:00:06 | Epoch: 495/500 | train Loss: 0.05205 | EVM: 5.243\n",
      "0:00:06 | Epoch: 496/500 | train Loss: 0.0506 | EVM: 5.078\n",
      "0:00:06 | Epoch: 497/500 | train Loss: 0.05249 | EVM: 5.285\n",
      "0:00:05 | Epoch: 498/500 | train Loss: 0.05304 | EVM: 5.33\n",
      "0:00:06 | Epoch: 499/500 | train Loss: 0.05151 | EVM: 5.179\n",
      "0:00:06 | Epoch: 500/500 | train Loss: 0.05217 | EVM: 5.243\n"
     ]
    }
   ],
   "source": [
    "model_info = {'linear_compensation': True,\n",
    "                          'sampling': 4,\n",
    "                          'batch_size': 100,\n",
    "                          'neuron': 320,\n",
    "                          'epochs': 500,\n",
    "                          'lr': 0.001,\n",
    "                          'activation': 'CReLU', # 'CReLU' or 'CSigmoid' or 'modReLU'\n",
    "                          'form': 'RZ16QAM',\n",
    "                          'Lmax': 2500}\n",
    "\n",
    "signal_info_random = {'signal_type': 'random',\n",
    "                                         'seed': '1234',\n",
    "                                         'bit_num': 50000}\n",
    "\n",
    "signal_info_image0 = {'signal_type': 'image',\n",
    "                                     'target_dir': 'train_0',\n",
    "                                     'step': 60,\n",
    "                                     'image_number': '0, 1, 2, 3, 4, 5, 6, 7, 8, 9',\n",
    "                                     'ebtb': True}\n",
    "\n",
    "signal_info_image1 = {'signal_type': 'image',\n",
    "                                     'target_dir': 'train_0',\n",
    "                                     'step': 60,\n",
    "                                     'image_number': '0, 5, 6, 12, 17, 33, 35, 45, 52, 53',\n",
    "                                     'ebtb': True}\n",
    "\n",
    "tap = 25\n",
    "train_cvnn_with_save(model_info, signal_info_image1, tap, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
